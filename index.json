[{"categories":null,"content":"  LoveIt is a clean, elegant but advanced blog theme for Hugo developed by Dillon. It is based on the original LeaveIt Theme and KeepIt Theme. Hugo Theme LoveIt ","date":"2019-08-02","objectID":"/about/:0:0","tags":null,"title":"About LoveIt","uri":"/about/"},{"categories":null,"content":"Features Performance and SEO  Optimized for performance: 99/100 on mobile and 100/100 on desktop in Google PageSpeed Insights  Optimized SEO performance with a correct SEO SCHEMA based on JSON-LD  Google Analytics supported  Fathom Analytics supported  Search engine verification supported (Google, Bind, Yandex and Baidu)  CDN for third-party libraries supported  Automatically converted images with Lazy Load by lazysizes Appearance and Layout / Responsive layout / Light/Dark mode  Globally consistent design language  Pagination supported  Easy-to-use and self-expanding table of contents  Multilanguage supported and i18n ready  Beautiful CSS animation Social and Comment Systems  Gravatar supported by Gravatar  Local Avatar supported  Up to 64 social links supported  Up to 28 share sites supported  Disqus comment system supported by Disqus  Gitalk comment system supported by Gitalk  Valine comment system supported by Valine  Facebook comments system supported by Facebook  Telegram comments system supported by Comments  Commento comment system supported by Commento  Utterances comment system supported by Utterances Extended Features  Search supported by Lunr.js or algolia  Twemoji supported  Automatically highlighting code  Copy code to clipboard with one click  Images gallery supported by lightgallery.js  Extended Markdown syntax for Font Awesome icons  Extended Markdown syntax for ruby annotation  Extended Markdown syntax for fraction  Mathematical formula supported by $ \\KaTeX $  Diagrams shortcode supported by mermaid  Interactive data visualization shortcode supported by ECharts  Mapbox shortcode supported by Mapbox GL JS  Music player shortcode supported by APlayer and MetingJS  Bilibili player shortcode  Kinds of admonitions shortcode  Custom style shortcode  Custom script shortcode  Animated typing supported by TypeIt  Dynamic scroll supported by Smooth Scroll  Cookie consent banner supported by cookieconsent … ","date":"2019-08-02","objectID":"/about/:0:1","tags":null,"title":"About LoveIt","uri":"/about/"},{"categories":null,"content":"License LoveIt is licensed under the MIT license. Check the LICENSE file for details. Thanks to the authors of following resources included in the theme: normalize.css Font Awesome Simple Icons Animate.css Smooth Scroll autocomplete.js Lunr.js algoliasearch lazysizes object-fit-images Twemoji lightgallery.js clipboard.js Sharer.js TypeIt $ \\KaTeX $ mermaid ECharts Mapbox GL JS APlayer MetingJS Gitalk Valine cookieconsent ","date":"2019-08-02","objectID":"/about/:0:2","tags":null,"title":"About LoveIt","uri":"/about/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 开篇词 | 业务代码真的会有这么多坑？  下载APP   关闭 讲堂 部落 算法训练营 前端进阶训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 开篇词 | 业务代码真的会有这么多坑？ 2020-03-09 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长14:27大小13.24M  你好，我是朱晔，贝壳金服的资深架构师。我先和你说说我这 15 年的工作经历吧，以加深彼此的了解。前 7 年，我专注于.NET 领域，负责业务项目的同时，也做了很多社区工作。在 CSDN 做版主期间，我因为回答了大量有关.NET 的问题，并把很多问题的答案总结成了博客，获得了 3 次微软 MVP 的称号。后来，我转到了 Java 领域，也从程序员变为了架构师，更关注开源项目和互联网架构设计。在空中网，我整体负责了百万人在线的大型 MMO 网游《激战》技术平台的架构设计，期间和团队开发了许多性能和稳定性都不错的 Java 框架；在饿了么，我负责过日千万订单量的物流平台的开发管理和架构工作，遇到了许多只有高并发下才会出现的问题，积累了大量的架构经验；现在，我在贝壳金服的基础架构团队，负责基础组件、中间件、基础服务开发规划，制定一些流程和规范，带领团队自研 Java 后端开发框架、微服务治理平台等，在落地 Spring Cloud 结合 Kubernetes 容器云平台技术体系的过程中，摸索出了很多适合公司项目的基础组件和最佳实践。这 15 年来，我一直没有脱离编码工作，接触过大大小小的项目不下 400 个，自己亲身经历的、见别人踩过的坑不计其数。我感触很深的一点是，业务代码中真的有太多的坑：有些是看似非常简单的知识点反而容易屡次踩坑，比如 Spring 声明式事务不生效的问题；而有些坑因为“潜伏期”长，引发的线上事故造成了大量的人力和资金损失。因此，我系统梳理了这些案例和坑点，最终筛选出 100 个案例，涉及 130 多个坑点，组成了这个课程。意识不到业务代码的坑，很危险我想看到 100、130 这两个数字，你不禁要问了：“我写了好几年的业务代码了，遇到问题时上网搜一下就有答案，遇到最多的问题就是服务器不稳定，重启一下基本就可以解决，哪里会有这么多坑呢？”带着这个问题，你继续听我往下说吧。据我观察，很多开发同学没意识到这些坑，有以下三种可能：意识不到坑的存在，比如所谓的服务器不稳定很可能是代码问题导致的，很多时候遇到 OOM、死锁、超时问题在运维层面通过改配置、重启、扩容等手段解决了，没有反推到开发层面去寻找根本原因。有些问题只会在特定情况下暴露。比如，缓存击穿、在多线程环境使用非线程安全的类，只有在多线程或高并发的情况才会暴露问题。有些性能问题不会导致明显的 Bug，只会让程序运行缓慢、内存使用增加，但会在量变到质变的瞬间爆发。而正是因为没有意识到这些坑和问题，采用了错误的处理方式，最后问题一旦爆发，处理起来就非常棘手，这是非常可怕的。下面这些场景有没有感觉似曾相识呢？比如，我曾听说过有一个订单量很大的项目，每天总有上千份订单的状态或流程有问题，需要花费大量的时间来核对数据，修复订单状态。开发同学因为每天牵扯太多经历在排查问题上，根本没时间开发新需求。技术负责人为此头痛不已，无奈之下招了专门的技术支持人员。最后痛定思痛，才决定开启明细日志彻查这个问题，结果发现是自调用方法导致事务没生效的坑。再比如，有个朋友告诉我，他们的金融项目计算利息的代码中，使用了 float 类型而不是 BigDecimal 类来保存和计算金额，导致给用户结算的每一笔利息都多了几分钱。好在，日终对账及时发现了问题。试想一下，结算的有上千个用户，每个用户有上千笔小订单，如果等月终对账的时候再发现，可能已经损失了几百万。再比如，我们使用 RabbitMQ 做异步处理，业务处理失败的消息会循环不断地进入 MQ。问题爆发之前，可能只影响了消息处理的时效性。但等 MQ 彻底瘫痪时，面对 MQ 中堆积的、混杂了死信和正常消息的几百万条数据，你除了清空又能怎么办。但清空 MQ，就意味着要花费几小时甚至几十小时的时间，来补正常的业务数据，对业务影响时间很长。像这样由一个小坑引发的重大事故，不仅仅会给公司造成损失，还会因为自责影响工作状态，降低编码的自信心。我就曾遇到过一位比较负责的核心开发同学，因为一个 Bug 给公司带来数万元的经济损失，最后心理上承受不住提出了辞职。其实，很多时候不是我们不想从根本上解决问题，只是不知道问题到底在了哪里。要避开这些坑、找到这些定时炸弹，第一步就是得知道它们是什么、在哪里、为什么会出现。而讲清楚这些坑点和相关的最佳实践，正是本课程的主要内容。这个课程是什么？如果用几个关键词概括这个课程的话，那我会选择“Java”“业务开发”“避坑 100 例”这 3 个。接下来，我就和你详细说说这个课程是什么，以及有什么特点。第一个关键词是“Java”，指的是课程内所有 Demo 都是基于 Java 语言的。如果你熟悉 Java，那可以 100% 体会到这些坑点，也可以直接用这些 Demo 去检查你的业务代码是否也有类似的错误实现。如果你不熟悉 Java 问题也不大，现在大部分高级语言的特性和结构都差不多，许多都是共性问题。此外“设计篇”“安全篇”的内容，基本是脱离具体语言层面的、高层次的问题。因此，即使不使用 Java，你也可以有不少收获，这也是本课程的第一个特点。讲到这里，我要说明的是，这个课程是围绕坑点而不是 Java 语言体系展开的，因此不是系统学习 Java 的教材。第二个关键词是“业务开发”，也就是说课程内容限定在业务项目的开发，侧重业务项目开发时可能遇到的坑。我们先看“业务”这个词。做业务开发时间长的同学尤其知道，业务项目有两大特点：工期紧、逻辑复杂，开发人员会更多地考虑主流程逻辑的正确实现，忽略非主流程逻辑，或保障、补偿、一致性逻辑的实现；往往缺乏详细的设计、监控和容量规划的闭环，结果就是随着业务发展出现各种各样的事故。根据这些性质，我总结出了近 30 个方面的内容，力求覆盖业务项目开发的关键问题。案例的全面性，是本课程的第二大特点。这些案例可以看作是 Java 业务代码的避坑大全，帮助你写出更好的代码，也能帮你进一步补全知识网增加面试的信心。你甚至可以把二级目录当作代码审核的 Checklist，帮助业务项目一起成长和避坑。我们再看“开发”这个词。为了更聚焦，也更有针对性，我把专栏内容限定在业务开发，不会过多地讨论架构、测试、部署运维等阶段的问题。而“设计篇”，重在讲述架构设计上可能会遇到的坑，不会全面、完整地介绍高可用、高并发、可伸缩性等架构因素。第三个关键词是“避坑 100 例”。坑就是容易犯的错，避坑就是踩坑后分析根因，避免重复踩同样的坑。整个课程 30 篇文章，涉及 100 个案例、约 130 个小坑，其中 40% 来自于我经历过或者是见过的 200 多个线上生产事故，剩下的 60% 来自于我开发业务项目，以及日常审核别人的代码发现的问题。贴近实际，而不是讲述过时的或日常开发根本用不到的技术或框架，就是本课程的第三大特点了。大部分案例我会配合一个可执行的 Demo 来演示，Demo 中不仅有错误实现（踩坑），还有修正后的正确实现（避坑）。完整且连续、授人以渔，是本课程的第四大特点。完整且连续，知其所以然。我会按照“知识介绍 -\u003e 还原业务场景 -\u003e 错误实现 -\u003e 正确实现 -\u003e 原理分析 -\u003e 小总结 ”来讲解每个案例，针对每个坑点我至少会给出一个解决方案，并会挑选核心的点和你剖析源码。这样一来，你不仅能避坑，更能知道产生坑的根本原因，提升自己的技术能力。授人以渔。在遇到问题的时候，我们一定是先通过经验和工具来定位分析问题，然后才能定位到坑，并不是一开始就知道为什么的。在这个课程中，我会尽可能地把分析问题的过程完整地呈现给你，而不是直接告诉你为什么，这样你以后遇到问题时也能有解决问题的思路。这也是为什么，网络上虽然有很多关于 Java 代码踩坑的资料，但很多同学却和我反馈说，看过之后印象不深刻，也因为没吃透导致在一个知识点上重复踩坑。鉴于此，我还会与你分析我根据多年经验和思考，梳理出的一些最佳实践。看到这里，是不是迫不及待地想要看看这个专栏的内容都会涉及哪些坑点了呢？那就看看下面这张思维导图吧：鉴于这个专栏的内容和特点，我再和你说说最佳的学习方式是什么。学习课程的最佳方法我们都知道，编程是一门实践科学，只看不练、不思考，效果通常不会太好。因此，我建议你打开每篇文章后，能够按照下面的方式深入学习：对于每一个坑点，实际运行调试一下源码，使用文中提到的工具和方法重现问题，眼见为实。对于每一个坑点，再思考下除了文内的解决方案和思路外，是否还有其他修正方式。对于坑点根因中涉及的 JDK 或框架源码分析，你可以找到相关类再系统阅读一下源码。实践课后思考题。这些思考题，有的是对文章内容的补充，有的是额外容易踩的坑。理解了课程涉及的所有案例后，你应该就对业务代码大部分容易犯错的点了如指掌了，不仅仅自己可以写出更高质量的业务代码，还可以在审核别人代码时发现可能存在的问题，帮助整个团队成长。当然了，你从这个课程收获的将不仅是解决案例中那些问题的方法，还可以提升自己分析定位问题、阅读源码的能力。当你再遇到其他诡异的坑时，也能有清晰的解决思路，也可以成长为一名救火专家，帮助大家一起定位、分析问题。好了，以上就是我今天想要和你分享的内容了。请赶快跟随我们的课程开启避坑之旅吧，也欢迎你留言说说自己的情况，","date":"0001-01-01","objectID":"/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9C%9F%E7%9A%84%E4%BC%9A%E6%9C%89%E8%BF%99%E4%B9%88%E5%A4%9A%E5%9D%91/:0:0","tags":null,"title":"","uri":"/00%E4%B8%A8%E5%BC%80%E7%AF%87%E8%AF%8D%E4%B8%A8%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9C%9F%E7%9A%84%E4%BC%9A%E6%9C%89%E8%BF%99%E4%B9%88%E5%A4%9A%E5%9D%91/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 01 | 使用了并发工具类库，线程安全就高枕无忧了吗？  防止断更 请务必加首发微信：171 6143665   关闭 讲堂 部落 算法训练营 前端进阶训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 01 | 使用了并发工具类库，线程安全就高枕无忧了吗？ 2020-03-09 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长18:28大小14.81M  你好，我是朱晔。作为课程的第一讲，我今天要和你聊聊使用并发工具类库相关的话题。在代码审核讨论的时候，我们有时会听到有关线程安全和并发工具的一些片面的观点和结论，比如“把 HashMap 改为 ConcurrentHashMap，就可以解决并发问题了呀”“要不我们试试无锁的 CopyOnWriteArrayList 吧，性能更好”。事实上，这些说法都不太准确。的确，为了方便开发者进行多线程编程，现代编程语言会提供各种并发工具类。但如果我们没有充分了解它们的使用场景、解决的问题，以及最佳实践的话，盲目使用就可能会导致一些坑，小则损失性能，大则无法确保多线程情况下业务逻辑的正确性。我需要先说明下，这里的并发工具类是指用来解决多线程环境下并发问题的工具类库。一般而言并发工具包括同步器和容器两大类，业务代码中使用并发容器的情况会多一些，我今天分享的例子也会侧重并发容器。接下来，我们就看看在使用并发工具时，最常遇到哪些坑，以及如何解决、避免这些坑吧。没有意识到线程重用导致用户信息错乱的 Bug之前有业务同学和我反馈，在生产上遇到一个诡异的问题，有时获取到的用户信息是别人的。查看代码后，我发现他使用了 ThreadLocal 来缓存获取到的用户信息。我们知道，ThreadLocal 适用于变量在线程间隔离，而在方法或类间共享的场景。如果用户信息的获取比较昂贵（比如从数据库查询用户信息），那么在 ThreadLocal 中缓存数据是比较合适的做法。但，这么做为什么会出现用户信息错乱的 Bug 呢？我们看一个具体的案例吧。使用 Spring Boot 创建一个 Web 应用程序，使用 ThreadLocal 存放一个 Integer 的值，来暂且代表需要在线程中保存的用户信息，这个值初始是 null。在业务逻辑中，我先从 ThreadLocal 获取一次值，然后把外部传入的参数设置到 ThreadLocal 中，来模拟从当前上下文获取到用户信息的逻辑，随后再获取一次值，最后输出两次获得的值和线程名称。private ThreadLocal\u003cInteger\u003e currentUser = ThreadLocal.withInitial(() -\u003e null);@GetMapping(\"wrong\")public Map wrong(@RequestParam(\"userId\") Integer userId) { //设置用户信息之前先查询一次ThreadLocal中的用户信息 String before = Thread.currentThread().getName() + \":\" + currentUser.get(); //设置用户信息到ThreadLocal currentUser.set(userId); //设置用户信息之后再查询一次ThreadLocal中的用户信息 String after = Thread.currentThread().getName() + \":\" + currentUser.get(); //汇总输出两次查询结果 Map result = new HashMap(); result.put(\"before\", before); result.put(\"after\", after); return result;}按理说，在设置用户信息之前第一次获取的值始终应该是 null，但我们要意识到，程序运行在 Tomcat 中，执行程序的线程是 Tomcat 的工作线程，而 Tomcat 的工作线程是基于线程池的。顾名思义，线程池会重用固定的几个线程，一旦线程重用，那么很可能首次从 ThreadLocal 获取的值是之前其他用户的请求遗留的值。这时，ThreadLocal 中的用户信息就是其他用户的信息。为了更快地重现这个问题，我在配置文件中设置一下 Tomcat 的参数，把工作线程池最大线程数设置为 1，这样始终是同一个线程在处理请求：server.tomcat.max-threads=1运行程序后先让用户 1 来请求接口，可以看到第一和第二次获取到用户 ID 分别是 null 和 1，符合预期：随后用户 2 来请求接口，这次就出现了 Bug，第一和第二次获取到用户 ID 分别是 1 和 2，显然第一次获取到了用户 1 的信息，原因就是 Tomcat 的线程池重用了线程。从图中可以看到，两次请求的线程都是同一个线程：http-nio-8080-exec-1。这个例子告诉我们，在写业务代码时，首先要理解代码会跑在什么线程上：我们可能会抱怨学多线程没用，因为代码里没有开启使用多线程。但其实，可能只是我们没有意识到，在 Tomcat 这种 Web 服务器下跑的业务代码，本来就运行在一个多线程环境（否则接口也不可能支持这么高的并发），并不能认为没有显式开启多线程就不会有线程安全问题。因为线程的创建比较昂贵，所以 Web 服务器往往会使用线程池来处理请求，这就意味着线程会被重用。这时，使用类似 ThreadLocal 工具来存放一些数据时，需要特别注意在代码运行完后，显式地去清空设置的数据。如果在代码中使用了自定义的线程池，也同样会遇到这个问题。理解了这个知识点后，我们修正这段代码的方案是，在代码的 finally 代码块中，显式清除 ThreadLocal 中的数据。这样一来，新的请求过来即使使用了之前的线程也不会获取到错误的用户信息了。修正后的代码如下：@GetMapping(\"right\")public Map right(@RequestParam(\"userId\") Integer userId) { String before = Thread.currentThread().getName() + \":\" + currentUser.get(); currentUser.set(userId); try { String after = Thread.currentThread().getName() + \":\" + currentUser.get(); Map result = new HashMap(); result.put(\"before\", before); result.put(\"after\", after); return result; } finally { //在finally代码块中删除ThreadLocal中的数据，确保数据不串 currentUser.remove(); }}重新运行程序可以验证，再也不会出现第一次查询用户信息查询到之前用户请求的 Bug：ThreadLocal 是利用独占资源的方式，来解决线程安全问题，那如果我们确实需要有资源在线程之前共享，应该怎么办呢？这时，我们可能就需要用到线程安全的容器了。使用了线程安全的并发工具，并不代表解决了所有线程安全问题JDK 1.5 后推出的 ConcurrentHashMap，是一个高性能的线程安全的哈希表容器。“线程安全”这四个字特别容易让人误解，因为 ConcurrentHashMap 只能保证提供的原子性读写操作是线程安全的。我在相当多的业务代码中看到过这个误区，比如下面这个场景。有一个含 900 个元素的 Map，现在再补充 100 个元素进去，这个补充操作由 10 个线程并发进行。开发人员误以为使用了 ConcurrentHashMap 就不会有线程安全问题，于是不加思索地写出了下面的代码：在每一个线程的代码逻辑中先通过 size 方法拿到当前元素数量，计算 ConcurrentHashMap 目前还需要补充多少元素，并在日志中输出了这个值，然后通过 putAll 方法把缺少的元素添加进去。为方便观察问题，我们输出了这个 Map 一开始和最后的元素个数。//线程个数private static int THREAD_COUNT = 10;//总元素数量private static int ITEM_COUNT = 1000;//帮助方法，用来获得一个指定元素数量模拟数据的ConcurrentHashMapprivate ConcurrentHashMap\u003cString, Long\u003e getData(int count) { return LongStream.rangeClosed(1, count) .boxed() .collect(Collectors.toConcurrentMap(i -\u003e UUID.randomUUID().toString(), Function.identity(), (o1, o2) -\u003e o1, ConcurrentHashMap::new));}@GetMapping(\"wrong\")public String wrong() throws InterruptedException { ConcurrentHashMap\u003cString, Long\u003e concurrentHashMap = getData(ITEM_COUNT - 100); //初始900个元素 ","date":"0001-01-01","objectID":"/01%E4%B8%A8%E4%BD%BF%E7%94%A8%E4%BA%86%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E5%BA%93%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%B0%B1%E9%AB%98%E6%9E%95%E6%97%A0%E5%BF%A7%E4%BA%86%E5%90%97/:0:0","tags":null,"title":"","uri":"/01%E4%B8%A8%E4%BD%BF%E7%94%A8%E4%BA%86%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E5%BA%93%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%B0%B1%E9%AB%98%E6%9E%95%E6%97%A0%E5%BF%A7%E4%BA%86%E5%90%97/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 02 | 代码加锁：不要让“锁”事成为烦心事  防止断更 请务必加首发微信：171 6143665   关闭 讲堂 部落 算法训练营 前端进阶训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 02 | 代码加锁：不要让“锁”事成为烦心事 2020-03-09 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长17:18大小15.85M  你好，我是朱晔。在上一讲中，我与你介绍了使用并发容器等工具解决线程安全的误区。今天，我们来看看解决线程安全问题的另一种重要手段——锁，在使用上比较容易犯哪些错。我先和你分享一个有趣的案例吧。有一天，一位同学在群里说“见鬼了，疑似遇到了一个 JVM 的 Bug”，我们都很好奇是什么 Bug。于是，他贴出了这样一段代码：在一个类里有两个 int 类型的字段 a 和 b，有一个 add 方法循环 1 万次对 a 和 b 进行 ++ 操作，有另一个 compare 方法，同样循环 1 万次判断 a 是否小于 b，条件成立就打印 a 和 b 的值，并判断 a\u003eb 是否成立。@Slf4jpublic class Interesting { volatile int a = 1; volatile int b = 1; public void add() { log.info(\"add start\"); for (int i = 0; i \u003c 10000; i++) { a++; b++; } log.info(\"add done\"); } public void compare() { log.info(\"compare start\"); for (int i = 0; i \u003c 10000; i++) { //a始终等于b吗？ if (a \u003c b) { log.info(\"a:{},b:{},{}\", a, b, a \u003e b); //最后的a\u003eb应该始终是false吗？ } } log.info(\"compare done\"); }}他起了两个线程来分别执行 add 和 compare 方法：Interesting interesting = new Interesting();new Thread(() -\u003e interesting.add()).start();new Thread(() -\u003e interesting.compare()).start();按道理，a 和 b 同样进行累加操作，应该始终相等，compare 中的第一次判断应该始终不会成立，不会输出任何日志。但，执行代码后发现不但输出了日志，而且更诡异的是，compare 方法在判断 a\u003cb 成立的情况下还输出了 a\u003eb 也成立：群里一位同学看到这个问题笑了，说：“这哪是 JVM 的 Bug，分明是线程安全问题嘛。很明显，你这是在操作两个字段 a 和 b，有线程安全问题，应该为 add 方法加上锁，确保 a 和 b 的 ++ 是原子性的，就不会错乱了。”随后，他为 add 方法加上了锁：public synchronized void add()但，加锁后问题并没有解决。我们来仔细想一下，为什么锁可以解决线程安全问题呢。因为只有一个线程可以拿到锁，所以加锁后的代码中的资源操作是线程安全的。但是，这个案例中的 add 方法始终只有一个线程在操作，显然只为 add 方法加锁是没用的。之所以出现这种错乱，是因为两个线程是交错执行 add 和 compare 方法中的业务逻辑，而且这些业务逻辑不是原子性的：a++ 和 b++ 操作中可以穿插在 compare 方法的比较代码中；更需要注意的是，a\u003cb 这种比较操作在字节码层面是加载 a、加载 b 和比较三步，代码虽然是一行但也不是原子性的。所以，正确的做法应该是，为 add 和 compare 都加上方法锁，确保 add 方法执行时，compare 无法读取 a 和 b：public synchronized void add()public synchronized void compare()所以，使用锁解决问题之前一定要理清楚，我们要保护的是什么逻辑，多线程执行的情况又是怎样的。加锁前要清楚锁和被保护的对象是不是一个层面的除了没有分析清线程、业务逻辑和锁三者之间的关系随意添加无效的方法锁外，还有一种比较常见的错误是，没有理清楚锁和要保护的对象是否是一个层面的。我们知道静态字段属于类，类级别的锁才能保护；而非静态字段属于类实例，实例级别的锁就可以保护。先看看这段代码有什么问题：在类 Data 中定义了一个静态的 int 字段 counter 和一个非静态的 wrong 方法，实现 counter 字段的累加操作。class Data { @Getter private static int counter = 0; public static int reset() { counter = 0; return counter; } public synchronized void wrong() { counter++; }}写一段代码测试下：@GetMapping(\"wrong\")public int wrong(@RequestParam(value = \"count\", defaultValue = \"1000000\") int count) { Data.reset(); //多线程循环一定次数调用Data类不同实例的wrong方法 IntStream.rangeClosed(1, count).parallel().forEach(i -\u003e new Data().wrong()); return Data.getCounter();}因为默认运行 100 万次，所以执行后应该输出 100 万，但页面输出的是 639242：我们来分析下为什么会出现这个问题吧。在非静态的 wrong 方法上加锁，只能确保多个线程无法执行同一个实例的 wrong 方法，却不能保证不会执行不同实例的 wrong 方法。而静态的 counter 在多个实例中共享，所以必然会出现线程安全问题。理清思路后，修正方法就很清晰了：同样在类中定义一个 Object 类型的静态字段，在操作 counter 之前对这个字段加锁。class Data { @Getter private static int counter = 0; private static Object locker = new Object(); public void right() { synchronized (locker) { counter++; } }}你可能要问了，把 wrong 方法定义为静态不就可以了，这个时候锁是类级别的。可以是可以，但我们不可能为了解决线程安全问题改变代码结构，把实例方法改为静态方法。感兴趣的同学还可以从字节码以及 JVM 的层面继续探索一下，代码块级别的 synchronized 和方法上标记 synchronized 关键字，在实现上有什么区别。加锁要考虑锁的粒度和场景问题在方法上加 synchronized 关键字实现加锁确实简单，也因此我曾看到一些业务代码中几乎所有方法都加了 synchronized，但这种滥用 synchronized 的做法：一是，没必要。通常情况下 60% 的业务代码是三层架构，数据经过无状态的 Controller、Service、Repository 流转到数据库，没必要使用 synchronized 来保护什么数据。二是，可能会极大地降低性能。使用 Spring 框架时，默认情况下 Controller、Service、Repository 是单例的，加上 synchronized 会导致整个程序几乎就只能支持单线程，造成极大的性能问题。即使我们确实有一些共享资源需要保护，也要尽可能降低锁的粒度，仅对必要的代码块甚至是需要保护的资源本身加锁。比如，在业务代码中，有一个 ArrayList 因为会被多个线程操作而需要保护，又有一段比较耗时的操作（代码中的 slow 方法）不涉及线程安全问题，应该如何加锁呢？错误的做法是，给整段业务逻辑加锁，把 slow 方法和操作 ArrayList 的代码同时纳入 synchronized 代码块；更合适的做法是，把加锁的粒度降到最低，只在操作 ArrayList 的时候给这个 ArrayList 加锁。private List\u003cInteger\u003e data = new ArrayList\u003c\u003e();//不涉及共享资源的慢方法private void slow() { try { TimeUnit.MILLISECONDS.sleep(10); } catch (InterruptedException e) { }}//错误的加锁方法@GetMapping(\"wrong\")public int wrong() { long begin = System.currentTimeMillis(); IntStream.rangeClosed(1, 1000).parallel().forEach(i -\u003e { //加锁粒度太粗了 synchronized (this) { slow(); data.add(i); } }); log.info(\"took:{}\", System.currentTimeMillis() - begin); return data.size();}","date":"0001-01-01","objectID":"/02%E4%B8%A8%E4%BB%A3%E7%A0%81%E5%8A%A0%E9%94%81%E4%B8%8D%E8%A6%81%E8%AE%A9%E9%94%81%E4%BA%8B%E6%88%90%E4%B8%BA%E7%83%A6%E5%BF%83%E4%BA%8B/:0:0","tags":null,"title":"","uri":"/02%E4%B8%A8%E4%BB%A3%E7%A0%81%E5%8A%A0%E9%94%81%E4%B8%8D%E8%A6%81%E8%AE%A9%E9%94%81%E4%BA%8B%E6%88%90%E4%B8%BA%E7%83%A6%E5%BF%83%E4%BA%8B/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 03 | 线程池：业务代码最常用也最容易犯错的组件  防止断更 请务必加首发微信：1716143665   关闭 讲堂 部落 算法训练营 前端进阶训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 03 | 线程池：业务代码最常用也最容易犯错的组件 2020-03-12 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长22:11大小20.33M  你好，我是朱晔。今天，我来讲讲使用线程池需要注意的一些问题。在程序中，我们会用各种池化技术来缓存创建昂贵的对象，比如线程池、连接池、内存池。一般是预先创建一些对象放入池中，使用的时候直接取出使用，用完归还以便复用，还会通过一定的策略调整池中缓存对象的数量，实现池的动态伸缩。由于线程的创建比较昂贵，随意、没有控制地创建大量线程会造成性能问题，因此短平快的任务一般考虑使用线程池来处理，而不是直接创建线程。今天，我们就针对线程池这个话题展开讨论，通过三个生产事故，来看看使用线程池应该注意些什么。线程池的声明需要手动进行Java 中的 Executors 类定义了一些快捷的工具方法，来帮助我们快速创建线程池。《阿里巴巴 Java 开发手册》中提到，禁止使用这些方法来创建线程池，而应该手动 new ThreadPoolExecutor 来创建线程池。这一条规则的背后，是大量血淋淋的生产事故，最典型的就是 newFixedThreadPool 和 newCachedThreadPool，可能因为资源耗尽导致 OOM 问题。首先，我们来看一下 newFixedThreadPool 为什么可能会出现 OOM 的问题。我们写一段测试代码，来初始化一个单线程的 FixedThreadPool，循环 1 亿次向线程池提交任务，每个任务都会创建一个比较大的字符串然后休眠一小时：@GetMapping(\"oom1\")public void oom1() throws InterruptedException { ThreadPoolExecutor threadPool = (ThreadPoolExecutor) Executors.newFixedThreadPool(1); //打印线程池的信息，稍后我会解释这段代码 printStats(threadPool); for (int i = 0; i \u003c 100000000; i++) { threadPool.execute(() -\u003e { String payload = IntStream.rangeClosed(1, 1000000) .mapToObj(__ -\u003e \"a\") .collect(Collectors.joining(\"\")) + UUID.randomUUID().toString(); try { TimeUnit.HOURS.sleep(1); } catch (InterruptedException e) { } log.info(payload); }); } threadPool.shutdown(); threadPool.awaitTermination(1, TimeUnit.HOURS);}执行程序后不久，日志中就出现了如下 OOM：Exception in thread \"http-nio-45678-ClientPoller\" java.lang.OutOfMemoryError: GC overhead limit exceeded翻看 newFixedThreadPool 方法的源码不难发现，线程池的工作队列直接 new 了一个 LinkedBlockingQueue，而默认构造方法的 LinkedBlockingQueue 是一个 Integer.MAX_VALUE 长度的队列，可以认为是无界的：public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u003cRunnable\u003e());}public class LinkedBlockingQueue\u003cE\u003e extends AbstractQueue\u003cE\u003e implements BlockingQueue\u003cE\u003e, java.io.Serializable { ... /** * Creates a {@code LinkedBlockingQueue} with a capacity of * {@link Integer#MAX_VALUE}. */ public LinkedBlockingQueue() { this(Integer.MAX_VALUE); }...}虽然使用 newFixedThreadPool 可以把工作线程控制在固定的数量上，但任务队列是无界的。如果任务较多并且执行较慢的话，队列可能会快速积压，撑爆内存导致 OOM。我们再把刚才的例子稍微改一下，改为使用 newCachedThreadPool 方法来获得线程池。程序运行不久后，同样看到了如下 OOM 异常：[11:30:30.487] [http-nio-45678-exec-1] [ERROR] [.a.c.c.C.[.[.[/].[dispatcherServlet]:175 ] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler dispatch failed; nested exception is java.lang.OutOfMemoryError: unable to create new native thread] with root causejava.lang.OutOfMemoryError: unable to create new native thread 从日志中可以看到，这次 OOM 的原因是无法创建线程，翻看 newCachedThreadPool 的源码可以看到，这种线程池的最大线程数是 Integer.MAX_VALUE，可以认为是没有上限的，而其工作队列 SynchronousQueue 是一个没有存储空间的阻塞队列。这意味着，只要有请求到来，就必须找到一条工作线程来处理，如果当前没有空闲的线程就再创建一条新的。由于我们的任务需要 1 小时才能执行完成，大量的任务进来后会创建大量的线程。我们知道线程是需要分配一定的内存空间作为线程栈的，比如 1MB，因此无限制创建线程必然会导致 OOM：public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue\u003cRunnable\u003e());其实，大部分 Java 开发同学知道这两种线程池的特性，只是抱有侥幸心理，觉得只是使用线程池做一些轻量级的任务，不可能造成队列积压或开启大量线程。但，现实往往是残酷的。我之前就遇到过这么一个事故：用户注册后，我们调用一个外部服务去发送短信，发送短信接口正常时可以在 100 毫秒内响应，TPS 100 的注册量，CachedThreadPool 能稳定在占用 10 个左右线程的情况下满足需求。在某个时间点，外部短信服务不可用了，我们调用这个服务的超时又特别长， 比如 1 分钟，1 分钟可能就进来了 6000 用户，产生 6000 个发送短信的任务，需要 6000 个线程，没多久就因为无法创建线程导致了 OOM，整个应用程序崩溃。因此，我同样不建议使用 Executors 提供的两种快捷的线程池，原因如下：我们需要根据自己的场景、并发情况来评估线程池的几个核心参数，包括核心线程数、最大线程数、线程回收策略、工作队列的类型，以及拒绝策略，确保线程池的工作行为符合需求，一般都需要设置有界的工作队列和可控的线程数。任何时候，都应该为自定义线程池指定有意义的名称，以方便排查问题。当出现线程数量暴增、线程死锁、线程占用大量 CPU、线程执行出现异常等问题时，我们往往会抓取线程栈。此时，有意义的线程名称，就可以方便我们定位问题。除了建议手动声明线程池以外，我还建议用一些监控手段来观察线程池的状态。线程池这个组件往往会表现得任劳任怨、默默无闻，除非是出现了拒绝策略，否则压力再大都不会抛出一个异常。如果我们能提前观察到线程池队列的积压，或者线程数量的快速膨胀，往往可以提早发现并解决问题。线程池线程管理策略详解在之前的 Demo 中，我们用一个 printStats 方法实现了最简陋的监控，每秒输出一次线程池的基本内部信息，包括线程数、活跃线程数、完成了多少任务，以及队列中还有多少积压任务等信息：private void printStats(ThreadPoolExecutor threadPool) { Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -\u003e { log.info(\"=","date":"0001-01-01","objectID":"/03%E4%B8%A8%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E6%9C%80%E5%B8%B8%E7%94%A8%E4%B9%9F%E6%9C%80%E5%AE%B9%E6%98%93%E7%8A%AF%E9%94%99%E7%9A%84%E7%BB%84%E4%BB%B6/:0:0","tags":null,"title":"","uri":"/03%E4%B8%A8%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E6%9C%80%E5%B8%B8%E7%94%A8%E4%B9%9F%E6%9C%80%E5%AE%B9%E6%98%93%E7%8A%AF%E9%94%99%E7%9A%84%E7%BB%84%E4%BB%B6/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 04 | 连接池：别让连接池帮了倒忙  防止断更 请务必加首发微信：1716143665   关闭 讲堂 部落 算法训练营 前端进阶训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 04 | 连接池：别让连接池帮了倒忙 2020-03-14 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长23:41大小21.70M  你好，我是朱晔。今天，我们来聊聊使用连接池需要注意的问题。在上一讲，我们学习了使用线程池需要注意的问题。今天，我再与你说说另一种很重要的池化技术，即连接池。我先和你说说连接池的结构。连接池一般对外提供获得连接、归还连接的接口给客户端使用，并暴露最小空闲连接数、最大连接数等可配置参数，在内部则实现连接建立、连接心跳保持、连接管理、空闲连接回收、连接可用性检测等功能。连接池的结构示意图，如下所示：业务项目中经常会用到的连接池，主要是数据库连接池、Redis 连接池和 HTTP 连接池。所以，今天我就以这三种连接池为例，和你聊聊使用和配置连接池容易出错的地方。注意鉴别客户端 SDK 是否基于连接池在使用三方客户端进行网络通信时，我们首先要确定客户端 SDK 是否是基于连接池技术实现的。我们知道，TCP 是面向连接的基于字节流的协议：面向连接，意味着连接需要先创建再使用，创建连接的三次握手有一定开销；基于字节流，意味着字节是发送数据的最小单元，TCP 协议本身无法区分哪几个字节是完整的消息体，也无法感知是否有多个客户端在使用同一个 TCP 连接，TCP 只是一个读写数据的管道。如果客户端 SDK 没有使用连接池，而直接是 TCP 连接，那么就需要考虑每次建立 TCP 连接的开销，并且因为 TCP 基于字节流，在多线程的情况下对同一连接进行复用，可能会产生线程安全问题。我们先看一下涉及 TCP 连接的客户端 SDK，对外提供 API 的三种方式。在面对各种三方客户端的时候，只有先识别出其属于哪一种，才能理清楚使用方式。连接池和连接分离的 API：有一个 XXXPool 类负责连接池实现，先从其获得连接 XXXConnection，然后用获得的连接进行服务端请求，完成后使用者需要归还连接。通常，XXXPool 是线程安全的，可以并发获取和归还连接，而 XXXConnection 是非线程安全的。对应到连接池的结构示意图中，XXXPool 就是右边连接池那个框，左边的客户端是我们自己的代码。内部带有连接池的 API：对外提供一个 XXXClient 类，通过这个类可以直接进行服务端请求；这个类内部维护了连接池，SDK 使用者无需考虑连接的获取和归还问题。一般而言，XXXClient 是线程安全的。对应到连接池的结构示意图中，整个 API 就是蓝色框包裹的部分。非连接池的 API：一般命名为 XXXConnection，以区分其是基于连接池还是单连接的，而不建议命名为 XXXClient 或直接是 XXX。直接连接方式的 API 基于单一连接，每次使用都需要创建和断开连接，性能一般，且通常不是线程安全的。对应到连接池的结构示意图中，这种形式相当于没有右边连接池那个框，客户端直接连接服务端创建连接。虽然上面提到了 SDK 一般的命名习惯，但不排除有一些客户端特立独行，因此在使用三方 SDK 时，一定要先查看官方文档了解其最佳实践，或是在类似 Stackoverflow 的网站搜索 XXX threadsafe/singleton 字样看看大家的回复，也可以一层一层往下看源码，直到定位到原始 Socket 来判断 Socket 和客户端 API 的对应关系。明确了 SDK 连接池的实现方式后，我们就大概知道了使用 SDK 的最佳实践：如果是分离方式，那么连接池本身一般是线程安全的，可以复用。每次使用需要从连接池获取连接，使用后归还，归还的工作由使用者负责。如果是内置连接池，SDK 会负责连接的获取和归还，使用的时候直接复用客户端。如果 SDK 没有实现连接池（大多数中间件、数据库的客户端 SDK 都会支持连接池），那通常不是线程安全的，而且短连接的方式性能不会很高，使用的时候需要考虑是否自己封装一个连接池。接下来，我就以 Java 中用于操作 Redis 最常见的库 Jedis 为例，从源码角度分析下 Jedis 类到底属于哪种类型的 API，直接在多线程环境下复用一个连接会产生什么问题，以及如何用最佳实践来修复这个问题。首先，向 Redis 初始化 2 组数据，Key=a、Value=1，Key=b、Value=2：@PostConstructpublic void init() { try (Jedis jedis = new Jedis(\"127.0.0.1\", 6379)) { Assert.isTrue(\"OK\".equals(jedis.set(\"a\", \"1\")), \"set a = 1 return OK\"); Assert.isTrue(\"OK\".equals(jedis.set(\"b\", \"2\")), \"set b = 2 return OK\"); }}然后，启动两个线程，共享操作同一个 Jedis 实例，每一个线程循环 1000 次，分别读取 Key 为 a 和 b 的 Value，判断是否分别为 1 和 2：Jedis jedis = new Jedis(\"127.0.0.1\", 6379);new Thread(() -\u003e { for (int i = 0; i \u003c 1000; i++) { String result = jedis.get(\"a\"); if (!result.equals(\"1\")) { log.warn(\"Expect a to be 1 but found {}\", result); return; } }}).start();new Thread(() -\u003e { for (int i = 0; i \u003c 1000; i++) { String result = jedis.get(\"b\"); if (!result.equals(\"2\")) { log.warn(\"Expect b to be 2 but found {}\", result); return; } }}).start();TimeUnit.SECONDS.sleep(5);执行程序多次，可以看到日志中出现了各种奇怪的异常信息，有的是读取 Key 为 b 的 Value 读取到了 1，有的是流非正常结束，还有的是连接关闭异常：//错误1[14:56:19.069] [Thread-28] [WARN ] [.t.c.c.redis.JedisMisreuseController:45 ] - Expect b to be 2 but found 1//错误2redis.clients.jedis.exceptions.JedisConnectionException: Unexpected end of stream. at redis.clients.jedis.util.RedisInputStream.ensureFill(RedisInputStream.java:202) at redis.clients.jedis.util.RedisInputStream.readLine(RedisInputStream.java:50) at redis.clients.jedis.Protocol.processError(Protocol.java:114) at redis.clients.jedis.Protocol.process(Protocol.java:166) at redis.clients.jedis.Protocol.read(Protocol.java:220) at redis.clients.jedis.Connection.readProtocolWithCheckingBroken(Connection.java:318) at redis.clients.jedis.Connection.getBinaryBulkReply(Connection.java:255) at redis.clients.jedis.Connection.getBulkReply(Connection.java:245) at redis.clients.jedis.Jedis.get(Jedis.java:181) at org.geekbang.time.commonmistakes.connectionpool.redis.JedisMisreuseController.lambda$wrong$1(JedisMisreuseController.java:43) at java.lang.Thread.run(Thread.java:748)//错误3java.io.IOException: Socket Closed at java.net.AbstractPlainSocketImpl.getOutputStream(AbstractPlainSocketImpl.java:440) at java.net.Socket$3.run(Socket.java:954) at java.net.Socket$3.run(Socket.java:952) at java.security.AccessController.do","date":"0001-01-01","objectID":"/04%E4%B8%A8%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%88%AB%E8%AE%A9%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%B8%AE%E4%BA%86%E5%80%92%E5%BF%99/:0:0","tags":null,"title":"","uri":"/04%E4%B8%A8%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%88%AB%E8%AE%A9%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%B8%AE%E4%BA%86%E5%80%92%E5%BF%99/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 05 | HTTP调用：你考虑到超时、重试、并发了吗？  防止断更 请务必加首发微信：17 16143665   关闭 讲堂 部落 算法训练营 前端进阶训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 05 | HTTP调用：你考虑到超时、重试、并发了吗？ 2020-03-19 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长21:09大小19.37M  你好，我是朱晔。今天，我们一起聊聊进行 HTTP 调用需要注意的超时、重试、并发等问题。与执行本地方法不同，进行 HTTP 调用本质上是通过 HTTP 协议进行一次网络请求。网络请求必然有超时的可能性，因此我们必须考虑到这三点：首先，框架设置的默认超时是否合理；其次，考虑到网络的不稳定，超时后的请求重试是一个不错的选择，但需要考虑服务端接口的幂等性设计是否允许我们重试；最后，需要考虑框架是否会像浏览器那样限制并发连接数，以免在服务并发很大的情况下，HTTP 调用的并发数限制成为瓶颈。Spring Cloud 是 Java 微服务架构的代表性框架。如果使用 Spring Cloud 进行微服务开发，就会使用 Feign 进行声明式的服务调用。如果不使用 Spring Cloud，而直接使用 Spring Boot 进行微服务开发的话，可能会直接使用 Java 中最常用的 HTTP 客户端 Apache HttpClient 进行服务调用。接下来，我们就看看使用 Feign 和 Apache HttpClient 进行 HTTP 接口调用时，可能会遇到的超时、重试和并发方面的坑。配置连接超时和读取超时参数的学问对于 HTTP 调用，虽然应用层走的是 HTTP 协议，但网络层面始终是 TCP/IP 协议。TCP/IP 是面向连接的协议，在传输数据之前需要建立连接。几乎所有的网络框架都会提供这么两个超时参数：连接超时参数 ConnectTimeout，让用户配置建连阶段的最长等待时间；读取超时参数 ReadTimeout，用来控制从 Socket 上读取数据的最长等待时间。这两个参数看似是网络层偏底层的配置参数，不足以引起开发同学的重视。但，正确理解和配置这两个参数，对业务应用特别重要，毕竟超时不是单方面的事情，需要客户端和服务端对超时有一致的估计，协同配合方能平衡吞吐量和错误率。连接超时参数和连接超时的误区有这么两个：连接超时配置得特别长，比如 60 秒。一般来说，TCP 三次握手建立连接需要的时间非常短，通常在毫秒级最多到秒级，不可能需要十几秒甚至几十秒。如果很久都无法建连，很可能是网络或防火墙配置的问题。这种情况下，如果几秒连接不上，那么可能永远也连接不上。因此，设置特别长的连接超时意义不大，将其配置得短一些（比如 1~5 秒）即可。如果是纯内网调用的话，这个参数可以设置得更短，在下游服务离线无法连接的时候，可以快速失败。排查连接超时问题，却没理清连的是哪里。通常情况下，我们的服务会有多个节点，如果别的客户端通过客户端负载均衡技术来连接服务端，那么客户端和服务端会直接建立连接，此时出现连接超时大概率是服务端的问题；而如果服务端通过类似 Nginx 的反向代理来负载均衡，客户端连接的其实是 Nginx，而不是服务端，此时出现连接超时应该排查 Nginx。读取超时参数和读取超时则会有更多的误区，我将其归纳为如下三个。第一个误区：认为出现了读取超时，服务端的执行就会中断。我们来简单测试下。定义一个 client 接口，内部通过 HttpClient 调用服务端接口 server，客户端读取超时 2 秒，服务端接口执行耗时 5 秒。@RestController@RequestMapping(\"clientreadtimeout\")@Slf4jpublic class ClientReadTimeoutController { private String getResponse(String url, int connectTimeout, int readTimeout) throws IOException { return Request.Get(\"http://localhost:45678/clientreadtimeout\" + url) .connectTimeout(connectTimeout) .socketTimeout(readTimeout) .execute() .returnContent() .asString(); } @GetMapping(\"client\") public String client() throws IOException { log.info(\"client1 called\"); //服务端5s超时，客户端读取超时2秒 return getResponse(\"/server?timeout=5000\", 1000, 2000); } @GetMapping(\"server\") public void server(@RequestParam(\"timeout\") int timeout) throws InterruptedException { log.info(\"server called\"); TimeUnit.MILLISECONDS.sleep(timeout); log.info(\"Done\"); }}调用 client 接口后，从日志中可以看到，客户端 2 秒后出现了 SocketTimeoutException，原因是读取超时，服务端却丝毫没受影响在 3 秒后执行完成。[11:35:11.943] [http-nio-45678-exec-1] [INFO ] [.t.c.c.d.ClientReadTimeoutController:29 ] - client1 called[11:35:12.032] [http-nio-45678-exec-2] [INFO ] [.t.c.c.d.ClientReadTimeoutController:36 ] - server called[11:35:14.042] [http-nio-45678-exec-1] [ERROR] [.a.c.c.C.[.[.[/].[dispatcherServlet]:175 ] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exceptionjava.net.SocketTimeoutException: Read timed out at java.net.SocketInputStream.socketRead0(Native Method) ...[11:35:17.036] [http-nio-45678-exec-2] [INFO ] [.t.c.c.d.ClientReadTimeoutController:38 ] - Done我们知道，类似 Tomcat 的 Web 服务器都是把服务端请求提交到线程池处理的，只要服务端收到了请求，网络层面的超时和断开便不会影响服务端的执行。因此，出现读取超时不能随意假设服务端的处理情况，需要根据业务状态考虑如何进行后续处理。第二个误区：认为读取超时只是 Socket 网络层面的概念，是数据传输的最长耗时，故将其配置得非常短，比如 100 毫秒。其实，发生了读取超时，网络层面无法区分是服务端没有把数据返回给客户端，还是数据在网络上耗时较久或丢包。但，因为 TCP 是先建立连接后传输数据，对于网络情况不是特别糟糕的服务调用，通常可以认为出现连接超时是网络问题或服务不在线，而出现读取超时是服务处理超时。确切地说，读取超时指的是，向 Socket 写入数据后，我们等到 Socket 返回数据的超时时间，其中包含的时间或者说绝大部分的时间，是服务端处理业务逻辑的时间。第三个误区：认为超时时间越长任务接口成功率就越高，将读取超时参数配置得太长。进行 HTTP 请求一般是需要获得结果的，属于同步调用。如果超时时间很长，在等待服务端返回数据的同时，客户端线程（通常是 Tomcat 线程）也在等待，当下游服务出现大量超时的时候，程序可能也会受到拖累创建大量线程，最终崩溃。对定时任务或异步任务来说，读取超时配置得长些问题不大。但面向用户响应的请求或是微服务短平快的同步接口调用，并发量一般较大，我们应该设置一个较短的读取超时时间，以防止被下游服务拖慢，通常不会设置超过 30 秒的读取超时。你可能会说，如果把读取超时设置为 2 秒，服务端接口需要 3 秒，岂不是永远都拿不到执行结果了？的确是这样，因此设置读取超时一定要根据实际情况，过长可能会让下游抖动影响到自己，过短又可能影响成功率。甚至，有些时候我们还要根据下游服务的 SLA，为不同的服务端接口设置不同的客户端读取超时。Feign 和 Ribbon 配合使用，你知道怎么配置超时吗？刚才我强调了根据自己的需求配置连接超时和读取超时的重要性，你是否尝试过为 Spring Cloud 的 Feign 配置超时参数呢，有没有被网上的各种资料绕晕呢？在我看来，为 Feign 配置超时参数的复杂之处在于，Feign 自己有两个超时参数，它使用的负载均衡组件 Ribbon 本身还有相关配置。那么，这些配置的优先级是怎样的，又哪些什么坑呢？接下来，我们做一些实验吧。为测试服务端的","date":"0001-01-01","objectID":"/05%E4%B8%A8http%E8%B0%83%E7%94%A8%E4%BD%A0%E8%80%83%E8%99%91%E5%88%B0%E8%B6%85%E6%97%B6%E9%87%8D%E8%AF%95%E5%B9%B6%E5%8F%91%E4%BA%86%E5%90%97/:0:0","tags":null,"title":"","uri":"/05%E4%B8%A8http%E8%B0%83%E7%94%A8%E4%BD%A0%E8%80%83%E8%99%91%E5%88%B0%E8%B6%85%E6%97%B6%E9%87%8D%E8%AF%95%E5%B9%B6%E5%8F%91%E4%BA%86%E5%90%97/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 06 | 20%的业务代码的Spring声明式事务，可能都没处理正确  下载APP   关闭 讲堂 部落 算法训练营 前端进阶训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 06 | 20%的业务代码的Spring声明式事务，可能都没处理正确 2020-03-21 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长20:43大小18.98M  你好，我是朱晔。今天，我来和你聊聊业务代码中与数据库事务相关的坑。Spring 针对 Java Transaction API (JTA)、JDBC、Hibernate 和 Java Persistence API (JPA) 等事务 API，实现了一致的编程模型，而 Spring 的声明式事务功能更是提供了极其方便的事务配置方式，配合 Spring Boot 的自动配置，大多数 Spring Boot 项目只需要在方法上标记 @Transactional 注解，即可一键开启方法的事务性配置。据我观察，大多数业务开发同学都有事务的概念，也知道如果整体考虑多个数据库操作要么成功要么失败时，需要通过数据库事务来实现多个操作的一致性和原子性。但，在使用上大多仅限于为方法标记 @Transactional，不会去关注事务是否有效、出错后事务是否正确回滚，也不会考虑复杂的业务代码中涉及多个子业务逻辑时，怎么正确处理事务。事务没有被正确处理，一般来说不会过于影响正常流程，也不容易在测试阶段被发现。但当系统越来越复杂、压力越来越大之后，就会带来大量的数据不一致问题，随后就是大量的人工介入查看和修复数据。所以说，一个成熟的业务系统和一个基本可用能完成功能的业务系统，在事务处理细节上的差异非常大。要确保事务的配置符合业务功能的需求，往往不仅仅是技术问题，还涉及产品流程和架构设计的问题。今天这一讲的标题“20% 的业务代码的 Spring 声明式事务，可能都没处理正确”中，20% 这个数字在我看来还是比较保守的。我今天要分享的内容，就是帮助你在技术问题上理清思路，避免因为事务处理不当让业务逻辑的实现产生大量偶发 Bug。小心 Spring 的事务可能没有生效在使用 @Transactional 注解开启声明式事务时， 第一个最容易忽略的问题是，很可能事务并没有生效。实现下面的 Demo 需要一些基础类，首先定义一个具有 ID 和姓名属性的 UserEntity，也就是一个包含两个字段的用户表：@Entity@Datapublic class UserEntity { @Id @GeneratedValue(strategy = AUTO) private Long id; private String name; public UserEntity() { } public UserEntity(String name) { this.name = name; }}为了方便理解，我使用 Spring JPA 做数据库访问，实现这样一个 Repository，新增一个根据用户名查询所有数据的方法：@Repositorypublic interface UserRepository extends JpaRepository\u003cUserEntity, Long\u003e { List\u003cUserEntity\u003e findByName(String name);}定义一个 UserService 类，负责业务逻辑处理。如果不清楚 @Transactional 的实现方式，只考虑代码逻辑的话，这段代码看起来没有问题。定义一个入口方法 createUserWrong1 来调用另一个私有方法 createUserPrivate，私有方法上标记了 @Transactional 注解。当传入的用户名包含 test 关键字时判断为用户名不合法，抛出异常，让用户创建操作失败，期望事务可以回滚：@Service@Slf4jpublic class UserService { @Autowired private UserRepository userRepository; //一个公共方法供Controller调用，内部调用事务性的私有方法 public int createUserWrong1(String name) { try { this.createUserPrivate(new UserEntity(name)); } catch (Exception ex) { log.error(\"create user failed because {}\", ex.getMessage()); } return userRepository.findByName(name).size(); } //标记了@Transactional的private方法 @Transactional private void createUserPrivate(UserEntity entity) { userRepository.save(entity); if (entity.getName().contains(\"test\")) throw new RuntimeException(\"invalid username!\"); } //根据用户名查询用户数 public int getUserCount(String name) { return userRepository.findByName(name).size(); }}下面是 Controller 的实现，只是调用一下刚才定义的 UserService 中的入口方法 createUserWrong1。@Autowiredprivate UserService userService;@GetMapping(\"wrong1\")public int wrong1(@RequestParam(\"name\") String name) { return userService.createUserWrong1(name);}调用接口后发现，即便用户名不合法，用户也能创建成功。刷新浏览器，多次发现有十几个的非法用户注册。这里给出 @Transactional 生效原则 1，除非特殊配置（比如使用 AspectJ 静态织入实现 AOP），否则只有定义在 public 方法上的 @Transactional 才能生效。原因是，Spring 默认通过动态代理的方式实现 AOP，对目标方法进行增强，private 方法无法代理到，Spring 自然也无法动态增强事务处理逻辑。你可能会说，修复方式很简单，把标记了事务注解的 createUserPrivate 方法改为 public 即可。在 UserService 中再建一个入口方法 createUserWrong2，来调用这个 public 方法再次尝试：public int createUserWrong2(String name) { try { this.createUserPublic(new UserEntity(name)); } catch (Exception ex) { log.error(\"create user failed because {}\", ex.getMessage()); } return userRepository.findByName(name).size();}//标记了@Transactional的public方法@Transactionalpublic void createUserPublic(UserEntity entity) { userRepository.save(entity); if (entity.getName().contains(\"test\")) throw new RuntimeException(\"invalid username!\");}测试发现，调用新的 createUserWrong2 方法事务同样不生效。这里，我给出 @Transactional 生效原则 2，必须通过代理过的类从外部调用目标方法才能生效。Spring 通过 AOP 技术对方法进行增强，要调用增强过的方法必然是调用代理后的对象。我们尝试修改下 UserService 的代码，注入一个 self，然后再通过 self 实例调用标记有 @Transactional 注解的 createUserPublic 方法。设置断点可以看到，self 是由 Spring 通过 CGLIB 方式增强过的类：CGLIB 通过继承方式实现代理类，private 方法在子类不可见，自然也就无法进行事务增强；this 指针代表对象自己，Spring 不可能注入 this，所以通过 this 访问方法必然不是代理。把 this 改为 self 后测试发现，在 Controller 中调用 createUserRight 方法可以验证事务是生效的，非法的用户注册操作可以回滚。虽然在 UserService 内部注入自己调用自己的 createUserPublic 可以正确实现事务，但更合理的实现方式是，让 Controller 直接调用之前定义的 UserService 的 createUserPublic 方法，因为注入自己调用自己很奇怪，也不符合分层实现的规范：@GetMapping(\"right2\")public int right2(@RequestParam(","date":"0001-01-01","objectID":"/06%E4%B8%A820%E7%9A%84%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9A%84spring%E5%A3%B0%E6%98%8E%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%8F%AF%E8%83%BD%E9%83%BD%E6%B2%A1%E5%A4%84%E7%90%86%E6%AD%A3%E7%A1%AE/:0:0","tags":null,"title":"","uri":"/06%E4%B8%A820%E7%9A%84%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9A%84spring%E5%A3%B0%E6%98%8E%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%8F%AF%E8%83%BD%E9%83%BD%E6%B2%A1%E5%A4%84%E7%90%86%E6%AD%A3%E7%A1%AE/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 07 | 数据库索引：索引并不是万能药  防止断更 请务必加首发微信：17 16143665   关闭 讲堂 部落 算法训练营 前端进阶训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 07 | 数据库索引：索引并不是万能药 2020-03-24 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长25:25大小23.28M  你好，我是朱晔。今天，我要和你分享的主题是，数据库的索引并不是万能药。几乎所有的业务项目都会涉及数据存储，虽然当前各种 NoSQL 和文件系统大行其道，但 MySQL 等关系型数据库因为满足 ACID、可靠性高、对开发友好等特点，仍然最常被用于存储重要数据。在关系型数据库中，索引是优化查询性能的重要手段。为此，我经常看到一些同学一遇到查询性能问题，就盲目要求运维或 DBA 给数据表相关字段创建大量索引。显然，这种想法是错误的。今天，我们就以 MySQL 为例来深入理解下索引的原理，以及相关误区。InnoDB 是如何存储数据的？MySQL 把数据存储和查询操作抽象成了存储引擎，不同的存储引擎，对数据的存储和读取方式各不相同。MySQL 支持多种存储引擎，并且可以以表为粒度设置存储引擎。因为支持事务，我们最常使用的是 InnoDB。为方便理解下面的内容，我先和你简单说说 InnoDB 是如何存储数据的。虽然数据保存在磁盘中，但其处理是在内存中进行的。为了减少磁盘随机读取次数，InnoDB 采用页而不是行的粒度来保存数据，即数据被分成若干页，以页为单位保存在磁盘中。InnoDB 的页大小，一般是 16KB。各个数据页组成一个双向链表，每个数据页中的记录按照主键顺序组成单向链表；每一个数据页中有一个页目录，方便按照主键查询记录。数据页的结构如下：页目录通过槽把记录分成不同的小组，每个小组有若干条记录。如图所示，记录中最前面的小方块中的数字，代表的是当前分组的记录条数，最小和最大的槽指向 2 个特殊的伪记录。有了槽之后，我们按照主键搜索页中记录时，就可以采用二分法快速搜索，无需从最小记录开始遍历整个页中的记录链表。举一个例子，如果要搜索主键（PK）=15 的记录：先二分得出槽中间位是 (0+6)/2=3，看到其指向的记录是 12＜15，所以需要从 #3 槽后继续搜索记录；再使用二分搜索出 #3 槽和 #6 槽的中间位是 (3+6)/2=4.5 取整 4，#4 槽对应的记录是 16＞15，所以记录一定在 #4 槽中；再从 #3 槽指向的 12 号记录开始向下搜索 3 次，定位到 15 号记录。理解了 InnoDB 存储数据的原理后，我们就可以继续学习 MySQL 索引相关的原理和坑了。聚簇索引和二级索引说到索引，页目录就是最简单的索引，是通过对记录进行一级分组来降低搜索的时间复杂度。但，这样能够降低的时间复杂度数量级，非常有限。当有无数个数据页来存储表数据的时候，我们就需要考虑如何建立合适的索引，才能方便定位记录所在的页。为了解决这个问题，InnoDB 引入了 B+ 树。如下图所示，B+ 树是一棵倒过来的树：B+ 树的特点包括：最底层的节点叫作叶子节点，用来存放数据；其他上层节点叫作非叶子节点，仅用来存放目录项，作为索引；非叶子节点分为不同层次，通过分层来降低每一层的搜索量；所有节点按照索引键大小排序，构成一个双向链表，加速范围查找。因此，InnoDB 使用 B+ 树，既可以保存实际数据，也可以加速数据搜索，这就是聚簇索引。如果把上图叶子节点下面方块中的省略号看作实际数据的话，那么它就是聚簇索引的示意图。由于数据在物理上只会保存一份，所以包含实际数据的聚簇索引只能有一个。InnoDB 会自动使用主键（唯一定义一条记录的单个或多个字段）作为聚簇索引的索引键（如果没有主键，就选择第一个不包含 NULL 值的唯一列）。上图方框中的数字代表了索引键的值，对聚簇索引而言一般就是主键。我们再看看 B+ 树如何实现快速查找主键。比如，我们要搜索 PK=4 的数据，通过根节点中的索引可以知道数据在第一个记录指向的 2 号页中，通过 2 号页的索引又可以知道数据在 5 号页，5 号页就是实际的数据页，然后再通过二分法查找页目录马上可以找到记录的指针。为了实现非主键字段的快速搜索，就引出了二级索引，也叫作非聚簇索引、辅助索引。二级索引，也是利用的 B+ 树的数据结构，如下图所示：这次二级索引的叶子节点中保存的不是实际数据，而是主键，获得主键值后去聚簇索引中获得数据行。这个过程就叫作回表。举个例子，有个索引是针对用户名字段创建的，索引记录上面方块中的字母是用户名，按照顺序形成链表。如果我们要搜索用户名为 b 的数据，经过两次定位可以得出在 #5 数据页中，查出所有的主键为 7 和 6，再拿着这两个主键继续使用聚簇索引进行两次回表得到完整数据。考虑额外创建二级索引的代价创建二级索引的代价，主要表现在维护代价、空间代价和回表代价三个方面。接下来，我就与你仔细分析下吧。首先是维护代价。创建 N 个二级索引，就需要再创建 N 棵 B+ 树，新增数据时不仅要修改聚簇索引，还需要修改这 N 个二级索引。我们通过实验测试一下创建索引的代价。假设有一个 person 表，有主键 ID，以及 name、score、create_time 三个字段：CREATE TABLE `person` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `name` varchar(255) NOT NULL, `score` int(11) NOT NULL, `create_time` timestamp NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;通过下面的存储过程循环创建 10 万条测试数据，我的机器的耗时是 140 秒（本文的例子均在 MySQL 5.7.26 中执行）：CREATE DEFINER=`root`@`%` PROCEDURE `insert_person`()begin declare c_id integer default 1; while c_id\u003c=100000 do insert into person values(c_id, concat('name',c_id), c_id+100, date_sub(NOW(), interval c_id second)); set c_id=c_id+1; end while;end如果再创建两个索引，一个是 name 和 score 构成的联合索引，另一个是单一列 create_time 的索引，那么创建 10 万条记录的耗时提高到 154 秒：KEY `name_score` (`name`,`score`) USING BTREE,KEY `create_time` (`create_time`) USING BTREE这里，我再额外提一下，页中的记录都是按照索引值从小到大的顺序存放的，新增记录就需要往页中插入数据，现有的页满了就需要新创建一个页，把现有页的部分数据移过去，这就是页分裂；如果删除了许多数据使得页比较空闲，还需要进行页合并。页分裂和合并，都会有 IO 代价，并且可能在操作过程中产生死锁。你可以查看这个文档，以进一步了解如何设置合理的合并阈值，来平衡页的空闲率和因为再次页分裂产生的代价。其次是空间代价。虽然二级索引不保存原始数据，但要保存索引列的数据，所以会占用更多的空间。比如，person 表创建了两个索引后，使用下面的 SQL 查看数据和索引占用的磁盘：SELECT DATA_LENGTH, INDEX_LENGTH FROM information_schema.TABLES WHERE TABLE_NAME='person'结果显示，数据本身只占用了 4.7M，而索引占用了 8.4M。最后是回表的代价。二级索引不保存原始数据，通过索引找到主键后需要再查询聚簇索引，才能得到我们要的数据。比如，使用 SELECT * 按照 name 字段查询用户，使用 EXPLAIN 查看执行计划：EXPLAIN SELECT * FROM person WHERE NAME='name1'执行计划如下，可以发现：key 字段代表实际走的是哪个索引，其值是 name_score，说明走的是 name_score 这个索引。type 字段代表了访问表的方式，其值 ref 说明是二级索引等值匹配，符合我们的查询。把 SQL 中的 * 修改为 NAME 和 SCORE，也就是 SELECT name_score 联合索引包含的两列：EXPLAIN SELECT NAME,SCORE FROM person WHERE NAME='name1'再来看看执行计划：可以看到，Extra 列多了一行 Using index 的提示，证明这次查询直接查的是二级索引，免去了回表。原因很简单，联合索引中其实保存了多个索引列的值，对于页中的记录先按照字段 1 排序，如果相同再按照字段 2 排序，如图所示：图中，叶子节点每一条记录的第一和第二个方块是索引列的数据，第三个方块是记录的主键。如果我们需要查询的是索引列索引或联合索引能覆盖的数据，那么查询索引本身已经“覆盖”了需要的数据，不再需要回表查询。因此，这种情况也叫作索引覆盖。我会在最后一小节介绍如何查看不同查询的成本，和你一起看看索引覆盖和索引查询后回表的代价","date":"0001-01-01","objectID":"/07%E4%B8%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E7%B4%A2%E5%BC%95%E5%B9%B6%E4%B8%8D%E6%98%AF%E4%B8%87%E8%83%BD%E8%8D%AF/:0:0","tags":null,"title":"","uri":"/07%E4%B8%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E7%B4%A2%E5%BC%95%E5%B9%B6%E4%B8%8D%E6%98%AF%E4%B8%87%E8%83%BD%E8%8D%AF/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 08 | 判等问题：程序里如何确定你就是你？  防止断更 请务必加首发微信：1716143665   关闭 讲堂 部落 算法训练营 架构师训练营 企业服务 前端训练营 客户端下载 兑换中心 渠道合作 推荐作者 08 | 判等问题：程序里如何确定你就是你？ 2020-03-26 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长20:30大小18.79M  你好，我是朱晔。今天，我来和你聊聊程序里的判等问题。你可能会说，判等不就是一行代码的事情吗，有什么好说的。但，这一行代码如果处理不当，不仅会出现 Bug，还可能会引起内存泄露等问题。涉及判等的 Bug，即使是使用 == 这种错误的判等方式，也不是所有时候都会出问题。所以类似的判等问题不太容易发现，可能会被隐藏很久。今天，我就 equals、compareTo 和 Java 的数值缓存、字符串驻留等问题展开讨论，希望你可以理解其原理，彻底消除业务代码中的相关 Bug。注意 equals 和 == 的区别在业务代码中，我们通常使用 equals 或 == 进行判等操作。equals 是方法而 == 是操作符，它们的使用是有区别的：对基本类型，比如 int、long，进行判等，只能使用 ==，比较的是直接值。因为基本类型的值就是其数值。对引用类型，比如 Integer、Long 和 String，进行判等，需要使用 equals 进行内容判等。因为引用类型的直接值是指针，使用 == 的话，比较的是指针，也就是两个对象在内存中的地址，即比较它们是不是同一个对象，而不是比较对象的内容。这就引出了我们必须必须要知道的第一个结论：比较值的内容，除了基本类型只能使用 == 外，其他类型都需要使用 equals。在开篇我提到了，即使使用 == 对 Integer 或 String 进行判等，有些时候也能得到正确结果。这又是为什么呢？我们用下面的测试用例深入研究下：使用 == 对两个值为 127 的直接赋值的 Integer 对象判等；使用 == 对两个值为 128 的直接赋值的 Integer 对象判等；使用 == 对一个值为 127 的直接赋值的 Integer 和另一个通过 new Integer 声明的值为 127 的对象判等；使用 == 对两个通过 new Integer 声明的值为 127 的对象判等；使用 == 对一个值为 128 的直接赋值的 Integer 对象和另一个值为 128 的 int 基本类型判等。Integer a = 127; //Integer.valueOf(127)Integer b = 127; //Integer.valueOf(127)log.info(\"\\nInteger a = 127;\\n\" + \"Integer b = 127;\\n\" + \"a == b ? {}\",a == b); // trueInteger c = 128; //Integer.valueOf(128)Integer d = 128; //Integer.valueOf(128)log.info(\"\\nInteger c = 128;\\n\" + \"Integer d = 128;\\n\" + \"c == d ? {}\", c == d); //falseInteger e = 127; //Integer.valueOf(127)Integer f = new Integer(127); //new instancelog.info(\"\\nInteger e = 127;\\n\" + \"Integer f = new Integer(127);\\n\" + \"e == f ? {}\", e == f); //falseInteger g = new Integer(127); //new instanceInteger h = new Integer(127); //new instancelog.info(\"\\nInteger g = new Integer(127);\\n\" + \"Integer h = new Integer(127);\\n\" + \"g == h ? {}\", g == h); //falseInteger i = 128; //unboxint j = 128;log.info(\"\\nInteger i = 128;\\n\" + \"int j = 128;\\n\" + \"i == j ? {}\", i == j); //true通过运行结果可以看到，虽然看起来永远是在对 127 和 127、128 和 128 判等，但 == 却没有永远给我们 true 的答复。原因是什么呢？第一个案例中，编译器会把 Integer a = 127 转换为 Integer.valueOf(127)。查看源码可以发现，这个转换在内部其实做了缓存，使得两个 Integer 指向同一个对象，所以 == 返回 true。public static Integer valueOf(int i) { if (i \u003e= IntegerCache.low \u0026\u0026 i \u003c= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);}第二个案例中，之所以同样的代码 128 就返回 false 的原因是，默认情况下会缓存[-128, 127]的数值，而 128 处于这个区间之外。设置 JVM 参数加上 -XX:AutoBoxCacheMax=1000 再试试，是不是就返回 true 了呢？private static class IntegerCache { static final int low = -128; static final int high; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k \u003c cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high \u003e= 127; }}第三和第四个案例中，New 出来的 Integer 始终是不走缓存的新对象。比较两个新对象，或者比较一个新对象和一个来自缓存的对象，结果肯定不是相同的对象，因此返回 false。第五个案例中，我们把装箱的 Integer 和基本类型 int 比较，前者会先拆箱再比较，比较的肯定是数值而不是引用，因此返回 true。看到这里，对于 Integer 什么时候是相同对象什么时候是不同对象，就很清楚了吧。但知道这些其实意义不大，因为在大多数时候，我们并不关心 Integer 对象是否是同一个，只需要记得比较 Integer 的值请使用 equals，而不是 ==（对于基本类型 int 的比较当然只能使用 ==）。其实，我们应该都知道这个原则，只是有的时候特别容易忽略。以我之前遇到过的一个生产事故为例，有这么一个枚举定义了订单状态和对于状态的描述：enum StatusEnum { CREATED(1000, \"已创建\"), PAID(1001, \"已支付\"), DELIVERED(1002, \"已送到\"), FINISHED(1003, \"已完成\"); private final Integer status; //注意这里的Integer private final String desc; StatusEnum(Integer status, String desc) { this.status = status; this.desc = desc; }}在业务代码中，开发同学使用了 == 对枚举和入参 OrderQuery 中的 status 属性进行判等：@Datapublic class OrderQuery { private Integer status; private String name;}@PostMapping(\"enumcompare\")public void enumcompare(@R","date":"0001-01-01","objectID":"/08%E4%B8%A8%E5%88%A4%E7%AD%89%E9%97%AE%E9%A2%98%E7%A8%8B%E5%BA%8F%E9%87%8C%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9A%E4%BD%A0%E5%B0%B1%E6%98%AF%E4%BD%A0/:0:0","tags":null,"title":"","uri":"/08%E4%B8%A8%E5%88%A4%E7%AD%89%E9%97%AE%E9%A2%98%E7%A8%8B%E5%BA%8F%E9%87%8C%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9A%E4%BD%A0%E5%B0%B1%E6%98%AF%E4%BD%A0/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 09 | 数值计算：注意精度、舍入和溢出问题  防止断更 请务必加首发微信：1716143665   关闭 讲堂 部落 算法训练营 架构师训练营 企业服务 前端训练营 客户端下载 兑换中心 渠道合作 推荐作者 09 | 数值计算：注意精度、舍入和溢出问题 2020-03-28 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长14:42大小13.48M  你好，我是朱晔。今天，我要和你说说数值计算的精度、舍入和溢出问题。之所以要单独分享数值计算，是因为很多时候我们习惯的或者说认为理所当然的计算，在计算器或计算机看来并不是那么回事儿。就比如前段时间爆出的一条新闻，说是手机计算器把 10%+10% 算成了 0.11 而不是 0.2。出现这种问题的原因在于，国外的计算程序使用的是单步计算法。在单步计算法中，a+b% 代表的是 a*(1+b%)。所以，手机计算器计算 10%+10% 时，其实计算的是 10%*（1+10%），所以得到的是 0.11 而不是 0.2。在我看来，计算器或计算机会得到反直觉的计算结果的原因，可以归结为：在人看来，浮点数只是具有小数点的数字，0.1 和 1 都是一样精确的数字。但，计算机其实无法精确保存浮点数，因此浮点数的计算结果也不可能精确。在人看来，一个超大的数字只是位数多一点而已，多写几个 1 并不会让大脑死机。但，计算机是把数值保存在了变量中，不同类型的数值变量能保存的数值范围不同，当数值超过类型能表达的数值上限则会发生溢出问题。接下来，我们就具体看看这些问题吧。“危险”的 Double我们先从简单的反直觉的四则运算看起。对几个简单的浮点数进行加减乘除运算：System.out.println(0.1+0.2);System.out.println(1.0-0.8);System.out.println(4.015*100);System.out.println(123.3/100);double amount1 = 2.15;double amount2 = 1.10;if (amount1 - amount2 == 1.05) System.out.println(\"OK\");输出结果如下：0.300000000000000040.19999999999999996401.499999999999941.2329999999999999可以看到，输出结果和我们预期的很不一样。比如，0.1+0.2 输出的不是 0.3 而是 0.30000000000000004；再比如，对 2.15-1.10 和 1.05 判等，结果判等不成立。出现这种问题的主要原因是，计算机是以二进制存储数值的，浮点数也不例外。Java 采用了IEEE 754 标准实现浮点数的表达和运算，你可以通过这里查看数值转化为二进制的结果。比如，0.1 的二进制表示为 0.0 0011 0011 0011… （0011 无限循环)，再转换为十进制就是 0.1000000000000000055511151231257827021181583404541015625。对于计算机而言，0.1 无法精确表达，这是浮点数计算造成精度损失的根源。你可能会说，以 0.1 为例，其十进制和二进制间转换后相差非常小，不会对计算产生什么影响。但，所谓积土成山，如果大量使用 double 来作大量的金钱计算，最终损失的精度就是大量的资金出入。比如，每天有一百万次交易，每次交易都差一分钱，一个月下来就差 30 万。这就不是小事儿了。那，如何解决这个问题呢？我们大都听说过 BigDecimal 类型，浮点数精确表达和运算的场景，一定要使用这个类型。不过，在使用 BigDecimal 时有几个坑需要避开。我们用 BigDecimal 把之前的四则运算改一下：System.out.println(new BigDecimal(0.1).add(new BigDecimal(0.2)));System.out.println(new BigDecimal(1.0).subtract(new BigDecimal(0.8)));System.out.println(new BigDecimal(4.015).multiply(new BigDecimal(100)));System.out.println(new BigDecimal(123.3).divide(new BigDecimal(100)));输出如下：0.30000000000000001665334536937734810635447502136230468750.1999999999999999555910790149937383830547332763671875401.499999999999968025576890795491635799407958984375001.232999999999999971578290569595992565155029296875可以看到，运算结果还是不精确，只不过是精度高了而已。这里给出浮点数运算避坑第一原则：使用 BigDecimal 表示和计算浮点数，且务必使用字符串的构造方法来初始化 BigDecimal：System.out.println(new BigDecimal(\"0.1\").add(new BigDecimal(\"0.2\")));System.out.println(new BigDecimal(\"1.0\").subtract(new BigDecimal(\"0.8\")));System.out.println(new BigDecimal(\"4.015\").multiply(new BigDecimal(\"100\")));System.out.println(new BigDecimal(\"123.3\").divide(new BigDecimal(\"100\")));改进后，就能得到我们想要的输出了：0.30.2401.5001.233到这里，你可能会继续问，不能调用 BigDecimal 传入 Double 的构造方法，但手头只有一个 Double，如何转换为精确表达的 BigDecimal 呢？我们试试用 Double.toString 把 double 转换为字符串，看看行不行？System.out.println(new BigDecimal(\"4.015\").multiply(new BigDecimal(Double.toString(100))));输出为 401.5000。与上面字符串初始化 100 和 4.015 相乘得到的结果 401.500 相比，这里为什么多了 1 个 0 呢？原因就是，BigDecimal 有 scale 和 precision 的概念，scale 表示小数点右边的位数，而 precision 表示精度，也就是有效数字的长度。调试一下可以发现，new BigDecimal(Double.toString(100)) 得到的 BigDecimal 的 scale=1、precision=4；而 new BigDecimal(“100”) 得到的 BigDecimal 的 scale=0、precision=3。对于 BigDecimal 乘法操作，返回值的 scale 是两个数的 scale 相加。所以，初始化 100 的两种不同方式，导致最后结果的 scale 分别是 4 和 3。如果一定要用 Double 来初始化 BigDecimal 的话，可以使用 BigDecimal.valueOf 方法，以确保其表现和字符串形式的构造方法一致，这也是官方文档更推荐的方式：System.out.println(new BigDecimal(\"4.015\").multiply(BigDecimal.valueOf(100)));BigDecimal 的 toString 方法得到的字符串和 scale 相关，又会引出了另一个问题：对于浮点数的字符串形式输出和格式化，我们应该考虑显式进行，通过格式化表达式或格式化工具来明确小数位数和舍入方式。接下来，我们就聊聊浮点数舍入和格式化。考虑浮点数舍入和格式化的方式除了使用 Double 保存浮点数可能带来精度问题外，更匪夷所思的是这种精度问题，加上 String.format 的格式化舍入方式，可能得到让人摸不着头脑的结果。我们看一个例子吧。首先用 double 和 float 初始化两个 3.35 的浮点数，然后通过 String.format 使用 %.1f 来格式化这 2 个数字：double num1 = 3.35;float num2 = 3.35f;System.out.println(String.format(\"%.1f\", num1));//四舍五入System.out.println(String.format(\"%.1f\", num2));得到的结果居然是 3.4 和 3.3。这就是由精度问题和舍入方式共同导致的，double 和 float 的 3.35 其实相当于 3.350xxx 和 3.349xxx：3.3500000000000000888178419700125232338905334472656253.349999904632568359375String.format 采用四舍五入的方式进行舍入，取 1 位小数，double 的 3.350 四舍五入为 3.4，而 float 的 3","date":"0001-01-01","objectID":"/09%E4%B8%A8%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97%E6%B3%A8%E6%84%8F%E7%B2%BE%E5%BA%A6%E8%88%8D%E5%85%A5%E5%92%8C%E6%BA%A2%E5%87%BA%E9%97%AE%E9%A2%98/:0:0","tags":null,"title":"","uri":"/09%E4%B8%A8%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97%E6%B3%A8%E6%84%8F%E7%B2%BE%E5%BA%A6%E8%88%8D%E5%85%A5%E5%92%8C%E6%BA%A2%E5%87%BA%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 10 | 集合类：坑满地的List列表操作  下载APP   关闭 讲堂 部落 算法训练营 架构师训练营 企业服务 前端训练营 客户端下载 兑换中心 渠道合作 推荐作者 10 | 集合类：坑满地的List列表操作 2020-03-31 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长18:49大小17.24M  你好，我是朱晔。今天，我来和你说说 List 列表操作有哪些坑。Pascal 之父尼克劳斯 · 维尔特（Niklaus Wirth），曾提出一个著名公式“程序 = 数据结构 + 算法”。由此可见，数据结构的重要性。常见的数据结构包括 List、Set、Map、Queue、Tree、Graph、Stack 等，其中 List、Set、Map、Queue 可以从广义上统称为集合类数据结构。现代编程语言一般都会提供各种数据结构的实现，供我们开箱即用。Java 也是一样，比如提供了集合类的各种实现。Java 的集合类包括 Map 和 Collection 两大类。Collection 包括 List、Set 和 Queue 三个小类，其中 List 列表集合是最重要也是所有业务代码都会用到的。所以，今天我会重点介绍 List 的内容，而不会集中介绍 Map 以及 Collection 中其他小类的坑。今天，我们就从把数组转换为 List 集合、对 List 进行切片操作、List 搜索的性能问题等几个方面着手，来聊聊其中最可能遇到的一些坑。使用 Arrays.asList 把数据转换为 List 的三个坑Java 8 中 Stream 流式处理的各种功能，大大减少了集合类各种操作（投影、过滤、转换）的代码量。所以，在业务开发中，我们常常会把原始的数组转换为 Lis 类数据结构，来继续展开各种 Stream 操作。你可能也想到了，使用 Arrays.asList 方法可以把数组一键转换为 List，但其实没这么简单。接下来，就让我们看看其中的缘由，以及使用 Arrays.asList 把数组转换为 List 的几个坑。在如下代码中，我们初始化三个数字的 int[]数组，然后使用 Arrays.asList 把数组转换为 List：int[] arr = {1, 2, 3};List list = Arrays.asList(arr);log.info(\"list:{} size:{} class:{}\", list, list.size(), list.get(0).getClass());但，这样初始化的 List 并不是我们期望的包含 3 个数字的 List。通过日志可以发现，这个 List 包含的其实是一个 int 数组，整个 List 的元素个数是 1，元素类型是整数数组。12:50:39.445 [main] INFO org.geekbang.time.commonmistakes.collection.aslist.AsListApplication - list:[[I@1c53fd30] size:1 class:class [I其原因是，只能是把 int 装箱为 Integer，不可能把 int 数组装箱为 Integer 数组。我们知道，Arrays.asList 方法传入的是一个泛型 T 类型可变参数，最终 int 数组整体作为了一个对象成为了泛型类型 T：public static \u003cT\u003e List\u003cT\u003e asList(T... a) { return new ArrayList\u003c\u003e(a);}直接遍历这样的 List 必然会出现 Bug，修复方式有两种，如果使用 Java8 以上版本可以使用 Arrays.stream 方法来转换，否则可以把 int 数组声明为包装类型 Integer 数组：int[] arr1 = {1, 2, 3};List list1 = Arrays.stream(arr1).boxed().collect(Collectors.toList());log.info(\"list:{} size:{} class:{}\", list1, list1.size(), list1.get(0).getClass());Integer[] arr2 = {1, 2, 3};List list2 = Arrays.asList(arr2);log.info(\"list:{} size:{} class:{}\", list2, list2.size(), list2.get(0).getClass());修复后的代码得到如下日志，可以看到 List 具有三个元素，元素类型是 Integer：13:10:57.373 [main] INFO org.geekbang.time.commonmistakes.collection.aslist.AsListApplication - list:[1, 2, 3] size:3 class:class java.lang.Integer可以看到第一个坑是，不能直接使用 Arrays.asList 来转换基本类型数组。那么，我们获得了正确的 List，是不是就可以像普通的 List 那样使用了呢？我们继续往下看。把三个字符串 1、2、3 构成的字符串数组，使用 Arrays.asList 转换为 List 后，将原始字符串数组的第二个字符修改为 4，然后为 List 增加一个字符串 5，最后数组和 List 会是怎样呢？String[] arr = {\"1\", \"2\", \"3\"};List list = Arrays.asList(arr);arr[1] = \"4\";try { list.add(\"5\");} catch (Exception ex) { ex.printStackTrace();}log.info(\"arr:{} list:{}\", Arrays.toString(arr), list);可以看到，日志里有一个 UnsupportedOperationException，为 List 新增字符串 5 的操作失败了，而且把原始数组的第二个元素从 2 修改为 4 后，asList 获得的 List 中的第二个元素也被修改为 4 了：java.lang.UnsupportedOperationException at java.util.AbstractList.add(AbstractList.java:148) at java.util.AbstractList.add(AbstractList.java:108) at org.geekbang.time.commonmistakes.collection.aslist.AsListApplication.wrong2(AsListApplication.java:41) at org.geekbang.time.commonmistakes.collection.aslist.AsListApplication.main(AsListApplication.java:15)13:15:34.699 [main] INFO org.geekbang.time.commonmistakes.collection.aslist.AsListApplication - arr:[1, 4, 3] list:[1, 4, 3]这里，又引出了两个坑。第二个坑，Arrays.asList 返回的 List 不支持增删操作。Arrays.asList 返回的 List 并不是我们期望的 java.util.ArrayList，而是 Arrays 的内部类 ArrayList。ArrayList 内部类继承自 AbstractList 类，并没有覆写父类的 add 方法，而父类中 add 方法的实现，就是抛出 UnsupportedOperationException。相关源码如下所示：public static \u003cT\u003e List\u003cT\u003e asList(T... a) { return new ArrayList\u003c\u003e(a);}private static class ArrayList\u003cE\u003e extends AbstractList\u003cE\u003e implements RandomAccess, java.io.Serializable{ private final E[] a; ArrayList(E[] array) { a = Objects.requireNonNull(array); }... @Override public E set(int index, E element) { E oldValue = a[index]; a[index] = element; return oldValue; } ...}public abstract class AbstractList\u003cE\u003e extends AbstractCollection\u003cE\u003e implements List\u003cE\u003e {...public void add(int index, E element) { throw new UnsupportedOperationException(); }}第三个坑，对原始数组的修改会影响到我们获得的那个 List。看一下 ArrayList 的实现，可以发现 ArrayList 其实是直接使用了原始的数组。所以，我们要特别小心，把通过 Ar","date":"0001-01-01","objectID":"/10%E4%B8%A8%E9%9B%86%E5%90%88%E7%B1%BB%E5%9D%91%E6%BB%A1%E5%9C%B0%E7%9A%84list%E5%88%97%E8%A1%A8%E6%93%8D%E4%BD%9C/:0:0","tags":null,"title":"","uri":"/10%E4%B8%A8%E9%9B%86%E5%90%88%E7%B1%BB%E5%9D%91%E6%BB%A1%E5%9C%B0%E7%9A%84list%E5%88%97%E8%A1%A8%E6%93%8D%E4%BD%9C/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 11 | 空值处理：分不清楚的null和恼人的空指针  防止断更 请务必加首发微信：1716 143665   关闭 讲堂 部落 算法训练营 架构师训练营 企业服务 前端训练营 客户端下载 兑换中心 渠道合作 推荐作者 11 | 空值处理：分不清楚的null和恼人的空指针 2020-04-02 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长23:36大小21.62M  你好，我是朱晔。今天，我要和你分享的主题是，空值处理：分不清楚的 null 和恼人的空指针。有一天我收到一条短信，内容是“尊敬的 null 你好，XXX”。当时我就笑了，这是程序员都能 Get 的笑点，程序没有获取到我的姓名，然后把空格式化为了 null。很明显，这是没处理好 null。哪怕把 null 替换为贵宾、顾客，也不会引发这样的笑话。程序中的变量是 null，就意味着它没有引用指向或者说没有指针。这时，我们对这个变量进行任何操作，都必然会引发空指针异常，在 Java 中就是 NullPointerException。那么，空指针异常容易在哪些情况下出现，又应该如何修复呢？空指针异常虽然恼人但好在容易定位，更麻烦的是要弄清楚 null 的含义。比如，客户端给服务端的一个数据是 null，那么其意图到底是给一个空值，还是没提供值呢？再比如，数据库中字段的 NULL 值，是否有特殊的含义呢，针对数据库中的 NULL 值，写 SQL 需要特别注意什么呢？今天，就让我们带着这些问题开始 null 的踩坑之旅吧。修复和定位恼人的空指针问题NullPointerException 是 Java 代码中最常见的异常，我将其最可能出现的场景归为以下 5 种：参数值是 Integer 等包装类型，使用时因为自动拆箱出现了空指针异常；字符串比较出现空指针异常；诸如 ConcurrentHashMap 这样的容器不支持 Key 和 Value 为 null，强行 put null 的 Key 或 Value 会出现空指针异常；A 对象包含了 B，在通过 A 对象的字段获得 B 之后，没有对字段判空就级联调用 B 的方法出现空指针异常；方法或远程服务返回的 List 不是空而是 null，没有进行判空就直接调用 List 的方法出现空指针异常。为模拟说明这 5 种场景，我写了一个 wrongMethod 方法，并一个 wrong 方法来调用它。wrong 方法的入参 test 是一个由 0 和 1 构成的、长度为 4 的字符串，第几位设置为 1 就代表第几个参数为 null，用来控制 wrongMethod 方法的 4 个入参，以模拟各种空指针情况：private List\u003cString\u003e wrongMethod(FooService fooService, Integer i, String s, String t) { log.info(\"result {} {} {} {}\", i + 1, s.equals(\"OK\"), s.equals(t), new ConcurrentHashMap\u003cString, String\u003e().put(null, null)); if (fooService.getBarService().bar().equals(\"OK\")) log.info(\"OK\"); return null;}@GetMapping(\"wrong\")public int wrong(@RequestParam(value = \"test\", defaultValue = \"1111\") String test) { return wrongMethod(test.charAt(0) == '1' ? null : new FooService(), test.charAt(1) == '1' ? null : 1, test.charAt(2) == '1' ? null : \"OK\", test.charAt(3) == '1' ? null : \"OK\").size();}class FooService { @Getter private BarService barService;}class BarService { String bar() { return \"OK\"; }}很明显，这个案例出现空指针异常是因为变量是一个空指针，尝试获得变量的值或访问变量的成员会获得空指针异常。但，这个异常的定位比较麻烦。在测试方法 wrongMethod 中，我们通过一行日志记录的操作，在一行代码中模拟了 4 处空指针异常：对入参 Integer i 进行 +1 操作；对入参 String s 进行比较操作，判断内容是否等于\"OK\"；对入参 String s 和入参 String t 进行比较操作，判断两者是否相等；对 new 出来的 ConcurrentHashMap 进行 put 操作，Key 和 Value 都设置为 null。输出的异常信息如下：java.lang.NullPointerException: null at org.geekbang.time.commonmistakes.nullvalue.demo2.AvoidNullPointerExceptionController.wrongMethod(AvoidNullPointerExceptionController.java:37) at org.geekbang.time.commonmistakes.nullvalue.demo2.AvoidNullPointerExceptionController.wrong(AvoidNullPointerExceptionController.java:20)这段信息确实提示了这行代码出现了空指针异常，但我们很难定位出到底是哪里出现了空指针，可能是把入参 Integer 拆箱为 int 的时候出现的，也可能是入参的两个字符串任意一个为 null，也可能是因为把 null 加入了 ConcurrentHashMap。你可能会想到，要排查这样的问题，只要设置一个断点看一下入参即可。但，在真实的业务场景中，空指针问题往往是在特定的入参和代码分支下才会出现，本地难以重现。如果要排查生产上出现的空指针问题，设置代码断点不现实，通常是要么把代码进行拆分，要么增加更多的日志，但都比较麻烦。在这里，我推荐使用阿里开源的 Java 故障诊断神器Arthas。Arthas 简单易用功能强大，可以定位出大多数的 Java 生产问题。接下来，我就和你演示下如何在 30 秒内知道 wrongMethod 方法的入参，从而定位到空指针到底是哪个入参引起的。如下截图中有三个红框，我先和你分析第二和第三个红框：第二个红框表示，Arthas 启动后被附加到了 JVM 进程；第三个红框表示，通过 watch 命令监控 wrongMethod 方法的入参。watch 命令的参数包括类名表达式、方法表达式和观察表达式。这里，我们设置观察类为 AvoidNullPointerExceptionController，观察方法为 wrongMethod，观察表达式为 params 表示观察入参：watch org.geekbang.time.commonmistakes.nullvalue.demo2.AvoidNullPointerExceptionController wrongMethod params开启 watch 后，执行 2 次 wrong 方法分别设置 test 入参为 1111 和 1101，也就是第一次传入 wrongMethod 的 4 个参数都为 null，第二次传入的第 1、2 和 4 个参数为 null。配合图中第一和第四个红框可以看到，第二次调用时，第三个参数是字符串 OK 其他参数是 null，Archas 正确输出了方法的所有入参，这样我们很容易就能定位到空指针的问题了。到这里，如果是简单的业务逻辑的话，你就可以定位到空指针异常了；如果是分支复杂的业务逻辑，你需要再借助 stack 命令来查看 wrongMethod 方法的调用栈，并配合 watch 命令查看各方法的入参，就可以很方便地定位到空指针的根源了。下图演示了通过 stack 命令观察 wrongMethod 的调用路径：如果你想了解 Arthas 各种命令的详细使用方法，可以点击这里查看。接下来，我们看看如何修复上面出现的 5 种空指针异常。其实，对于任何空指针异常的处理，最直白的方式是先判空后操作。不过，这只能让异常不再出现，我们还是要找到程序逻辑中出现的空指针究竟是来源于入参还是 Bug：如果是来源于入参，还要进一步分析入参是否合理等；如果是来源于 Bug，那空指针不一定是纯粹的程序 Bug，可能还涉及业务属性和接口调用规范等。在这里，因为是 Demo，所以我们只考虑纯粹的空指针判空这种修复方式。如果要先判空后处理，大多数人会想到使用 if-else 代码块。但，这种方式既增加代码量又会降低易读性，我们可以尝试利用 Java 8 的 Optional 类来消除这样的 if-else 逻辑，使用一行代码进行判空和处理。修复思路如下：对于 Integer 的判空，可以使用 Optional.ofNullable 来构造一个 Optional，然后使用 orElse(0) 把 null 替换为默认值再进行 +1 操作。对于 String 和字面","date":"0001-01-01","objectID":"/11%E4%B8%A8%E7%A9%BA%E5%80%BC%E5%A4%84%E7%90%86%E5%88%86%E4%B8%8D%E6%B8%85%E6%A5%9A%E7%9A%84null%E5%92%8C%E6%81%BC%E4%BA%BA%E7%9A%84%E7%A9%BA%E6%8C%87%E9%92%88/:0:0","tags":null,"title":"","uri":"/11%E4%B8%A8%E7%A9%BA%E5%80%BC%E5%A4%84%E7%90%86%E5%88%86%E4%B8%8D%E6%B8%85%E6%A5%9A%E7%9A%84null%E5%92%8C%E6%81%BC%E4%BA%BA%E7%9A%84%E7%A9%BA%E6%8C%87%E9%92%88/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 12 | 异常处理：别让自己在出问题的时候变为瞎子  下载APP   关闭 讲堂 部落 算法训练营 架构师训练营 企业服务 前端训练营 客户端下载 兑换中心 渠道合作 推荐作者 12 | 异常处理：别让自己在出问题的时候变为瞎子 2020-04-04 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长18:25大小12.66M  你好，我是朱晔。今天，我来和你聊聊异常处理容易踩的坑。应用程序避免不了出异常，捕获和处理异常是考验编程功力的一个精细活。一些业务项目中，我曾看到开发同学在开发业务逻辑时不考虑任何异常处理，项目接近完成时再采用“流水线”的方式进行异常处理，也就是统一为所有方法打上 try…catch…捕获所有异常记录日志，有些技巧的同学可能会使用 AOP 来进行类似的“统一异常处理”。其实，这种处理异常的方式非常不可取。那么今天，我就和你分享下不可取的原因、与异常处理相关的坑和最佳实践。捕获和处理异常容易犯的错“统一异常处理”方式正是我要说的第一个错：不在业务代码层面考虑异常处理，仅在框架层面粗犷捕获和处理异常。为了理解错在何处，我们先来看看大多数业务应用都采用的三层架构：Controller 层负责信息收集、参数校验、转换服务层处理的数据适配前端，轻业务逻辑；Service 层负责核心业务逻辑，包括各种外部服务调用、访问数据库、缓存处理、消息处理等；Repository 层负责数据访问实现，一般没有业务逻辑。每层架构的工作性质不同，且从业务性质上异常可能分为业务异常和系统异常两大类，这就决定了很难进行统一的异常处理。我们从底向上看一下三层架构：Repository 层出现异常或许可以忽略，或许可以降级，或许需要转化为一个友好的异常。如果一律捕获异常仅记录日志，很可能业务逻辑已经出错，而用户和程序本身完全感知不到。Service 层往往涉及数据库事务，出现异常同样不适合捕获，否则事务无法自动回滚。此外 Service 层涉及业务逻辑，有些业务逻辑执行中遇到业务异常，可能需要在异常后转入分支业务流程。如果业务异常都被框架捕获了，业务功能就会不正常。如果下层异常上升到 Controller 层还是无法处理的话，Controller 层往往会给予用户友好提示，或是根据每一个 API 的异常表返回指定的异常类型，同样无法对所有异常一视同仁。因此，我不建议在框架层面进行异常的自动、统一处理，尤其不要随意捕获异常。但，框架可以做兜底工作。如果异常上升到最上层逻辑还是无法处理的话，可以以统一的方式进行异常转换，比如通过 @RestControllerAdvice + @ExceptionHandler，来捕获这些“未处理”异常：对于自定义的业务异常，以 Warn 级别的日志记录异常以及当前 URL、执行方法等信息后，提取异常中的错误码和消息等信息，转换为合适的 API 包装体返回给 API 调用方；对于无法处理的系统异常，以 Error 级别的日志记录异常和上下文信息（比如 URL、参数、用户 ID）后，转换为普适的“服务器忙，请稍后再试”异常信息，同样以 API 包装体返回给调用方。比如，下面这段代码的做法：@RestControllerAdvice@Slf4jpublic class RestControllerExceptionHandler { private static int GENERIC_SERVER_ERROR_CODE = 2000; private static String GENERIC_SERVER_ERROR_MESSAGE = \"服务器忙，请稍后再试\"; @ExceptionHandler public APIResponse handle(HttpServletRequest req, HandlerMethod method, Exception ex) { if (ex instanceof BusinessException) { BusinessException exception = (BusinessException) ex; log.warn(String.format(\"访问 %s -\u003e %s 出现业务异常！\", req.getRequestURI(), method.toString()), ex); return new APIResponse(false, null, exception.getCode(), exception.getMessage()); } else { log.error(String.format(\"访问 %s -\u003e %s 出现系统异常！\", req.getRequestURI(), method.toString()), ex); return new APIResponse(false, null, GENERIC_SERVER_ERROR_CODE, GENERIC_SERVER_ERROR_MESSAGE); } }}出现运行时系统异常后，异常处理程序会直接把异常转换为 JSON 返回给调用方：要做得更好，你可以把相关出入参、用户信息在脱敏后记录到日志中，方便出现问题时根据上下文进一步排查。第二个错，捕获了异常后直接生吞。在任何时候，我们捕获了异常都不应该生吞，也就是直接丢弃异常不记录、不抛出。这样的处理方式还不如不捕获异常，因为被生吞掉的异常一旦导致 Bug，就很难在程序中找到蛛丝马迹，使得 Bug 排查工作难上加难。通常情况下，生吞异常的原因，可能是不希望自己的方法抛出受检异常，只是为了把异常“处理掉”而捕获并生吞异常，也可能是想当然地认为异常并不重要或不可能产生。但不管是什么原因，不管是你认为多么不重要的异常，都不应该生吞，哪怕是一个日志也好。第三个错，丢弃异常的原始信息。我们来看两个不太合适的异常处理方式，虽然没有完全生吞异常，但也丢失了宝贵的异常信息。比如有这么一个会抛出受检异常的方法 readFile：private void readFile() throws IOException { Files.readAllLines(Paths.get(\"a_file\"));}像这样调用 readFile 方法，捕获异常后，完全不记录原始异常，直接抛出一个转换后异常，导致出了问题不知道 IOException 具体是哪里引起的：@GetMapping(\"wrong1\")public void wrong1(){ try { readFile(); } catch (IOException e) { //原始异常信息丢失 throw new RuntimeException(\"系统忙请稍后再试\"); }}或者是这样，只记录了异常消息，却丢失了异常的类型、栈等重要信息：catch (IOException e) { //只保留了异常消息，栈没有记录 log.error(\"文件读取错误, {}\", e.getMessage()); throw new RuntimeException(\"系统忙请稍后再试\");}留下的日志是这样的，看完一脸茫然，只知道文件读取错误的文件名，至于为什么读取错误、是不存在还是没权限，完全不知道。[12:57:19.746] [http-nio-45678-exec-1] [ERROR] [.g.t.c.e.d.HandleExceptionController:35 ] - 文件读取错误, a_file这两种处理方式都不太合理，可以改为如下方式：catch (IOException e) { log.error(\"文件读取错误\", e); throw new RuntimeException(\"系统忙请稍后再试\");}或者，把原始异常作为转换后新异常的 cause，原始异常信息同样不会丢：catch (IOException e) { throw new RuntimeException(\"系统忙请稍后再试\", e);}其实，JDK 内部也会犯类似的错。之前我遇到一个使用 JDK10 的应用偶发启动失败的案例，日志中可以看到出现类似的错误信息：Caused by: java.lang.SecurityException: Couldn't parse jurisdiction policy files in: unlimited at java.base/javax.crypto.JceSecurity.setupJurisdictionPolicies(JceSecurity.java:355) at java.base/javax.crypto.JceSecurity.access$000(JceSecurity.java:73) at java.base/javax.crypto.JceSecurity$1.run(JceSecurity.java:109) at java.base/javax.crypto.JceSecurity$1.run(JceSecurity.java:106) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.crypto.JceSecurity.\u003cclinit\u003e(JceSecurity.java:105) ... 20 more查看 JDK JceSecurity 类 setupJurisdict","date":"0001-01-01","objectID":"/12%E4%B8%A8%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E5%88%AB%E8%AE%A9%E8%87%AA%E5%B7%B1%E5%9C%A8%E5%87%BA%E9%97%AE%E9%A2%98%E7%9A%84%E6%97%B6%E5%80%99%E5%8F%98%E4%B8%BA%E7%9E%8E%E5%AD%90/:0:0","tags":null,"title":"","uri":"/12%E4%B8%A8%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E5%88%AB%E8%AE%A9%E8%87%AA%E5%B7%B1%E5%9C%A8%E5%87%BA%E9%97%AE%E9%A2%98%E7%9A%84%E6%97%B6%E5%80%99%E5%8F%98%E4%B8%BA%E7%9E%8E%E5%AD%90/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 13 | 日志：日志记录真没你想象的那么简单  下载APP   关闭 讲堂 部落 算法训练营 架构师训练营 企业服务 前端训练营 客户端下载 兑换中心 渠道合作 推荐作者 13 | 日志：日志记录真没你想象的那么简单 2020-04-07 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长22:28大小20.59M  你好，我是朱晔。今天，我和你分享的是，记录日志可能会踩的坑。一些同学可能要说了，记录日志还不简单，无非是几个常用的 API 方法，比如 debug、info、warn、error；但我就见过不少坑都是记录日志引起的，容易出错主要在于三个方面：日志框架众多，不同的类库可能会使用不同的日志框架，如何兼容是一个问题。配置复杂且容易出错。日志配置文件通常很复杂，因此有些开发同学会从其他项目或者网络上复制一份配置文件，但却不知道如何修改，甚至是胡乱修改，造成很多问题。比如，重复记录日志的问题、同步日志的性能问题、异步记录的错误配置问题。日志记录本身就有些误区，比如没考虑到日志内容获取的代价、胡乱使用日志级别等。Logback、Log4j、Log4j2、commons-logging、JDK 自带的 java.util.logging 等，都是 Java 体系的日志框架，确实非常多。而不同的类库，还可能选择使用不同的日志框架。这样一来，日志的统一管理就变得非常困难。为了解决这个问题，就有了 SLF4J（Simple Logging Facade For Java），如下图所示：SLF4J 实现了三种功能：一是提供了统一的日志门面 API，即图中紫色部分，实现了中立的日志记录 API。二是桥接功能，即图中蓝色部分，用来把各种日志框架的 API（图中绿色部分）桥接到 SLF4J API。这样一来，即便你的程序中使用了各种日志 API 记录日志，最终都可以桥接到 SLF4J 门面 API。三是适配功能，即图中红色部分，可以实现 SLF4J API 和实际日志框架（图中灰色部分）的绑定。SLF4J 只是日志标准，我们还是需要一个实际的日志框架。日志框架本身没有实现 SLF4J API，所以需要有一个前置转换。Logback 就是按照 SLF4J API 标准实现的，因此不需要绑定模块做转换。需要理清楚的是，虽然我们可以使用 log4j-over-slf4j 来实现 Log4j 桥接到 SLF4J，也可以使用 slf4j-log4j12 实现 SLF4J 适配到 Log4j，也把它们画到了一列，但是它不能同时使用它们，否则就会产生死循环。jcl 和 jul 也是同样的道理。虽然图中有 4 个灰色的日志实现框架，但我看到的业务系统使用最广泛的是 Logback 和 Log4j，它们是同一人开发的。Logback 可以认为是 Log4j 的改进版本，我更推荐使用。所以，关于日志框架配置的案例，我都会围绕 Logback 展开。Spring Boot 是目前最流行的 Java 框架，它的日志框架也用的是 Logback。那，为什么我们没有手动引入 Logback 的包，就可以直接使用 Logback 了呢？查看 Spring Boot 的 Maven 依赖树，可以发现 spring-boot-starter 模块依赖了 spring-boot-starter-logging 模块，而 spring-boot-starter-logging 模块又帮我们自动引入了 logback-classic（包含了 SLF4J 和 Logback 日志框架）和 SLF4J 的一些适配器。其中，log4j-to-slf4j 用于实现 Log4j2 API 到 SLF4J 的桥接，jul-to-slf4j 则是实现 java.util.logging API 到 SLF4J 的桥接：接下来，我就用几个实际的案例和你说说日志配置和记录这两大问题，顺便以 Logback 为例复习一下常见的日志配置。为什么我的日志会重复记录？日志重复记录在业务上非常常见，不但给查看日志和统计工作带来不必要的麻烦，还会增加磁盘和日志收集系统的负担。接下来，我和你分享两个重复记录的案例，同时帮助你梳理 Logback 配置的基本结构。第一个案例是，logger 配置继承关系导致日志重复记录。首先，定义一个方法实现 debug、info、warn 和 error 四种日志的记录：@Log4j2@RequestMapping(\"logging\")@RestControllerpublic class LoggingController { @GetMapping(\"log\") public void log() { log.debug(\"debug\"); log.info(\"info\"); log.warn(\"warn\"); log.error(\"error\"); }}然后，使用下面的 Logback 配置：第 11 和 12 行设置了全局的日志级别为 INFO，日志输出使用 CONSOLE Appender。第 3 到 7 行，首先将 CONSOLE Appender 定义为 ConsoleAppender，也就是把日志输出到控制台（System.out/System.err）；然后通过 PatternLayout 定义了日志的输出格式。关于格式化字符串的各种使用方式，你可以进一步查阅官方文档。第 8 到 10 行实现了一个 Logger 配置，将应用包的日志级别设置为 DEBUG、日志输出同样使用 CONSOLE Appender。\u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e\u003cconfiguration\u003e \u003cappender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"\u003e \u003clayout class=\"ch.qos.logback.classic.PatternLayout\"\u003e \u003cpattern\u003e[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%thread] [%-5level] [%logger{40}:%line] - %msg%n\u003c/pattern\u003e \u003c/layout\u003e \u003c/appender\u003e \u003clogger name=\"org.geekbang.time.commonmistakes.logging\" level=\"DEBUG\"\u003e \u003cappender-ref ref=\"CONSOLE\"/\u003e \u003c/logger\u003e \u003croot level=\"INFO\"\u003e \u003cappender-ref ref=\"CONSOLE\"/\u003e \u003c/root\u003e\u003c/configuration\u003e这段配置看起来没啥问题，但执行方法后出现了日志重复记录的问题：从配置文件的第 9 和 12 行可以看到，CONSOLE 这个 Appender 同时挂载到了两个 Logger 上，一个是我们定义的，一个是，由于我们定义的继承自，所以同一条日志既会通过 logger 记录，也会发送到 root 记录，因此应用 package 下的日志出现了重复记录。后来我了解到，这个同学如此配置的初衷是实现自定义的 logger 配置，让应用内的日志暂时开启 DEBUG 级别的日志记录。其实，他完全不需要重复挂载 Appender，去掉下挂载的 Appender 即可：\u003clogger name=\"org.geekbang.time.commonmistakes.logging\" level=\"DEBUG\"/\u003e如果自定义的需要把日志输出到不同的 Appender，比如将应用的日志输出到文件 app.log、把其他框架的日志输出到控制台，可以设置的 additivity 属性为 false，这样就不会继承的 Appender 了：\u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e\u003cconfiguration\u003e \u003cappender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"\u003e \u003cfile\u003eapp.log\u003c/file\u003e \u003cencoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"\u003e \u003cpattern\u003e[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%thread] [%-5level] [%logger{40}:%line] - %msg%n\u003c/pattern\u003e \u003c/encoder\u003e \u003c/appender\u003e \u003cappender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"\u003e \u003clayout class=\"ch.qos.logback.classic.PatternLayout\"\u003e \u003cpattern\u003e[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%thread] [%-5level] [%logger{40}:%line] - %msg%n\u003c/pattern\u003e \u003c/layout\u003e \u003c/appender\u003e \u003clogger name=\"org.geekbang.time.commonmistakes.logging\" level=\"DEBUG\" additivity=\"false\"\u003e \u003cappender-ref ref=\"FI","date":"0001-01-01","objectID":"/13%E4%B8%A8%E6%97%A5%E5%BF%97%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%E7%9C%9F%E6%B2%A1%E4%BD%A0%E6%83%B3%E8%B1%A1%E7%9A%84%E9%82%A3%E4%B9%88%E7%AE%80%E5%8D%95/:0:0","tags":null,"title":"","uri":"/13%E4%B8%A8%E6%97%A5%E5%BF%97%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%E7%9C%9F%E6%B2%A1%E4%BD%A0%E6%83%B3%E8%B1%A1%E7%9A%84%E9%82%A3%E4%B9%88%E7%AE%80%E5%8D%95/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 14 | 文件IO：实现高效正确的文件读写并非易事  下载APP   关闭 讲堂 学习路径 部落 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 14 | 文件IO：实现高效正确的文件读写并非易事 2020-04-11 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长16:11大小14.84M  你好，我是朱晔。今天，我们来聊聊如何实现高效、正确的文件操作。随着数据库系统的成熟和普及，需要直接做文件 IO 操作的需求越来越少，这就导致我们对相关 API 不够熟悉，以至于遇到类似文件导出、三方文件对账等需求时，只能临时抱佛脚，随意搜索一些代码完成需求，出现性能问题或者 Bug 后不知从何处入手。今天这篇文章，我就会从字符编码、缓冲区和文件句柄释放这 3 个常见问题出发，和你分享如何解决与文件操作相关的性能问题或者 Bug。如果你对文件操作相关的 API 不够熟悉，可以查看Oracle 官网的介绍。文件读写需要确保字符编码一致有一个项目需要读取三方的对账文件定时对账，原先一直是单机处理的，没什么问题。后来为了提升性能，使用双节点同时处理对账，每一个节点处理部分对账数据，但新增的节点在处理文件中中文的时候总是读取到乱码。程序代码都是一致的，为什么老节点就不会有问题呢？我们知道，这很可能是写代码时没有注意编码问题导致的。接下来，我们就分析下这个问题吧。为模拟这个场景，我们使用 GBK 编码把“你好 hi”写入一个名为 hello.txt 的文本文件，然后直接以字节数组形式读取文件内容，转换为十六进制字符串输出到日志中：Files.deleteIfExists(Paths.get(\"hello.txt\"));Files.write(Paths.get(\"hello.txt\"), \"你好hi\".getBytes(Charset.forName(\"GBK\")));log.info(\"bytes:{}\", Hex.encodeHexString(Files.readAllBytes(Paths.get(\"hello.txt\"))).toUpperCase());输出如下：13:06:28.955 [main] INFO org.geekbang.time.commonmistakes.io.demo3.FileBadEncodingIssueApplication - bytes:C4E3BAC36869虽然我们打开文本文件时看到的是“你好 hi”，但不管是什么文字，计算机中都是按照一定的规则将其以二进制保存的。这个规则就是字符集，字符集枚举了所有支持的字符映射成二进制的映射表。在处理文件读写的时候，如果是在字节层面进行操作，那么不会涉及字符编码问题；而如果需要在字符层面进行读写的话，就需要明确字符的编码方式也就是字符集了。当时出现问题的文件读取代码是这样的：char[] chars = new char[10];String content = \"\";try (FileReader fileReader = new FileReader(\"hello.txt\")) { int count; while ((count = fileReader.read(chars)) != -1) { content += new String(chars, 0, count); }}log.info(\"result:{}\", content);可以看到，是使用了 FileReader 类以字符方式进行文件读取，日志中读取出来的“你好”变为了乱码：13:06:28.961 [main] INFO org.geekbang.time.commonmistakes.io.demo3.FileBadEncodingIssueApplication - result:���hi显然，这里并没有指定以什么字符集来读取文件中的字符。查看JDK 文档可以发现，FileReader 是以当前机器的默认字符集来读取文件的，如果希望指定字符集的话，需要直接使用 InputStreamReader 和 FileInputStream。到这里我们就明白了，FileReader 虽然方便但因为使用了默认字符集对环境产生了依赖，这就是为什么老的机器上程序可以正常运作，在新节点上读取中文时却产生了乱码。那，怎么确定当前机器的默认字符集呢？写一段代码输出当前机器的默认字符集，以及 UTF-8 方式编码的“你好 hi”的十六进制字符串：log.info(\"charset: {}\", Charset.defaultCharset());Files.write(Paths.get(\"hello2.txt\"), \"你好hi\".getBytes(Charsets.UTF_8));log.info(\"bytes:{}\", Hex.encodeHexString(Files.readAllBytes(Paths.get(\"hello2.txt\"))).toUpperCase());输出结果如下：13:06:28.961 [main] INFO org.geekbang.time.commonmistakes.io.demo3.FileBadEncodingIssueApplication - charset: UTF-813:06:28.962 [main] INFO org.geekbang.time.commonmistakes.io.demo3.FileBadEncodingIssueApplication - bytes:E4BDA0E5A5BD6869可以看到，当前机器默认字符集是 UTF-8，当然无法读取 GBK 编码的汉字。UTF-8 编码的“你好”的十六进制是 E4BDA0E5A5BD，每一个汉字需要三个字节；而 GBK 编码的汉字，每一个汉字两个字节。字节长度都不一样，以 GBK 编码后保存的汉字，以 UTF8 进行解码读取，必然不会成功。定位到问题后，修复就很简单了。按照文档所说，直接使用 FileInputStream 拿文件流，然后使用 InputStreamReader 读取字符流，并指定字符集为 GBK：private static void right1() throws IOException { char[] chars = new char[10]; String content = \"\"; try (FileInputStream fileInputStream = new FileInputStream(\"hello.txt\"); InputStreamReader inputStreamReader = new InputStreamReader(fileInputStream, Charset.forName(\"GBK\"))) { int count; while ((count = inputStreamReader.read(chars)) != -1) { content += new String(chars, 0, count); } } log.info(\"result: {}\", content);}从日志中看到，修复后的代码正确读取到了“你好 Hi”。13:06:28.963 [main] INFO org.geekbang.time.commonmistakes.io.demo3.FileBadEncodingIssueApplication - result: 你好hi如果你觉得这种方式比较麻烦的话，使用 JDK1.7 推出的 Files 类的 readAllLines 方法，可以很方便地用一行代码完成文件内容读取：log.info(\"result: {}\", Files.readAllLines(Paths.get(\"hello.txt\"), Charset.forName(\"GBK\")).stream().findFirst().orElse(\"\"));但这种方式有个问题是，读取超出内存大小的大文件时会出现 OOM。为什么呢？打开 readAllLines 方法的源码可以看到，readAllLines 读取文件所有内容后，放到一个 List\u003cString\u003e 中返回，如果内存无法容纳这个 List，就会 OOM：public static List\u003cString\u003e readAllLines(Path path, Charset cs) throws IOException { try (BufferedReader reader = newBufferedReader(path, cs)) { List\u003cString\u003e result = new ArrayList\u003c\u003e(); for (;;) { String line = reader.readLine(); if (line == null) break; result.add(line); } return result; }}那么，有没有办法实现按需的流式读取呢？比如，需要消费某行数据时再读取，而不是把整个文件一次性读取到内存？当然有，解决方案就是 File 类的 lines 方法。接下来，我就与你说说使用 lines 方法时需要注意的一些问题。使用 Files 类静态方法进行文件操作注意释放文件句柄与 readAllLines 方法返回 List\u003cString\u003e 不同，lines 方法返回的是","date":"0001-01-01","objectID":"/14%E4%B8%A8%E6%96%87%E4%BB%B6io%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%95%88%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E5%B9%B6%E9%9D%9E%E6%98%93%E4%BA%8B/:0:0","tags":null,"title":"","uri":"/14%E4%B8%A8%E6%96%87%E4%BB%B6io%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%95%88%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E5%B9%B6%E9%9D%9E%E6%98%93%E4%BA%8B/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 15 | 序列化：一来一回你还是原来的你吗？  下载APP   关闭 讲堂 部落 前端训练营 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 15 | 序列化：一来一回你还是原来的你吗？ 2020-04-14 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长22:20大小20.45M  你好，我是朱晔。今天，我来和你聊聊序列化相关的坑和最佳实践。序列化是把对象转换为字节流的过程，以方便传输或存储。反序列化，则是反过来把字节流转换为对象的过程。在介绍文件 IO的时候，我提到字符编码是把字符转换为二进制的过程，至于怎么转换需要由字符集制定规则。同样地，对象的序列化和反序列化，也需要由序列化算法制定规则。关于序列化算法，几年前常用的有 JDK（Java）序列化、XML 序列化等，但前者不能跨语言，后者性能较差（时间空间开销大）；现在 RESTful 应用最常用的是 JSON 序列化，追求性能的 RPC 框架（比如 gRPC）使用 protobuf 序列化，这 2 种方法都是跨语言的，而且性能不错，应用广泛。在架构设计阶段，我们可能会重点关注算法选型，在性能、易用性和跨平台性等中权衡，不过这里的坑比较少。通常情况下，序列化问题常见的坑会集中在业务场景中，比如 Redis、参数和响应序列化反序列化。今天，我们就一起聊聊开发中序列化常见的一些坑吧。序列化和反序列化需要确保算法一致业务代码中涉及序列化时，很重要的一点是要确保序列化和反序列化的算法一致性。有一次我要排查缓存命中率问题，需要运维同学帮忙拉取 Redis 中的 Key，结果他反馈 Redis 中存的都是乱码，怀疑 Redis 被攻击了。其实呢，这个问题就是序列化算法导致的，我们来看下吧。在这个案例中，开发同学使用 RedisTemplate 来操作 Redis 进行数据缓存。因为相比于 Jedis，使用 Spring 提供的 RedisTemplate 操作 Redis，除了无需考虑连接池、更方便外，还可以与 Spring Cache 等其他组件无缝整合。如果使用 Spring Boot 的话，无需任何配置就可以直接使用。数据（包含 Key 和 Value）要保存到 Redis，需要经过序列化算法来序列化成字符串。虽然 Redis 支持多种数据结构，比如 Hash，但其每一个 field 的 Value 还是字符串。如果 Value 本身也是字符串的话，能否有便捷的方式来使用 RedisTemplate，而无需考虑序列化呢？其实是有的，那就是 StringRedisTemplate。那 StringRedisTemplate 和 RedisTemplate 的区别是什么呢？开头提到的乱码又是怎么回事呢？带着这些问题让我们来研究一下吧。写一段测试代码，在应用初始化完成后向 Redis 设置两组数据，第一次使用 RedisTemplate 设置 Key 为 redisTemplate、Value 为 User 对象，第二次使用 StringRedisTemplate 设置 Key 为 stringRedisTemplate、Value 为 JSON 序列化后的 User 对象：@Autowiredprivate RedisTemplate redisTemplate;@Autowiredprivate StringRedisTemplate stringRedisTemplate;@Autowiredprivate ObjectMapper objectMapper;@PostConstructpublic void init() throws JsonProcessingException { redisTemplate.opsForValue().set(\"redisTemplate\", new User(\"zhuye\", 36)); stringRedisTemplate.opsForValue().set(\"stringRedisTemplate\", objectMapper.writeValueAsString(new User(\"zhuye\", 36)));}如果你认为，StringRedisTemplate 和 RedisTemplate 的区别，无非是读取的 Value 是 String 和 Object，那就大错特错了，因为使用这两种方式存取的数据完全无法通用。我们做个小实验，通过 RedisTemplate 读取 Key 为 stringRedisTemplate 的 Value，使用 StringRedisTemplate 读取 Key 为 redisTemplate 的 Value：log.info(\"redisTemplate get {}\", redisTemplate.opsForValue().get(\"stringRedisTemplate\"));log.info(\"stringRedisTemplate get {}\", stringRedisTemplate.opsForValue().get(\"redisTemplate\"));结果是，两次都无法读取到 Value：[11:49:38.478] [http-nio-45678-exec-1] [INFO ] [.t.c.s.demo1.RedisTemplateController:38 ] - redisTemplate get null[11:49:38.481] [http-nio-45678-exec-1] [INFO ] [.t.c.s.demo1.RedisTemplateController:39 ] - stringRedisTemplate get null通过 redis-cli 客户端工具连接到 Redis，你会发现根本就没有叫作 redisTemplate 的 Key，所以 StringRedisTemplate 无法查到数据：查看 RedisTemplate 的源码发现，默认情况下 RedisTemplate 针对 Key 和 Value 使用了 JDK 序列化：public void afterPropertiesSet() { ... if (defaultSerializer == null) { defaultSerializer = new JdkSerializationRedisSerializer( classLoader != null ? classLoader : this.getClass().getClassLoader()); } if (enableDefaultSerializer) { if (keySerializer == null) { keySerializer = defaultSerializer; defaultUsed = true; } if (valueSerializer == null) { valueSerializer = defaultSerializer; defaultUsed = true; } if (hashKeySerializer == null) { hashKeySerializer = defaultSerializer; defaultUsed = true; } if (hashValueSerializer == null) { hashValueSerializer = defaultSerializer; defaultUsed = true; } } ...}redis-cli 看到的类似一串乱码的\"\\xac\\xed\\x00\\x05t\\x00\\rredisTemplate\"字符串，其实就是字符串 redisTemplate 经过 JDK 序列化后的结果。这就回答了之前提到的乱码问题。而 RedisTemplate 尝试读取 Key 为 stringRedisTemplate 数据时，也会对这个字符串进行 JDK 序列化处理，所以同样无法读取到数据。而 StringRedisTemplate 对于 Key 和 Value，使用的是 String 序列化方式，Key 和 Value 只能是 String：public class StringRedisTemplate extends RedisTemplate\u003cString, String\u003e { public StringRedisTemplate() { setKeySerializer(RedisSerializer.string()); setValueSerializer(RedisSerializer.string()); setHashKeySerializer(RedisSerializer.string()); setHashValueSerializer(RedisSerializer.string()); }}public class StringRedisSerializer implements RedisSerializer\u003cString\u003e { @Override public String deserialize(@Nullable byte[] bytes) { return (bytes == null ? null : new String(bytes, charset)); } @Override publi","date":"0001-01-01","objectID":"/15%E4%B8%A8%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%80%E6%9D%A5%E4%B8%80%E5%9B%9E%E4%BD%A0%E8%BF%98%E6%98%AF%E5%8E%9F%E6%9D%A5%E7%9A%84%E4%BD%A0%E5%90%97/:0:0","tags":null,"title":"","uri":"/15%E4%B8%A8%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%80%E6%9D%A5%E4%B8%80%E5%9B%9E%E4%BD%A0%E8%BF%98%E6%98%AF%E5%8E%9F%E6%9D%A5%E7%9A%84%E4%BD%A0%E5%90%97/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 16 | 用好Java 8的日期时间类，少踩一些“老三样”的坑  防止断更 请务必加首发微信：17161 43665   关闭 讲堂 部落 前端训练营 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 16 | 用好Java 8的日期时间类，少踩一些“老三样”的坑 2020-04-16 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长21:28大小19.66M  你好，我是朱晔。今天，我来和你说说恼人的时间错乱问题。在 Java 8 之前，我们处理日期时间需求时，使用 Date、Calender 和 SimpleDateFormat，来声明时间戳、使用日历处理日期和格式化解析日期时间。但是，这些类的 API 的缺点比较明显，比如可读性差、易用性差、使用起来冗余繁琐，还有线程安全问题。因此，Java 8 推出了新的日期时间类。每一个类功能明确清晰、类之间协作简单、API 定义清晰不踩坑，API 功能强大无需借助外部工具类即可完成操作，并且线程安全。但是，Java 8 刚推出的时候，诸如序列化、数据访问等类库都还不支持 Java 8 的日期时间类型，需要在新老类中来回转换。比如，在业务逻辑层使用 LocalDateTime，存入数据库或者返回前端的时候还要切换回 Date。因此，很多同学还是选择使用老的日期时间类。现在几年时间过去了，几乎所有的类库都支持了新日期时间类型，使用起来也不会有来回切换等问题了。但，很多代码中因为还是用的遗留的日期时间类，因此出现了很多时间错乱的错误实践。比如，试图通过随意修改时区，使读取到的数据匹配当前时钟；再比如，试图直接对读取到的数据做加、减几个小时的操作，来“修正数据”。今天，我就重点与你分析下时间错乱问题背后的原因，看看使用遗留的日期时间类，来处理日期时间初始化、格式化、解析、计算等可能会遇到的问题，以及如何使用新日期时间类来解决。初始化日期时间我们先从日期时间的初始化看起。如果要初始化一个 2019 年 12 月 31 日 11 点 12 分 13 秒这样的时间，可以使用下面的两行代码吗？Date date = new Date(2019, 12, 31, 11, 12, 13);System.out.println(date);可以看到，输出的时间是 3029 年 1 月 31 日 11 点 12 分 13 秒：Sat Jan 31 11:12:13 CST 3920相信看到这里，你会说这是新手才会犯的低级错误：年应该是和 1900 的差值，月应该是从 0 到 11 而不是从 1 到 12。Date date = new Date(2019 - 1900, 11, 31, 11, 12, 13);你说的没错，但更重要的问题是，当有国际化需求时，需要使用 Calendar 类来初始化时间。使用 Calendar 改造之后，初始化时年参数直接使用当前年即可，不过月需要注意是从 0 到 11。当然，你也可以直接使用 Calendar.DECEMBER 来初始化月份，更不容易犯错。为了说明时区的问题，我分别使用当前时区和纽约时区初始化了两次相同的日期：Calendar calendar = Calendar.getInstance();calendar.set(2019, 11, 31, 11, 12, 13);System.out.println(calendar.getTime());Calendar calendar2 = Calendar.getInstance(TimeZone.getTimeZone(\"America/New_York\"));calendar2.set(2019, Calendar.DECEMBER, 31, 11, 12, 13);System.out.println(calendar2.getTime());输出显示了两个时间，说明时区产生了作用。但，我们更习惯年 / 月 / 日 时: 分: 秒这样的日期时间格式，对现在输出的日期格式还不满意：Tue Dec 31 11:12:13 CST 2019Wed Jan 01 00:12:13 CST 2020那，时区的问题是怎么回事，又怎么格式化需要输出的日期时间呢？接下来，我就与你逐一分析下这两个问题。“恼人”的时区问题我们知道，全球有 24 个时区，同一个时刻不同时区（比如中国上海和美国纽约）的时间是不一样的。对于需要全球化的项目，如果初始化时间时没有提供时区，那就不是一个真正意义上的时间，只能认为是我看到的当前时间的一个表示。关于 Date 类，我们要有两点认识：一是，Date 并无时区问题，世界上任何一台计算机使用 new Date() 初始化得到的时间都一样。因为，Date 中保存的是 UTC 时间，UTC 是以原子钟为基础的统一时间，不以太阳参照计时，并无时区划分。二是，Date 中保存的是一个时间戳，代表的是从 1970 年 1 月 1 日 0 点（Epoch 时间）到现在的毫秒数。尝试输出 Date(0)：System.out.println(new Date(0));System.out.println(TimeZone.getDefault().getID() + \":\" + TimeZone.getDefault().getRawOffset()/3600);我得到的是 1970 年 1 月 1 日 8 点。因为我机器当前的时区是中国上海，相比 UTC 时差 +8 小时：Thu Jan 01 08:00:00 CST 1970Asia/Shanghai:8对于国际化（世界各国的人都在使用）的项目，处理好时间和时区问题首先就是要正确保存日期时间。这里有两种保存方式：方式一，以 UTC 保存，保存的时间没有时区属性，是不涉及时区时间差问题的世界统一时间。我们通常说的时间戳，或 Java 中的 Date 类就是用的这种方式，这也是推荐的方式。方式二，以字面量保存，比如年 / 月 / 日 时: 分: 秒，一定要同时保存时区信息。只有有了时区信息，我们才能知道这个字面量时间真正的时间点，否则它只是一个给人看的时间表示，只在当前时区有意义。Calendar 是有时区概念的，所以我们通过不同的时区初始化 Calendar，得到了不同的时间。正确保存日期时间之后，就是正确展示，即我们要使用正确的时区，把时间点展示为符合当前时区的时间表示。到这里，我们就能理解为什么会有所谓的“时间错乱”问题了。接下来，我再通过实际案例分析一下，从字面量解析成时间和从时间格式化为字面量这两类问题。第一类是，对于同一个时间表示，比如 2020-01-02 22:00:00，不同时区的人转换成 Date 会得到不同的时间（时间戳）：String stringDate = \"2020-01-02 22:00:00\";SimpleDateFormat inputFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");//默认时区解析时间表示Date date1 = inputFormat.parse(stringDate);System.out.println(date1 + \":\" + date1.getTime());//纽约时区解析时间表示inputFormat.setTimeZone(TimeZone.getTimeZone(\"America/New_York\"));Date date2 = inputFormat.parse(stringDate);System.out.println(date2 + \":\" + date2.getTime());可以看到，把 2020-01-02 22:00:00 这样的时间表示，对于当前的上海时区和纽约时区，转化为 UTC 时间戳是不同的时间：Thu Jan 02 22:00:00 CST 2020:1577973600000Fri Jan 03 11:00:00 CST 2020:1578020400000这正是 UTC 的意义，并不是时间错乱。对于同一个本地时间的表示，不同时区的人解析得到的 UTC 时间一定是不同的，反过来不同的本地时间可能对应同一个 UTC。第二类问题是，格式化后出现的错乱，即同一个 Date，在不同的时区下格式化得到不同的时间表示。比如，在我的当前时区和纽约时区格式化 2020-01-02 22:00:00：String stringDate = \"2020-01-02 22:00:00\";SimpleDateFormat inputFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");//同一DateDate date = inputFormat.parse(stringDate);//默认时区格式化输出：System.out.println(new SimpleDateFormat(\"[yyyy-MM-dd HH:mm:ss Z]\").format(date));//纽约时区格式化输出TimeZone.setDefault(TimeZone.getTimeZone(\"America/New_York\"));System.out.println(new SimpleDateFormat(\"[yyyy-MM-dd HH:mm:ss Z]\").format(date));输出如下，我当前时区","date":"0001-01-01","objectID":"/16%E4%B8%A8%E7%94%A8%E5%A5%BDjava8%E7%9A%84%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E7%B1%BB%E5%B0%91%E8%B8%A9%E4%B8%80%E4%BA%9B%E8%80%81%E4%B8%89%E6%A0%B7%E7%9A%84%E5%9D%91/:0:0","tags":null,"title":"","uri":"/16%E4%B8%A8%E7%94%A8%E5%A5%BDjava8%E7%9A%84%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E7%B1%BB%E5%B0%91%E8%B8%A9%E4%B8%80%E4%BA%9B%E8%80%81%E4%B8%89%E6%A0%B7%E7%9A%84%E5%9D%91/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 17 | 别以为“自动挡”就不可能出现OOM  防止断更 请务必加首发微信：17161 43665   关闭 讲堂 部落 前端训练营 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 17 | 别以为“自动挡”就不可能出现OOM 2020-04-18 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长17:52大小16.38M  你好，我是朱晔。今天，我要和你分享的主题是，别以为“自动挡”就不可能出现 OOM。这里的“自动挡”，是我对 Java 自动垃圾收集器的戏称。的确，经过这么多年的发展，Java 的垃圾收集器已经非常成熟了。有了自动垃圾收集器，绝大多数情况下我们写程序时可以专注于业务逻辑，无需过多考虑对象的分配和释放，一般也不会出现 OOM。但，内存空间始终是有限的，Java 的几大内存区域始终都有 OOM 的可能。相应地，Java 程序的常见 OOM 类型，可以分为堆内存的 OOM、栈 OOM、元空间 OOM、直接内存 OOM 等。几乎每一种 OOM 都可以使用几行代码模拟，市面上也有很多资料在堆、元空间、直接内存中分配超大对象或是无限分配对象，尝试创建无限个线程或是进行方法无限递归调用来模拟。但值得注意的是，我们的业务代码并不会这么干。所以今天，我会从内存分配意识的角度通过一些案例，展示业务代码中可能导致 OOM 的一些坑。这些坑，或是因为我们意识不到对象的分配，或是因为不合理的资源使用，或是没有控制缓存的数据量等。在第 3 讲介绍线程时，我们已经看到了两种 OOM 的情况，一是因为使用无界队列导致的堆 OOM，二是因为使用没有最大线程数量限制的线程池导致无限创建线程的 OOM。接下来，我们再一起看看，在写业务代码的过程中，还有哪些意识上的疏忽可能会导致 OOM。太多份相同的对象导致 OOM我要分享的第一个案例是这样的。有一个项目在内存中缓存了全量用户数据，在搜索用户时可以直接从缓存中返回用户信息。现在为了改善用户体验，需要实现输入部分用户名自动在下拉框提示补全用户名的功能（也就是所谓的自动完成功能）。在第 10 讲介绍集合时，我提到对于这种快速检索的需求，最好使用 Map 来实现，会比直接从 List 搜索快得多。为实现这个功能，我们需要一个 HashMap 来存放这些用户数据，Key 是用户姓名索引，Value 是索引下对应的用户列表。举一个例子，如果有两个用户 aa 和 ab，那么 Key 就有三个，分别是 a、aa 和 ab。用户输入字母 a 时，就能从 Value 这个 List 中拿到所有字母 a 开头的用户，即 aa 和 ab。在代码中，在数据库中存入 1 万个测试用户，用户名由 a~j 这 6 个字母随机构成，然后把每一个用户名的前 1 个字母、前 2 个字母以此类推直到完整用户名作为 Key 存入缓存中，缓存的 Value 是一个 UserDTO 的 List，存放的是所有相同的用户名索引，以及对应的用户信息：//自动完成的索引，Key是用户输入的部分用户名，Value是对应的用户数据private ConcurrentHashMap\u003cString, List\u003cUserDTO\u003e\u003e autoCompleteIndex = new ConcurrentHashMap\u003c\u003e();@Autowiredprivate UserRepository userRepository;@PostConstructpublic void wrong() { //先保存10000个用户名随机的用户到数据库中 userRepository.saveAll(LongStream.rangeClosed(1, 10000).mapToObj(i -\u003e new UserEntity(i, randomName())).collect(Collectors.toList())); //从数据库加载所有用户 userRepository.findAll().forEach(userEntity -\u003e { int len = userEntity.getName().length(); //对于每一个用户，对其用户名的前N位进行索引，N可能是1~6六种长度类型 for (int i = 0; i \u003c len; i++) { String key = userEntity.getName().substring(0, i + 1); autoCompleteIndex.computeIfAbsent(key, s -\u003e new ArrayList\u003c\u003e()) .add(new UserDTO(userEntity.getName())); } }); log.info(\"autoCompleteIndex size:{} count:{}\", autoCompleteIndex.size(), autoCompleteIndex.entrySet().stream().map(item -\u003e item.getValue().size()).reduce(0, Integer::sum));}对于每一个用户对象 UserDTO，除了有用户名，我们还加入了 10K 左右的数据模拟其用户信息：@Datapublic class UserDTO { private String name; @EqualsAndHashCode.Exclude private String payload; public UserDTO(String name) { this.name = name; this.payload = IntStream.rangeClosed(1, 10_000) .mapToObj(__ -\u003e \"a\") .collect(Collectors.joining(\"\")); }}运行程序后，日志输出如下：[11:11:22.982] [main] [INFO ] [.t.c.o.d.UsernameAutoCompleteService:37 ] - autoCompleteIndex size:26838 count:60000可以看到，一共有 26838 个索引（也就是所有用户名的 1 位、2 位一直到 6 位有 26838 个组合），HashMap 的 Value，也就是 List一共有 1 万个用户 *6=6 万个 UserDTO 对象。使用内存分析工具 MAT 打开堆 dump 发现，6 万个 UserDTO 占用了约 1.2GB 的内存：看到这里发现，虽然真正的用户只有 1 万个，但因为使用部分用户名作为索引的 Key，导致缓存的 Key 有 26838 个，缓存的用户信息多达 6 万个。如果我们的用户名不是 6 位而是 10 位、20 位，那么缓存的用户信息可能就是 10 万、20 万个，必然会产生堆 OOM。尝试调大用户名的最大长度，重启程序可以看到类似如下的错误：[17:30:29.858] [main] [ERROR] [ringframework.boot.SpringApplication:826 ] - Application run failedorg.springframework.beans.factory.BeanCreationException: Error creating bean with name 'usernameAutoCompleteService': Invocation of init method failed; nested exception is java.lang.OutOfMemoryError: Java heap space我们可能会想当然地认为，数据库中有 1 万个用户，内存中也应该只有 1 万个 UserDTO 对象，但实现的时候每次都会 new 出来 UserDTO 加入缓存，当然在内存中都是新对象。在实际的项目中，用户信息的缓存可能是随着用户输入增量缓存的，而不是像这个案例一样在程序初始化的时候全量缓存，所以问题暴露得不会这么早。知道原因后，解决起来就比较简单了。把所有 UserDTO 先加入 HashSet 中，因为 UserDTO 以 name 来标识唯一性，所以重复用户名会被过滤掉，最终加入 HashSet 的 UserDTO 就不足 1 万个。有了 HashSet 来缓存所有可能的 UserDTO 信息，我们再构建自动完成索引 autoCompleteIndex 这个 HashMap 时，就可以直接从 HashSet 获取所有用户信息来构建了。这样一来，同一个用户名前缀的不同组合（比如用户名为 abc 的用户，a、ab 和 abc 三个 Key）关联到 UserDTO 是同一份：@PostConstructpublic void right() { ... HashSet\u003cUserDTO\u003e cache = userRepository.findAll().stream() .map(item -\u003e new UserDTO(item.getName())) .collect(Collectors.toCollection(HashSet::new)); cache.stream().forEach(userDTO -\u003e { int len = userDTO.getName().length(); for (int i = 0; i \u003c len; i++) { Strin","date":"0001-01-01","objectID":"/17%E4%B8%A8%E5%88%AB%E4%BB%A5%E4%B8%BA%E8%87%AA%E5%8A%A8%E6%8C%A1%E5%B0%B1%E4%B8%8D%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0oom/:0:0","tags":null,"title":"","uri":"/17%E4%B8%A8%E5%88%AB%E4%BB%A5%E4%B8%BA%E8%87%AA%E5%8A%A8%E6%8C%A1%E5%B0%B1%E4%B8%8D%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0oom/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 18 | 当反射、注解和泛型遇到OOP时，会有哪些坑？  下载APP   关闭 讲堂 部落 前端训练营 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 18 | 当反射、注解和泛型遇到OOP时，会有哪些坑？ 2020-04-23 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长16:56大小15.52M  你好，我是朱晔。今天，我们聊聊 Java 高级特性的话题，看看反射、注解和泛型遇到重载和继承时可能会产生的坑。你可能说，业务项目中几乎都是增删改查，用到反射、注解和泛型这些高级特性的机会少之又少，没啥好学的。但我要说的是，只有学好、用好这些高级特性，才能开发出更简洁易读的代码，而且几乎所有的框架都使用了这三大高级特性。比如，要减少重复代码，就得用到反射和注解（详见第 21 讲）。如果你从来没用过反射、注解和泛型，可以先通过官网有一个大概了解：Java Reflection API \u0026 Reflection Tutorials；Annotations \u0026 Lesson: Annotations；Generics \u0026 Lesson: Generics。接下来，我们就通过几个案例，看看这三大特性结合 OOP 使用时会有哪些坑吧。反射调用方法不是以传参决定重载反射的功能包括，在运行时动态获取类和类成员定义，以及动态读取属性调用方法。也就是说，针对类动态调用方法，不管类中字段和方法怎么变动，我们都可以用相同的规则来读取信息和执行方法。因此，几乎所有的 ORM（对象关系映射）、对象映射、MVC 框架都使用了反射。反射的起点是 Class 类，Class 类提供了各种方法帮我们查询它的信息。你可以通过这个文档，了解每一个方法的作用。接下来，我们先看一个反射调用方法遇到重载的坑：有两个叫 age 的方法，入参分别是基本类型 int 和包装类型 Integer。@Slf4jpublic class ReflectionIssueApplication { private void age(int age) { log.info(\"int age = {}\", age); } private void age(Integer age) { log.info(\"Integer age = {}\", age); }}如果不通过反射调用，走哪个重载方法很清晰，比如传入 36 走 int 参数的重载方法，传入 Integer.valueOf(“36”) 走 Integer 重载：ReflectionIssueApplication application = new ReflectionIssueApplication();application.age(36);application.age(Integer.valueOf(\"36\"));但使用反射时的误区是，认为反射调用方法还是根据入参确定方法重载。比如，使用 getDeclaredMethod 来获取 age 方法，然后传入 Integer.valueOf(“36”)：getClass().getDeclaredMethod(\"age\", Integer.TYPE).invoke(this, Integer.valueOf(\"36\"));输出的日志证明，走的是 int 重载方法：14:23:09.801 [main] INFO org.geekbang.time.commonmistakes.advancedfeatures.demo1.ReflectionIssueApplication - int age = 36其实，要通过反射进行方法调用，第一步就是通过方法签名来确定方法。具体到这个案例，getDeclaredMethod 传入的参数类型 Integer.TYPE 代表的是 int，所以实际执行方法时无论传的是包装类型还是基本类型，都会调用 int 入参的 age 方法。把 Integer.TYPE 改为 Integer.class，执行的参数类型就是包装类型的 Integer。这时，无论传入的是 Integer.valueOf(“36”) 还是基本类型的 36：getClass().getDeclaredMethod(\"age\", Integer.class).invoke(this, Integer.valueOf(\"36\"));getClass().getDeclaredMethod(\"age\", Integer.class).invoke(this, 36);都会调用 Integer 为入参的 age 方法：14:25:18.028 [main] INFO org.geekbang.time.commonmistakes.advancedfeatures.demo1.ReflectionIssueApplication - Integer age = 3614:25:18.029 [main] INFO org.geekbang.time.commonmistakes.advancedfeatures.demo1.ReflectionIssueApplication - Integer age = 36现在我们非常清楚了，反射调用方法，是以反射获取方法时传入的方法名称和参数类型来确定调用方法的。接下来，我们再来看一下反射、泛型擦除和继承结合在一起会碰撞出什么坑。泛型经过类型擦除多出桥接方法的坑泛型是一种风格或范式，一般用于强类型程序设计语言，允许开发者使用类型参数替代明确的类型，实例化时再指明具体的类型。它是代码重用的有效手段，允许把一套代码应用到多种数据类型上，避免针对每一种数据类型实现重复的代码。Java 编译器对泛型应用了强大的类型检测，如果代码违反了类型安全就会报错，可以在编译时暴露大多数泛型的编码错误。但总有一部分编码错误，比如泛型类型擦除的坑，在运行时才会暴露。接下来，我就和你分享一个案例吧。有一个项目希望在类字段内容变动时记录日志，于是开发同学就想到定义一个泛型父类，并在父类中定义一个统一的日志记录方法，子类可以通过继承重用这个方法。代码上线后业务没啥问题，但总是出现日志重复记录的问题。开始时，我们怀疑是日志框架的问题，排查到最后才发现是泛型的问题，反复修改多次才解决了这个问题。父类是这样的：有一个泛型占位符 T；有一个 AtomicInteger 计数器，用来记录 value 字段更新的次数，其中 value 字段是泛型 T 类型的，setValue 方法每次为 value 赋值时对计数器进行 +1 操作。我重写了 toString 方法，输出 value 字段的值和计数器的值：class Parent\u003cT\u003e { //用于记录value更新的次数，模拟日志记录的逻辑 AtomicInteger updateCount = new AtomicInteger(); private T value; //重写toString，输出值和值更新次数 @Override public String toString() { return String.format(\"value: %s updateCount: %d\", value, updateCount.get()); } //设置值 public void setValue(T value) { this.value = value; updateCount.incrementAndGet(); }}子类 Child1 的实现是这样的：继承父类，但没有提供父类泛型参数；定义了一个参数为 String 的 setValue 方法，通过 super.setValue 调用父类方法实现日志记录。我们也能明白，开发同学这么设计是希望覆盖父类的 setValue 实现：class Child1 extends Parent { public void setValue(String value) { System.out.println(\"Child1.setValue called\"); super.setValue(value); }}在实现的时候，子类方法的调用是通过反射进行的。实例化 Child1 类型后，通过 getClass().getMethods 方法获得所有的方法；然后按照方法名过滤出 setValue 方法进行调用，传入字符串 test 作为参数：Child1 child1 = new Child1();Arrays.stream(child1.getClass().getMethods()) .filter(method -\u003e method.getName().equals(\"setValue\")) .forEach(method -\u003e { try { method.invoke(child1, \"test\"); } catch (Exception e) { e.printStackTrace(); } });System.out.println(child1.toString());运行代码后可以看到，虽然 Parent 的 value 字段正确设置了 test，但父类的 setValue 方法调用了两次，计数器也显示 2 而不是 1：Child1.setValue calledParent.setValue calledParent.setValue calledvalue: test updateCount: 2显","date":"0001-01-01","objectID":"/18%E4%B8%A8%E5%BD%93%E5%8F%8D%E5%B0%84%E6%B3%A8%E8%A7%A3%E5%92%8C%E6%B3%9B%E5%9E%8B%E9%81%87%E5%88%B0oop%E6%97%B6%E4%BC%9A%E6%9C%89%E5%93%AA%E4%BA%9B%E5%9D%91/:0:0","tags":null,"title":"","uri":"/18%E4%B8%A8%E5%BD%93%E5%8F%8D%E5%B0%84%E6%B3%A8%E8%A7%A3%E5%92%8C%E6%B3%9B%E5%9E%8B%E9%81%87%E5%88%B0oop%E6%97%B6%E4%BC%9A%E6%9C%89%E5%93%AA%E4%BA%9B%E5%9D%91/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 19 | Spring框架：IoC和AOP是扩展的核心  下载APP   关闭 讲堂 部落 Python 进阶训练营 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 19 | Spring框架：IoC和AOP是扩展的核心 2020-04-25 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长17:44大小16.24M  你好，我是朱晔。今天，我们来聊聊 Spring 框架中的 IoC 和 AOP，及其容易出错的地方。熟悉 Java 的同学都知道，Spring 的家族庞大，常用的模块就有 Spring Data、Spring Security、Spring Boot、Spring Cloud 等。其实呢，Spring 体系虽然庞大，但都是围绕 Spring Core 展开的，而 Spring Core 中最核心的就是 IoC（控制反转）和 AOP（面向切面编程）。概括地说，IoC 和 AOP 的初衷是解耦和扩展。理解这两个核心技术，就可以让你的代码变得更灵活、可随时替换，以及业务组件间更解耦。在接下来的两讲中，我会与你深入剖析几个案例，带你绕过业务中通过 Spring 实现 IoC 和 AOP 相关的坑。为了便于理解这两讲中的案例，我们先回顾下 IoC 和 AOP 的基础知识。IoC，其实就是一种设计思想。使用 Spring 来实现 IoC，意味着将你设计好的对象交给 Spring 容器控制，而不是直接在对象内部控制。那，为什么要让容器来管理对象呢？或许你能想到的是，使用 IoC 方便、可以实现解耦。但在我看来，相比于这两个原因，更重要的是 IoC 带来了更多的可能性。如果以容器为依托来管理所有的框架、业务对象，我们不仅可以无侵入地调整对象的关系，还可以无侵入地随时调整对象的属性，甚至是实现对象的替换。这就使得框架开发者在程序背后实现一些扩展不再是问题，带来的可能性是无限的。比如我们要监控的对象如果是 Bean，实现就会非常简单。所以，这套容器体系，不仅被 Spring Core 和 Spring Boot 大量依赖，还实现了一些外部框架和 Spring 的无缝整合。AOP，体现了松耦合、高内聚的精髓，在切面集中实现横切关注点（缓存、权限、日志等），然后通过切点配置把代码注入合适的地方。切面、切点、增强、连接点，是 AOP 中非常重要的概念，也是我们这两讲会大量提及的。为方便理解，我们把 Spring AOP 技术看作为蛋糕做奶油夹层的工序。如果我们希望找到一个合适的地方把奶油注入蛋糕胚子中，那应该如何指导工人完成操作呢？首先，我们要提醒他，只能往蛋糕胚子里面加奶油，而不能上面或下面加奶油。这就是连接点（Join point），对于 Spring AOP 来说，连接点就是方法执行。然后，我们要告诉他，在什么点切开蛋糕加奶油。比如，可以在蛋糕坯子中间加入一层奶油，在中间切一次；也可以在中间加两层奶油，在 1/3 和 2/3 的地方切两次。这就是切点（Pointcut），Spring AOP 中默认使用 AspectJ 查询表达式，通过在连接点运行查询表达式来匹配切入点。接下来也是最重要的，我们要告诉他，切开蛋糕后要做什么，也就是加入奶油。这就是增强（Advice），也叫作通知，定义了切入切点后增强的方式，包括前、后、环绕等。Spring AOP 中，把增强定义为拦截器。最后，我们要告诉他，找到蛋糕胚子中要加奶油的地方并加入奶油。为蛋糕做奶油夹层的操作，对 Spring AOP 来说就是切面（Aspect），也叫作方面。切面 = 切点 + 增强。好了，理解了这几个核心概念，我们就可以继续分析案例了。我要首先说明的是，Spring 相关问题的问题比较复杂，一方面是 Spring 提供的 IoC 和 AOP 本就灵活，另一方面 Spring Boot 的自动装配、Spring Cloud 复杂的模块会让问题排查变得更复杂。因此，今天这一讲，我会带你先打好基础，通过两个案例来重点聊聊 IoC 和 AOP；然后，我会在下一讲中与你分享 Spring 相关的坑。单例的 Bean 如何注入 Prototype 的 Bean？我们虽然知道 Spring 创建的 Bean 默认是单例的，但当 Bean 遇到继承的时候，可能会忽略这一点。为什么呢？忽略这一点又会造成什么影响呢？接下来，我就和你分享一个由单例引起内存泄露的案例。架构师一开始定义了这么一个 SayService 抽象类，其中维护了一个类型是 ArrayList 的字段 data，用于保存方法处理的中间数据。每次调用 say 方法都会往 data 加入新数据，可以认为 SayService 是有状态，如果 SayService 是单例的话必然会 OOM：@Slf4jpublic abstract class SayService { List\u003cString\u003e data = new ArrayList\u003c\u003e(); public void say() { data.add(IntStream.rangeClosed(1, 1000000) .mapToObj(__ -\u003e \"a\") .collect(Collectors.joining(\"\")) + UUID.randomUUID().toString()); log.info(\"I'm {} size:{}\", this, data.size()); }}但实际开发的时候，开发同学没有过多思考就把 SayHello 和 SayBye 类加上了 @Service 注解，让它们成为了 Bean，也没有考虑到父类是有状态的：@Service@Slf4jpublic class SayHello extends SayService { @Override public void say() { super.say(); log.info(\"hello\"); }}@Service@Slf4jpublic class SayBye extends SayService { @Override public void say() { super.say(); log.info(\"bye\"); }}许多开发同学认为，@Service 注解的意义在于，能通过 @Autowired 注解让 Spring 自动注入对象，就比如可以直接使用注入的 List获取到 SayHello 和 SayBye，而没想过类的生命周期：@AutowiredList\u003cSayService\u003e sayServiceList;@GetMapping(\"test\")public void test() { log.info(\"====================\"); sayServiceList.forEach(SayService::say);}这一个点非常容易忽略。开发基类的架构师将基类设计为有状态的，但并不知道子类是怎么使用基类的；而开发子类的同学，没多想就直接标记了 @Service，让类成为了 Bean，通过 @Autowired 注解来注入这个服务。但这样设置后，有状态的基类就可能产生内存泄露或线程安全问题。正确的方式是，在为类标记上 @Service 注解把类型交由容器管理前，首先评估一下类是否有状态，然后为 Bean 设置合适的 Scope。好在上线前，架构师发现了这个内存泄露问题，开发同学也做了修改，为 SayHello 和 SayBye 两个类都标记了 @Scope 注解，设置了 PROTOTYPE 的生命周期，也就是多例：@Scope(value = ConfigurableBeanFactory.SCOPE_PROTOTYPE)但，上线后还是出现了内存泄漏，证明修改是无效的。从日志可以看到，第一次调用和第二次调用的时候，SayBye 对象都是 4c0bfe9e，SayHello 也是一样的问题。从日志第 7 到 10 行还可以看到，第二次调用后 List 的元素个数变为了 2，说明父类 SayService 维护的 List 在不断增长，不断调用必然出现 OOM：[15:01:09.349] [http-nio-45678-exec-1] [INFO ] [.s.d.BeanSingletonAndOrderController:22 ] - ====================[15:01:09.401] [http-nio-45678-exec-1] [INFO ] [o.g.t.c.spring.demo1.SayService :19 ] - I'm org.geekbang.time.commonmistakes.spring.demo1.SayBye@4c0bfe9e size:1[15:01:09.402] [http-nio-45678-exec-1] [INFO ] [t.commonmistakes.spring.demo1.SayBye:16 ] - bye[15:01:09.469] [http-nio-45678-exec-1] [INFO ] [o.g.t.c.spring.demo1.SayService :19 ] - I'm org.geekbang.time.commonmistakes.spring.demo1.SayHello@490fbeaa size:1[15:01:09.469] [http-nio-45678-exec-1] ","date":"0001-01-01","objectID":"/19%E4%B8%A8spring%E6%A1%86%E6%9E%B6ioc%E5%92%8Caop%E6%98%AF%E6%89%A9%E5%B1%95%E7%9A%84%E6%A0%B8%E5%BF%83/:0:0","tags":null,"title":"","uri":"/19%E4%B8%A8spring%E6%A1%86%E6%9E%B6ioc%E5%92%8Caop%E6%98%AF%E6%89%A9%E5%B1%95%E7%9A%84%E6%A0%B8%E5%BF%83/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 20 | Spring框架：框架帮我们做了很多工作也带来了复杂度  防止断更 请务必加首发微信：1716 143665   关闭 讲堂 部落 Python 进阶训练营 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 20 | Spring框架：框架帮我们做了很多工作也带来了复杂度 2020-04-28 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长22:40大小20.77M  你好，我是朱晔。今天，我们聊聊 Spring 框架给业务代码带来的复杂度，以及与之相关的坑。在上一讲，通过 AOP 实现统一的监控组件的案例，我们看到了 IoC 和 AOP 配合使用的威力：当对象由 Spring 容器管理成为 Bean 之后，我们不但可以通过容器管理配置 Bean 的属性，还可以方便地对感兴趣的方法做 AOP。不过，前提是对象必须是 Bean。你可能会觉得这个结论很明显，也很容易理解啊。但就和上一讲提到的 Bean 默认是单例一样，理解起来简单，实践的时候却非常容易踩坑。其中原因，一方面是，理解 Spring 的体系结构和使用方式有一定曲线；另一方面是，Spring 多年发展堆积起来的内部结构非常复杂，这也是更重要的原因。在我看来，Spring 框架内部的复杂度主要表现为三点：第一，Spring 框架借助 IoC 和 AOP 的功能，实现了修改、拦截 Bean 的定义和实例的灵活性，因此真正执行的代码流程并不是串行的。第二，Spring Boot 根据当前依赖情况实现了自动配置，虽然省去了手动配置的麻烦，但也因此多了一些黑盒、提升了复杂度。第三，Spring Cloud 模块多版本也多，Spring Boot 1.x 和 2.x 的区别也很大。如果要对 Spring Cloud 或 Spring Boot 进行二次开发的话，考虑兼容性的成本会很高。今天，我们就通过配置 AOP 切入 Spring Cloud Feign 组件失败、Spring Boot 程序的文件配置被覆盖这两个案例，感受一下 Spring 的复杂度。我希望这一讲的内容，能帮助你面对 Spring 这个复杂框架出现的问题时，可以非常自信地找到解决方案。Feign AOP 切不到的诡异案例我曾遇到过这么一个案例：使用 Spring Cloud 做微服务调用，为方便统一处理 Feign，想到了用 AOP 实现，即使用 within 指示器匹配 feign.Client 接口的实现进行 AOP 切入。代码如下，通过 @Before 注解在执行方法前打印日志，并在代码中定义了一个标记了 @FeignClient 注解的 Client 类，让其成为一个 Feign 接口：//测试Feign@FeignClient(name = \"client\")public interface Client { @GetMapping(\"/feignaop/server\") String api();}//AOP切入feign.Client的实现@Aspect@Slf4j@Componentpublic class WrongAspect { @Before(\"within(feign.Client+)\") public void before(JoinPoint pjp) { log.info(\"within(feign.Client+) pjp {}, args:{}\", pjp, pjp.getArgs()); }}//配置扫描Feign@Configuration@EnableFeignClients(basePackages = \"org.geekbang.time.commonmistakes.spring.demo4.feign\")public class Config {}//测试Feign@FeignClient(name = \"client\")public interface Client { @GetMapping(\"/feignaop/server\") String api();}//AOP切入feign.Client的实现@Aspect@Slf4j@Componentpublic class WrongAspect { @Before(\"within(feign.Client+)\") public void before(JoinPoint pjp) { log.info(\"within(feign.Client+) pjp {}, args:{}\", pjp, pjp.getArgs()); }}//配置扫描Feign@Configuration@EnableFeignClients(basePackages = \"org.geekbang.time.commonmistakes.spring.demo4.feign\")public class Config {}通过 Feign 调用服务后可以看到日志中有输出，的确实现了 feign.Client 的切入，切入的是 execute 方法：[15:48:32.850] [http-nio-45678-exec-1] [INFO ] [o.g.t.c.spring.demo4.WrongAspect :20 ] - within(feign.Client+) pjp execution(Response feign.Client.execute(Request,Options)), args:[GET http://client/feignaop/server HTTP/1.1Binary data, feign.Request$Options@5c16561a]一开始这个项目使用的是客户端的负载均衡，也就是让 Ribbon 来做负载均衡，代码没啥问题。后来因为后端服务通过 Nginx 实现服务端负载均衡，所以开发同学把 @FeignClient 的配置设置了 URL 属性，直接通过一个固定 URL 调用后端服务：@FeignClient(name = \"anotherClient\",url = \"http://localhost:45678\")public interface ClientWithUrl { @GetMapping(\"/feignaop/server\") String api();}但这样配置后，之前的 AOP 切面竟然失效了，也就是 within(feign.Client+) 无法切入 ClientWithUrl 的调用了。为了还原这个场景，我写了一段代码，定义两个方法分别通过 Client 和 ClientWithUrl 这两个 Feign 进行接口调用：@Autowiredprivate Client client;@Autowiredprivate ClientWithUrl clientWithUrl;@GetMapping(\"client\")public String client() { return client.api();}@GetMapping(\"clientWithUrl\")public String clientWithUrl() { return clientWithUrl.api();}可以看到，调用 Client 后 AOP 有日志输出，调用 ClientWithUrl 后却没有：[15:50:32.850] [http-nio-45678-exec-1] [INFO ] [o.g.t.c.spring.demo4.WrongAspect :20 ] - within(feign.Client+) pjp execution(Response feign.Client.execute(Request,Options)), args:[GET http://client/feignaop/server HTTP/1.1Binary data, feign.Request$Options@5c16561这就很费解了。难道为 Feign 指定了 URL，其实现就不是 feign.Clinet 了吗？要明白原因，我们需要分析一下 FeignClient 的创建过程，也就是分析 FeignClientFactoryBean 类的 getTarget 方法。源码第 4 行有一个 if 判断，当 URL 没有内容也就是为空或者不配置时调用 loadBalance 方法，在其内部通过 FeignContext 从容器获取 feign.Client 的实例：\u003cT\u003e T getTarget() { FeignContext context = this.applicationContext.getBean(FeignContext.class); Feign.Builder builder = feign(context); if (!StringUtils.hasText(this.url)) { ... return (T) loadBalance(builder, context, new HardCodedTarget\u003c\u003e(this.type, this.name, this.url)); } ... String url = this.url + cleanPath(); Client client = getOptional(context, Client.class); if (client","date":"0001-01-01","objectID":"/20%E4%B8%A8spring%E6%A1%86%E6%9E%B6%E6%A1%86%E6%9E%B6%E5%B8%AE%E6%88%91%E4%BB%AC%E5%81%9A%E4%BA%86%E5%BE%88%E5%A4%9A%E5%B7%A5%E4%BD%9C%E4%B9%9F%E5%B8%A6%E6%9D%A5%E4%BA%86%E5%A4%8D%E6%9D%82%E5%BA%A6/:0:0","tags":null,"title":"","uri":"/20%E4%B8%A8spring%E6%A1%86%E6%9E%B6%E6%A1%86%E6%9E%B6%E5%B8%AE%E6%88%91%E4%BB%AC%E5%81%9A%E4%BA%86%E5%BE%88%E5%A4%9A%E5%B7%A5%E4%BD%9C%E4%B9%9F%E5%B8%A6%E6%9D%A5%E4%BA%86%E5%A4%8D%E6%9D%82%E5%BA%A6/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 21 | 代码重复：搞定代码重复的三个绝招  防止断更 请务必加首发微信：1716 143665   关闭 讲堂 部落 Python 进阶训练营 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 21 | 代码重复：搞定代码重复的三个绝招 2020-05-02 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长18:22大小16.82M  你好，我是朱晔。今天，我来和你聊聊搞定代码重复的三个绝招。业务同学抱怨业务开发没有技术含量，用不到设计模式、Java 高级特性、OOP，平时写代码都在堆 CRUD，个人成长无从谈起。每次面试官问到“请说说平时常用的设计模式”，都只能答单例模式，因为其他设计模式的确是听过但没用过；对于反射、注解之类的高级特性，也只是知道它们在写框架的时候非常常用，但自己又不写框架代码，没有用武之地。其实，我认为不是这样的。设计模式、OOP 是前辈们在大型项目中积累下来的经验，通过这些方法论来改善大型项目的可维护性。反射、注解、泛型等高级特性在框架中大量使用的原因是，框架往往需要以同一套算法来应对不同的数据结构，而这些特性可以帮助减少重复代码，提升项目可维护性。在我看来，可维护性是大型项目成熟度的一个重要指标，而提升可维护性非常重要的一个手段就是减少代码重复。那为什么这样说呢？如果多处重复代码实现完全相同的功能，很容易修改一处忘记修改另一处，造成 Bug；有一些代码并不是完全重复，而是相似度很高，修改这些类似的代码容易改（复制粘贴）错，把原本有区别的地方改为了一样。今天，我就从业务代码中最常见的三个需求展开，和你聊聊如何使用 Java 中的一些高级特性、设计模式，以及一些工具消除重复代码，才能既优雅又高端。通过今天的学习，也希望改变你对业务代码没有技术含量的看法。利用工厂模式 + 模板方法模式，消除 if…else 和重复代码假设要开发一个购物车下单的功能，针对不同用户进行不同处理：普通用户需要收取运费，运费是商品价格的 10%，无商品折扣；VIP 用户同样需要收取商品价格 10% 的快递费，但购买两件以上相同商品时，第三件开始享受一定折扣；内部用户可以免运费，无商品折扣。我们的目标是实现三种类型的购物车业务逻辑，把入参 Map 对象（Key 是商品 ID，Value 是商品数量），转换为出参购物车类型 Cart。先实现针对普通用户的购物车处理逻辑：//购物车@Datapublic class Cart { //商品清单 private List\u003cItem\u003e items = new ArrayList\u003c\u003e(); //总优惠 private BigDecimal totalDiscount; //商品总价 private BigDecimal totalItemPrice; //总运费 private BigDecimal totalDeliveryPrice; //应付总价 private BigDecimal payPrice;}//购物车中的商品@Datapublic class Item { //商品ID private long id; //商品数量 private int quantity; //商品单价 private BigDecimal price; //商品优惠 private BigDecimal couponPrice; //商品运费 private BigDecimal deliveryPrice;}//普通用户购物车处理public class NormalUserCart { public Cart process(long userId, Map\u003cLong, Integer\u003e items) { Cart cart = new Cart(); //把Map的购物车转换为Item列表 List\u003cItem\u003e itemList = new ArrayList\u003c\u003e(); items.entrySet().stream().forEach(entry -\u003e { Item item = new Item(); item.setId(entry.getKey()); item.setPrice(Db.getItemPrice(entry.getKey())); item.setQuantity(entry.getValue()); itemList.add(item); }); cart.setItems(itemList); //处理运费和商品优惠 itemList.stream().forEach(item -\u003e { //运费为商品总价的10% item.setDeliveryPrice(item.getPrice().multiply(BigDecimal.valueOf(item.getQuantity())).multiply(new BigDecimal(\"0.1\"))); //无优惠 item.setCouponPrice(BigDecimal.ZERO); }); //计算商品总价 cart.setTotalItemPrice(cart.getItems().stream().map(item -\u003e item.getPrice().multiply(BigDecimal.valueOf(item.getQuantity()))).reduce(BigDecimal.ZERO, BigDecimal::add)); //计算运费总价 cart.setTotalDeliveryPrice(cart.getItems().stream().map(Item::getDeliveryPrice).reduce(BigDecimal.ZERO, BigDecimal::add)); //计算总优惠 cart.setTotalDiscount(cart.getItems().stream().map(Item::getCouponPrice).reduce(BigDecimal.ZERO, BigDecimal::add)); //应付总价=商品总价+运费总价-总优惠 cart.setPayPrice(cart.getTotalItemPrice().add(cart.getTotalDeliveryPrice()).subtract(cart.getTotalDiscount())); return cart; }}然后实现针对 VIP 用户的购物车逻辑。与普通用户购物车逻辑的不同在于，VIP 用户能享受同类商品多买的折扣。所以，这部分代码只需要额外处理多买折扣部分：public class VipUserCart { public Cart process(long userId, Map\u003cLong, Integer\u003e items) { ... itemList.stream().forEach(item -\u003e { //运费为商品总价的10% item.setDeliveryPrice(item.getPrice().multiply(BigDecimal.valueOf(item.getQuantity())).multiply(new BigDecimal(\"0.1\"))); //购买两件以上相同商品，第三件开始享受一定折扣 if (item.getQuantity() \u003e 2) { item.setCouponPrice(item.getPrice() .multiply(BigDecimal.valueOf(100 - Db.getUserCouponPercent(userId)).divide(new BigDecimal(\"100\"))) .multiply(BigDecimal.valueOf(item.getQuantity() - 2))); } else { item.setCouponPrice(BigDecimal.ZERO); } }); ... return cart; }}最后是免运费、无折扣的内部用户，同样只是处理商品折扣和运费时的逻辑差异：public class InternalUserCart { public Cart process(long userId, Map\u003cLong, Integer\u003e items) { ... itemList.stream().forEach(item -\u003e { //免运费 item.setDeliveryPrice(BigDecimal.ZERO); //无优惠 item.setCouponPrice(BigDecimal.ZERO); }); ... return cart; }}对比一下代码量可以发现，三种购物车 70% 的代码是重复的。原因很简单，虽然不同类型用户计算运费和优惠的方式不同，但整个购物车的初始化、统计总价、总运费、总优惠和支付价格的逻辑都是一样的。正如我们开始时提到的，代码重复本身不可怕，可怕的是漏改或改错。比如，写 VIP 用户购物车的同学发现商品总价计算有 Bug，不应该是把所有 Item 的 price 加在一起，而是应该把所有 Item 的 price*quantity 加在一起。这时，他可能会只修改 VIP 用户购物车的代码，而忽略了普通用户、内部用户的购物车中，重复的逻辑实现也有相同的 Bug。有了三个购物车后，我们就需要根据不同的用户类型使用不同的购物车了。如下代码所示，使用三个 if 实现不同类型用","date":"0001-01-01","objectID":"/21%E4%B8%A8%E4%BB%A3%E7%A0%81%E9%87%8D%E5%A4%8D%E6%90%9E%E5%AE%9A%E4%BB%A3%E7%A0%81%E9%87%8D%E5%A4%8D%E7%9A%84%E4%B8%89%E4%B8%AA%E7%BB%9D%E6%8B%9B/:0:0","tags":null,"title":"","uri":"/21%E4%B8%A8%E4%BB%A3%E7%A0%81%E9%87%8D%E5%A4%8D%E6%90%9E%E5%AE%9A%E4%BB%A3%E7%A0%81%E9%87%8D%E5%A4%8D%E7%9A%84%E4%B8%89%E4%B8%AA%E7%BB%9D%E6%8B%9B/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 22 | 接口设计：系统间对话的语言，一定要统一  防止断更 请务必加首发微信：171 6143665   关闭 讲堂 部落 Python 进阶训练营 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 22 | 接口设计：系统间对话的语言，一定要统一 2020-05-05 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长20:03大小18.37M  你好，我是朱晔。今天，我要和你分享的主题是，在做接口设计时一定要确保系统之间对话的语言是统一的。我们知道，开发一个服务的第一步就是设计接口。接口的设计需要考虑的点非常多，比如接口的命名、参数列表、包装结构体、接口粒度、版本策略、幂等性实现、同步异步处理方式等。这其中，和接口设计相关比较重要的点有三个，分别是包装结构体、版本策略、同步异步处理方式。今天，我就通过我遇到的实际案例，和你一起看看因为接口设计思路和调用方理解不一致所导致的问题，以及相关的实践经验。接口的响应要明确表示接口的处理结果我曾遇到过一个处理收单的收单中心项目，下单接口返回的响应体中，包含了 success、code、info、message 等属性，以及二级嵌套对象 data 结构体。在对项目进行重构的时候，我们发现真的是无从入手，接口缺少文档，代码一有改动就出错。有时候，下单操作的响应结果是这样的：success 是 true、message 是 OK，貌似代表下单成功了；但 info 里却提示订单存在风险，code 是一个 5001 的错误码，data 中能看到订单状态是 Cancelled，订单 ID 是 -1，好像又说明没有下单成功。{ \"success\": true, \"code\": 5001, \"info\": \"Risk order detected\", \"message\": \"OK\", \"data\": { \"orderStatus\": \"Cancelled\", \"orderId\": -1 }}有些时候，这个下单接口又会返回这样的结果：success 是 false，message 提示非法用户 ID，看上去下单失败；但 data 里的 orderStatus 是 Created、info 是空、code 是 0。那么，这次下单到底是成功还是失败呢？{ \"success\": false, \"code\": 0, \"info\": \"\", \"message\": \"Illegal userId\", \"data\": { \"orderStatus\": \"Created\", \"orderId\": 0 }}这样的结果，让我们非常疑惑：结构体的 code 和 HTTP 响应状态码，是什么关系？success 到底代表下单成功还是失败？info 和 message 的区别是什么？data 中永远都有数据吗？什么时候应该去查询 data？造成如此混乱的原因是：这个收单服务本身并不真正处理下单操作，只是做一些预校验和预处理；真正的下单操作，需要在收单服务内部调用另一个订单服务来处理；订单服务处理完成后，会返回订单状态和 ID。在一切正常的情况下，下单后的订单状态就是已创建 Created，订单 ID 是一个大于 0 的数字。而结构体中的 message 和 success，其实是收单服务的处理异常信息和处理成功与否的结果，code、info 是调用订单服务的结果。对于第一次调用，收单服务自己没问题，success 是 true，message 是 OK，但调用订单服务时却因为订单风险问题被拒绝，所以 code 是 5001，info 是 Risk order detected，data 中的信息是订单服务返回的，所以最终订单状态是 Cancelled。对于第二次调用，因为用户 ID 非法，所以收单服务在校验了参数后直接就返回了 success 是 false，message 是 Illegal userId。因为请求没有到订单服务，所以 info、code、data 都是默认值，订单状态的默认值是 Created。因此，第二次下单肯定失败了，但订单状态却是已创建。可以看到，如此混乱的接口定义和实现方式，是无法让调用者分清到底应该怎么处理的。为了将接口设计得更合理，我们需要考虑如下两个原则：对外隐藏内部实现。虽然说收单服务调用订单服务进行真正的下单操作，但是直接接口其实是收单服务提供的，收单服务不应该“直接”暴露其背后订单服务的状态码、错误描述。设计接口结构时，明确每个字段的含义，以及客户端的处理方式。基于这两个原则，我们调整一下返回结构体，去掉外层的 info，即不再把订单服务的调用结果告知客户端：@Datapublic class APIResponse\u003cT\u003e { private boolean success; private T data; private int code; private String message;}并明确接口的设计逻辑：如果出现非 200 的 HTTP 响应状态码，就代表请求没有到收单服务，可能是网络出问题、网络超时，或者网络配置的问题。这时，肯定无法拿到服务端的响应体，客户端可以给予友好提示，比如让用户重试，不需要继续解析响应结构体。如果 HTTP 响应码是 200，解析响应体查看 success，为 false 代表下单请求处理失败，可能是因为收单服务参数验证错误，也可能是因为订单服务下单操作失败。这时，根据收单服务定义的错误码表和 code，做不同处理。比如友好提示，或是让用户重新填写相关信息，其中友好提示的文字内容可以从 message 中获取。success 为 true 的情况下，才需要继续解析响应体中的 data 结构体。data 结构体代表了业务数据，通常会有下面两种情况。通常情况下，success 为 true 时订单状态是 Created，获取 orderId 属性可以拿到订单号。特殊情况下，比如收单服务内部处理不当，或是订单服务出现了额外的状态，虽然 success 为 true，但订单实际状态不是 Created，这时可以给予友好的错误提示。明确了接口的设计逻辑，我们就是可以实现收单服务的服务端和客户端来模拟这些情况了。首先，实现服务端的逻辑：@GetMapping(\"server\")public APIResponse\u003cOrderInfo\u003e server(@RequestParam(\"userId\") Long userId) { APIResponse\u003cOrderInfo\u003e response = new APIResponse\u003c\u003e(); if (userId == null) { //对于userId为空的情况，收单服务直接处理失败，给予相应的错误码和错误提示 response.setSuccess(false); response.setCode(3001); response.setMessage(\"Illegal userId\"); } else if (userId == 1) { //对于userId=1的用户，模拟订单服务对于风险用户的情况 response.setSuccess(false); //把订单服务返回的错误码转换为收单服务错误码 response.setCode(3002); response.setMessage(\"Internal Error, order is cancelled\"); //同时日志记录内部错误 log.warn(\"用户 {} 调用订单服务失败，原因是 Risk order detected\", userId); } else { //其他用户，下单成功 response.setSuccess(true); response.setCode(2000); response.setMessage(\"OK\"); response.setData(new OrderInfo(\"Created\", 2L)); } return response;}客户端代码，则可以按照流程图上的逻辑来实现，同样模拟三种出错情况和正常下单的情况：error==1 的用例模拟一个不存在的 URL，请求无法到收单服务，会得到 404 的 HTTP 状态码，直接进行友好提示，这是第一层处理。error==2 的用例模拟 userId 参数为空的情况，收单服务会因为缺少 userId 参数提示非法用户。这时，可以把响应体中的 message 展示给用户，这是第二层处理。error==3 的用例模拟 userId 为 1 的情况，因为用户有风险，收单服务调用订单服务出错。处理方式和之前没有任何区别，因为收单服务会屏蔽订单服务的内部错误。但在服务端可以看到如下错误信息：[14:13:13.951] [http-nio-45678-exec-8] [WARN ] [.c.a.d.APIThreeLevelStatusController:36 ] - 用户 1 调用订单服务失败，原因是 Risk order detectederror==0 的用例模拟正常用户，下单成功。这时可以解析 data 结构体提取业务结果，作为兜底，需要判断订单状态，如果不是 Created 则给予友好提示，否则查询 orderId 获得下单的订单号，这是第三层处理。客户端的实现代码如下：@GetMapping(\"client\")public String client(@RequestParam(va","date":"0001-01-01","objectID":"/22%E4%B8%A8%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%E7%B3%BB%E7%BB%9F%E9%97%B4%E5%AF%B9%E8%AF%9D%E7%9A%84%E8%AF%AD%E8%A8%80%E4%B8%80%E5%AE%9A%E8%A6%81%E7%BB%9F%E4%B8%80/:0:0","tags":null,"title":"","uri":"/22%E4%B8%A8%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%E7%B3%BB%E7%BB%9F%E9%97%B4%E5%AF%B9%E8%AF%9D%E7%9A%84%E8%AF%AD%E8%A8%80%E4%B8%80%E5%AE%9A%E8%A6%81%E7%BB%9F%E4%B8%80/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 23 | 缓存设计：缓存可以锦上添花也可以落井下石  下载APP   关闭 讲堂 部落 Python 进阶训练营 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 23 | 缓存设计：缓存可以锦上添花也可以落井下石 2020-05-07 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长22:03大小20.19M  你好，我是朱晔。今天，我从设计的角度，与你聊聊缓存。通常我们会使用更快的介质（比如内存）作为缓存，来解决较慢介质（比如磁盘）读取数据慢的问题，缓存是用空间换时间，来解决性能问题的一种架构设计模式。更重要的是，磁盘上存储的往往是原始数据，而缓存中保存的可以是面向呈现的数据。这样一来，缓存不仅仅是加快了 IO，还可以减少原始数据的计算工作。此外，缓存系统一般设计简单，功能相对单一，所以诸如 Redis 这种缓存系统的整体吞吐量，能达到关系型数据库的几倍甚至几十倍，因此缓存特别适用于互联网应用的高并发场景。使用 Redis 做缓存虽然简单好用，但使用和设计缓存并不是 set 一下这么简单，需要注意缓存的同步、雪崩、并发、穿透等问题。今天，我们就来详细聊聊。不要把 Redis 当作数据库通常，我们会使用 Redis 等分布式缓存数据库来缓存数据，但是千万别把 Redis 当做数据库来使用。我就见过许多案例，因为 Redis 中数据消失导致业务逻辑错误，并且因为没有保留原始数据，业务都无法恢复。Redis 的确具有数据持久化功能，可以实现服务重启后数据不丢失。这一点，很容易让我们误认为 Redis 可以作为高性能的 KV 数据库。其实，从本质上来看，Redis（免费版）是一个内存数据库，所有数据保存在内存中，并且直接从内存读写数据响应操作，只不过具有数据持久化能力。所以，Redis 的特点是，处理请求很快，但无法保存超过内存大小的数据。备注：VM 模式虽然可以保存超过内存大小的数据，但是因为性能原因从 2.6 开始已经被废弃。此外，Redis 企业版提供了 Redis on Flash 可以实现 Key+ 字典 + 热数据保存在内存中，冷数据保存在 SSD 中。因此，把 Redis 用作缓存，我们需要注意两点。第一，从客户端的角度来说，缓存数据的特点一定是有原始数据来源，且允许丢失，即使设置的缓存时间是 1 分钟，在 30 秒时缓存数据因为某种原因消失了，我们也要能接受。当数据丢失后，我们需要从原始数据重新加载数据，不能认为缓存系统是绝对可靠的，更不能认为缓存系统不会删除没有过期的数据。第二，从 Redis 服务端的角度来说，缓存系统可以保存的数据量一定是小于原始数据的。首先，我们应该限制 Redis 对内存的使用量，也就是设置 maxmemory 参数；其次，我们应该根据数据特点，明确 Redis 应该以怎样的算法来驱逐数据。从Redis 的文档可以看到，常用的数据淘汰策略有：allkeys-lru，针对所有 Key，优先删除最近最少使用的 Key；volatile-lru，针对带有过期时间的 Key，优先删除最近最少使用的 Key；volatile-ttl，针对带有过期时间的 Key，优先删除即将过期的 Key（根据 TTL 的值）；allkeys-lfu（Redis 4.0 以上），针对所有 Key，优先删除最少使用的 Key；volatile-lfu（Redis 4.0 以上），针对带有过期时间的 Key，优先删除最少使用的 Key。其实，这些算法是 Key 范围 +Key 选择算法的搭配组合，其中范围有 allkeys 和 volatile 两种，算法有 LRU、TTL 和 LFU 三种。接下来，我就从 Key 范围和算法角度，和你说说如何选择合适的驱逐算法。首先，从算法角度来说，Redis 4.0 以后推出的 LFU 比 LRU 更“实用”。试想一下，如果一个 Key 访问频率是 1 天一次，但正好在 1 秒前刚访问过，那么 LRU 可能不会选择优先淘汰这个 Key，反而可能会淘汰一个 5 秒访问一次但最近 2 秒没有访问过的 Key，而 LFU 算法不会有这个问题。而 TTL 会比较“头脑简单”一点，优先删除即将过期的 Key，但有可能这个 Key 正在被大量访问。然后，从 Key 范围角度来说，allkeys 可以确保即使 Key 没有 TTL 也能回收，如果使用的时候客户端总是“忘记”设置缓存的过期时间，那么可以考虑使用这个系列的算法。而 volatile 会更稳妥一些，万一客户端把 Redis 当做了长效缓存使用，只是启动时候初始化一次缓存，那么一旦删除了此类没有 TTL 的数据，可能就会导致客户端出错。所以，不管是使用者还是管理者都要考虑 Redis 的使用方式，使用者需要考虑应该以缓存的姿势来使用 Redis，管理者应该为 Redis 设置内存限制和合适的驱逐策略，避免出现 OOM。注意缓存雪崩问题由于缓存系统的 IOPS 比数据库高很多，因此要特别小心短时间内大量缓存失效的情况。这种情况一旦发生，可能就会在瞬间有大量的数据需要回源到数据库查询，对数据库造成极大的压力，极限情况下甚至导致后端数据库直接崩溃。这就是我们常说的缓存失效，也叫作缓存雪崩。从广义上说，产生缓存雪崩的原因有两种：第一种是，缓存系统本身不可用，导致大量请求直接回源到数据库；第二种是，应用设计层面大量的 Key 在同一时间过期，导致大量的数据回源。第一种原因，主要涉及缓存系统本身高可用的配置，不属于缓存设计层面的问题，所以今天我主要和你说说如何确保大量 Key 不在同一时间被动过期。程序初始化的时候放入 1000 条城市数据到 Redis 缓存中，过期时间是 30 秒；数据过期后从数据库获取数据然后写入缓存，每次从数据库获取数据后计数器 +1；在程序启动的同时，启动一个定时任务线程每隔一秒输出计数器的值，并把计数器归零。压测一个随机查询某城市信息的接口，观察一下数据库的 QPS：@Autowiredprivate StringRedisTemplate stringRedisTemplate;private AtomicInteger atomicInteger = new AtomicInteger();@PostConstructpublic void wrongInit() { //初始化1000个城市数据到Redis，所有缓存数据有效期30秒 IntStream.rangeClosed(1, 1000).forEach(i -\u003e stringRedisTemplate.opsForValue().set(\"city\" + i, getCityFromDb(i), 30, TimeUnit.SECONDS)); log.info(\"Cache init finished\"); //每秒一次，输出数据库访问的QPS Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -\u003e { log.info(\"DB QPS : {}\", atomicInteger.getAndSet(0)); }, 0, 1, TimeUnit.SECONDS);}@GetMapping(\"city\")public String city() { //随机查询一个城市 int id = ThreadLocalRandom.current().nextInt(1000) + 1; String key = \"city\" + id; String data = stringRedisTemplate.opsForValue().get(key); if (data == null) { //回源到数据库查询 data = getCityFromDb(id); if (!StringUtils.isEmpty(data)) //缓存30秒过期 stringRedisTemplate.opsForValue().set(key, data, 30, TimeUnit.SECONDS); } return data;}private String getCityFromDb(int cityId) { //模拟查询数据库，查一次增加计数器加一 atomicInteger.incrementAndGet(); return \"citydata\" + System.currentTimeMillis();}使用 wrk 工具，设置 10 线程 10 连接压测 city 接口：wrk -c10 -t10 -d 100s http://localhost:45678/cacheinvalid/city启动程序 30 秒后缓存过期，回源的数据库 QPS 最高达到了 700 多：解决缓存 Key 同时大规模失效需要回源，导致数据库压力激增问题的方式有两种。方案一，差异化缓存过期时间，不要让大量的 Key 在同一时间过期。比如，在初始化缓存的时候，设置缓存的过期时间是 30 秒 +10 秒以内的随机延迟（扰动值）。这样，这些 Key 不会集中在 30 秒这个时刻过期，而是会分散在 30~40 秒之间过期：@PostConstructpublic void rightInit1() { //这次缓存的过期时间是30秒+10秒内的随机延迟 IntStream.rangeClosed(1, 1000).forEach(i -","date":"0001-01-01","objectID":"/23%E4%B8%A8%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1%E7%BC%93%E5%AD%98%E5%8F%AF%E4%BB%A5%E9%94%A6%E4%B8%8A%E6%B7%BB%E8%8A%B1%E4%B9%9F%E5%8F%AF%E4%BB%A5%E8%90%BD%E4%BA%95%E4%B8%8B%E7%9F%B3/:0:0","tags":null,"title":"","uri":"/23%E4%B8%A8%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1%E7%BC%93%E5%AD%98%E5%8F%AF%E4%BB%A5%E9%94%A6%E4%B8%8A%E6%B7%BB%E8%8A%B1%E4%B9%9F%E5%8F%AF%E4%BB%A5%E8%90%BD%E4%BA%95%E4%B8%8B%E7%9F%B3/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 24 | 业务代码写完，就意味着生产就绪了？  下载APP   关闭 讲堂 部落 Python 进阶训练营 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 24 | 业务代码写完，就意味着生产就绪了？ 2020-05-09 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长22:52大小20.96M  你好，我是朱晔。今天，我们来聊聊业务代码写完，是不是就意味着生产就绪，可以直接投产了。所谓生产就绪（Production-ready），是指应用开发完成要投入生产环境，开发层面需要额外做的一些工作。在我看来，如果应用只是开发完成了功能代码，然后就直接投产，那意味着应用其实在裸奔。在这种情况下，遇到问题因为缺乏有效的监控导致无法排查定位问题，同时很可能遇到问题我们自己都不知道，需要依靠用户反馈才知道应用出了问题。那么，生产就绪需要做哪些工作呢？我认为，以下三方面的工作最重要。第一，提供健康检测接口。传统采用 ping 的方式对应用进行探活检测并不准确。有的时候，应用的关键内部或外部依赖已经离线，导致其根本无法正常工作，但其对外的 Web 端口或管理端口是可以 ping 通的。我们应该提供一个专有的监控检测接口，并尽可能触达一些内部组件。第二，暴露应用内部信息。应用内部诸如线程池、内存队列等组件，往往在应用内部扮演了重要的角色，如果应用或应用框架可以对外暴露这些重要信息，并加以监控，那么就有可能在诸如 OOM 等重大问题暴露之前发现蛛丝马迹，避免出现更大的问题。第三，建立应用指标 Metrics 监控。Metrics 可以翻译为度量或者指标，指的是对于一些关键信息以可聚合的、数值的形式做定期统计，并绘制出各种趋势图表。这里的指标监控，包括两个方面：一是，应用内部重要组件的指标监控，比如 JVM 的一些指标、接口的 QPS 等；二是，应用的业务数据的监控，比如电商订单量、游戏在线人数等。今天，我就通过实际案例，和你聊聊如何快速实现这三方面的工作。准备工作：配置 Spring Boot ActuatorSpring Boot 有一个 Actuator 模块，封装了诸如健康检测、应用内部信息、Metrics 指标等生产就绪的功能。今天这一讲后面的内容都是基于 Actuator 的，因此我们需要先完成 Actuator 的引入和配置。我们可以像这样在 pom 中通过添加依赖的方式引入 Actuator：\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-actuator\u003c/artifactId\u003e\u003c/dependency\u003e之后，你就可以直接使用 Actuator 了，但还要注意一些重要的配置：如果你不希望 Web 应用的 Actuator 管理端口和应用端口重合的话，可以使用 management.server.port 设置独立的端口。Actuator 自带了很多开箱即用提供信息的端点（Endpoint），可以通过 JMX 或 Web 两种方式进行暴露。考虑到有些信息比较敏感，这些内置的端点默认不是完全开启的，你可以通过官网查看这些默认值。在这里，为了方便后续 Demo，我们设置所有端点通过 Web 方式开启。默认情况下，Actuator 的 Web 访问方式的根地址为 /actuator，可以通过 management.endpoints.web.base-path 参数进行修改。我来演示下，如何将其修改为 /admin。management.server.port=45679management.endpoints.web.exposure.include=*management.endpoints.web.base-path=/admin现在，你就可以访问 http://localhost:45679/admin ，来查看 Actuator 的所有功能 URL 了：其中，大部分端点提供的是只读信息，比如查询 Spring 的 Bean、ConfigurableEnvironment、定时任务、SpringBoot 自动配置、Spring MVC 映射等；少部分端点还提供了修改功能，比如优雅关闭程序、下载线程 Dump、下载堆 Dump、修改日志级别等。你可以访问这里，查看所有这些端点的功能，详细了解它们提供的信息以及实现的操作。此外，我再分享一个不错的 Spring Boot 管理工具Spring Boot Admin，它把大部分 Actuator 端点提供的功能封装为了 Web UI。健康检测需要触达关键组件在这一讲开始我们提到，健康检测接口可以让监控系统或发布工具知晓应用的真实健康状态，比 ping 应用端口更可靠。不过，要达到这种效果最关键的是，我们能确保健康检测接口可以探查到关键组件的状态。好在 Spring Boot Actuator 帮我们预先实现了诸如数据库、InfluxDB、Elasticsearch、Redis、RabbitMQ 等三方系统的健康检测指示器 HealthIndicator。通过 Spring Boot 的自动配置，这些指示器会自动生效。当这些组件有问题的时候，HealthIndicator 会返回 DOWN 或 OUT_OF_SERVICE 状态，health 端点 HTTP 响应状态码也会变为 503，我们可以以此来配置程序健康状态监控报警。为了演示，我们可以修改配置文件，把 management.endpoint.health.show-details 参数设置为 always，让所有用户都可以直接查看各个组件的健康情况（如果配置为 when-authorized，那么可以结合 management.endpoint.health.roles 配置授权的角色）：management.endpoint.health.show-details=always访问 health 端点可以看到，数据库、磁盘、RabbitMQ、Redis 等组件健康状态是 UP，整个应用的状态也是 UP：在了解了基本配置之后，我们考虑一下，如果程序依赖一个很重要的三方服务，我们希望这个服务无法访问的时候，应用本身的健康状态也是 DOWN。比如三方服务有一个 user 接口，出现异常的概率是 50%：@Slf4j@RestController@RequestMapping(\"user\")public class UserServiceController { @GetMapping public User getUser(@RequestParam(\"userId\") long id) { //一半概率返回正确响应，一半概率抛异常 if (ThreadLocalRandom.current().nextInt() % 2 == 0) return new User(id, \"name\" + id); else throw new RuntimeException(\"error\"); }}要实现这个 user 接口是否正确响应和程序整体的健康状态挂钩的话，很简单，只需定义一个 UserServiceHealthIndicator 实现 HealthIndicator 接口即可。在 health 方法中，我们通过 RestTemplate 来访问这个 user 接口，如果结果正确则返回 Health.up()，并把调用执行耗时和结果作为补充信息加入 Health 对象中。如果调用接口出现异常，则返回 Health.down()，并把异常信息作为补充信息加入 Health 对象中：@Component@Slf4jpublic class UserServiceHealthIndicator implements HealthIndicator { @Autowired private RestTemplate restTemplate; @Override public Health health() { long begin = System.currentTimeMillis(); long userId = 1L; User user = null; try { //访问远程接口 user = restTemplate.getForObject(\"http://localhost:45678/user?userId=\" + userId, User.class); if (user != null \u0026\u0026 user.getUserId() == userId) { //结果正确，返回UP状态，补充提供耗时和用户信息 return Health.up() .withDetail(\"user\", user) .withDetail(\"took\", System.currentTimeMillis() - begin) .build(); } else { //结果不正确，返回DOWN状态，补充提供耗时 return Health.down().withDetail(\"took\", System.currentTimeMillis() - begin).build(); } } catch (Exception ex) { //出现异常，先记录异常，然后返回DOWN状态，补充提供异常信息和耗时 log.warn(\"health ","date":"0001-01-01","objectID":"/24%E4%B8%A8%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E5%86%99%E5%AE%8C%E5%B0%B1%E6%84%8F%E5%91%B3%E7%9D%80%E7%94%9F%E4%BA%A7%E5%B0%B1%E7%BB%AA%E4%BA%86/:0:0","tags":null,"title":"","uri":"/24%E4%B8%A8%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E5%86%99%E5%AE%8C%E5%B0%B1%E6%84%8F%E5%91%B3%E7%9D%80%E7%94%9F%E4%BA%A7%E5%B0%B1%E7%BB%AA%E4%BA%86/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 25 | 异步处理好用，但非常容易用错  下载APP   关闭 讲堂部落算法训练营Python进阶训练营架构师训练营企业版极客商城兑换中心App下载 渠道合作 推荐作者 25 | 异步处理好用，但非常容易用错 2020-05-12 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长20:19大小18.62M  你好，我是朱晔。今天，我来和你聊聊好用但容易出错的异步处理。异步处理是互联网应用不可或缺的一种架构模式，大多数业务项目都是由同步处理、异步处理和定时任务处理三种模式相辅相成实现的。区别于同步处理，异步处理无需同步等待流程处理完毕，因此适用场景主要包括：服务于主流程的分支流程。比如，在注册流程中，把数据写入数据库的操作是主流程，但注册后给用户发优惠券或欢迎短信的操作是分支流程，时效性不那么强，可以进行异步处理。用户不需要实时看到结果的流程。比如，下单后的配货、送货流程完全可以进行异步处理，每个阶段处理完成后，再给用户发推送或短信让用户知晓即可。同时，异步处理因为可以有 MQ 中间件的介入用于任务的缓冲的分发，所以相比于同步处理，在应对流量洪峰、实现模块解耦和消息广播方面有功能优势。不过，异步处理虽然好用，但在实现的时候却有三个最容易犯的错，分别是异步处理流程的可靠性问题、消息发送模式的区分问题，以及大量死信消息堵塞队列的问题。今天，我就用三个代码案例结合目前常用的 MQ 系统 RabbitMQ，来和你具体聊聊。今天这一讲的演示，我都会使用 Spring AMQP 来操作 RabbitMQ，所以你需要先引入 amqp 依赖：\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-amqp\u003c/artifactId\u003e\u003c/dependency\u003e异步处理需要消息补偿闭环使用类似 RabbitMQ、RocketMQ 等 MQ 系统来做消息队列实现异步处理，虽然说消息可以落地到磁盘保存，即使 MQ 出现问题消息数据也不会丢失，但是异步流程在消息发送、传输、处理等环节，都可能发生消息丢失。此外，任何 MQ 中间件都无法确保 100% 可用，需要考虑不可用时异步流程如何继续进行。因此，对于异步处理流程，必须考虑补偿或者说建立主备双活流程。我们来看一个用户注册后异步发送欢迎消息的场景。用户注册落数据库的流程为同步流程，会员服务收到消息后发送欢迎消息的流程为异步流程。我们来分析一下：蓝色的线，使用 MQ 进行的异步处理，我们称作主线，可能存在消息丢失的情况（虚线代表异步调用）；绿色的线，使用补偿 Job 定期进行消息补偿，我们称作备线，用来补偿主线丢失的消息；考虑到极端的 MQ 中间件失效的情况，我们要求备线的处理吞吐能力达到主线的能力水平。我们来看一下相关的实现代码。首先，定义 UserController 用于注册 + 发送异步消息。对于注册方法，我们一次性注册 10 个用户，用户注册消息不能发送出去的概率为 50%。@RestController@Slf4j@RequestMapping(\"user\")public class UserController { @Autowired private UserService userService; @Autowired private RabbitTemplate rabbitTemplate; @GetMapping(\"register\") public void register() { //模拟10个用户注册 IntStream.rangeClosed(1, 10).forEach(i -\u003e { //落库 User user = userService.register(); //模拟50%的消息可能发送失败 if (ThreadLocalRandom.current().nextInt(10) % 2 == 0) { //通过RabbitMQ发送消息 rabbitTemplate.convertAndSend(RabbitConfiguration.EXCHANGE, RabbitConfiguration.ROUTING_KEY, user); log.info(\"sent mq user {}\", user.getId()); } }); }}然后，定义 MemberService 类用于模拟会员服务。会员服务监听用户注册成功的消息，并发送欢迎短信。我们使用 ConcurrentHashMap 来存放那些发过短信的用户 ID 实现幂等，避免相同的用户进行补偿时重复发送短信：@Component@Slf4jpublic class MemberService { //发送欢迎消息的状态 private Map\u003cLong, Boolean\u003e welcomeStatus = new ConcurrentHashMap\u003c\u003e(); //监听用户注册成功的消息，发送欢迎消息 @RabbitListener(queues = RabbitConfiguration.QUEUE) public void listen(User user) { log.info(\"receive mq user {}\", user.getId()); welcome(user); } //发送欢迎消息 public void welcome(User user) { //去重操作 if (welcomeStatus.putIfAbsent(user.getId(), true) == null) { try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { } log.info(\"memberService: welcome new user {}\", user.getId()); } }}对于 MQ 消费程序，处理逻辑务必考虑去重（支持幂等），原因有几个：MQ 消息可能会因为中间件本身配置错误、稳定性等原因出现重复。自动补偿重复，比如本例，同一条消息可能既走 MQ 也走补偿，肯定会出现重复，而且考虑到高内聚，补偿 Job 本身不会做去重处理。人工补偿重复。出现消息堆积时，异步处理流程必然会延迟。如果我们提供了通过后台进行补偿的功能，那么在处理遇到延迟的时候，很可能会先进行人工补偿，过了一段时间后处理程序又收到消息了，重复处理。我之前就遇到过一次由 MQ 故障引发的事故，MQ 中堆积了几十万条发放资金的消息，导致业务无法及时处理，运营以为程序出错了就先通过后台进行了人工处理，结果 MQ 系统恢复后消息又被重复处理了一次，造成大量资金重复发放。接下来，定义补偿 Job 也就是备线操作。我们在 CompensationJob 中定义一个 @Scheduled 定时任务，5 秒做一次补偿操作，因为 Job 并不知道哪些用户注册的消息可能丢失，所以是全量补偿，补偿逻辑是：每 5 秒补偿一次，按顺序一次补偿 5 个用户，下一次补偿操作从上一次补偿的最后一个用户 ID 开始；对于补偿任务我们提交到线程池进行“异步”处理，提高处理能力。@Component@Slf4jpublic class CompensationJob { //补偿Job异步处理线程池 private static ThreadPoolExecutor compensationThreadPool = new ThreadPoolExecutor( 10, 10, 1, TimeUnit.HOURS, new ArrayBlockingQueue\u003c\u003e(1000), new ThreadFactoryBuilder().setNameFormat(\"compensation-threadpool-%d\").get()); @Autowired private UserService userService; @Autowired private MemberService memberService; //目前补偿到哪个用户ID private long offset = 0; //10秒后开始补偿，5秒补偿一次 @Scheduled(initialDelay = 10_000, fixedRate = 5_000) public void compensationJob() { log.info(\"开始从用户ID {} 补偿\", offset); //获取从offset开始的用户 userService.getUsersAfterIdWithLimit(offset, 5).forEach(user -\u003e { compensationThreadPool.execute(() -\u003e memberService.welcome(user)); offset = user.getId(); }); }}为了实现高内聚，主线和备线处理消息，最好使用同一个方法。比如，本例中 MemberService 监听到 MQ 消息和 CompensationJob 补偿，调用的都是 welcome 方法。此外值得一说的是，Demo 中的补偿逻辑比较简单，生产级的代码应该在以下几个方面进行加强：考虑配置补偿的频次、每次处理数量，以及补偿线程池大小等参数为合适的值，以满足补偿的吞吐量。考虑备线补偿数据进行适当延迟。比如，对注册时间在 3","date":"0001-01-01","objectID":"/25%E4%B8%A8%E5%BC%82%E6%AD%A5%E5%A4%84%E7%90%86%E5%A5%BD%E7%94%A8%E4%BD%86%E9%9D%9E%E5%B8%B8%E5%AE%B9%E6%98%93%E7%94%A8%E9%94%99/:0:0","tags":null,"title":"","uri":"/25%E4%B8%A8%E5%BC%82%E6%AD%A5%E5%A4%84%E7%90%86%E5%A5%BD%E7%94%A8%E4%BD%86%E9%9D%9E%E5%B8%B8%E5%AE%B9%E6%98%93%E7%94%A8%E9%94%99/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 26 | 数据存储：NoSQL与RDBMS如何取长补短、相辅相成？  防止断更 请务必加首发微信：171 6143665   关闭 讲堂部落算法训练营Python进阶训练营架构师训练营企业版极客商城兑换中心App下载 渠道合作 推荐作者 26 | 数据存储：NoSQL与RDBMS如何取长补短、相辅相成？ 2020-05-14 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长20:40大小18.93M  你好，我是朱晔。今天，我来和你聊聊数据存储的常见错误。近几年，各种非关系型数据库，也就是 NoSQL 发展迅猛，在项目中也非常常见。其中不乏一些使用上的极端情况，比如直接把关系型数据库（RDBMS）全部替换为 NoSQL，或是在不合适的场景下错误地使用 NoSQL。其实，每种 NoSQL 的特点不同，都有其要着重解决的某一方面的问题。因此，我们在使用 NoSQL 的时候，要尽量让它去处理擅长的场景，否则不但发挥不出它的功能和优势，还可能会导致性能问题。NoSQL 一般可以分为缓存数据库、时间序列数据库、全文搜索数据库、文档数据库、图数据库等。今天，我会以缓存数据库 Redis、时间序列数据库 InfluxDB、全文搜索数据库 ElasticSearch 为例，通过一些测试案例，和你聊聊这些常见 NoSQL 的特点，以及它们擅长和不擅长的地方。最后，我也还会和你说说 NoSQL 如何与 RDBMS 相辅相成，来构成一套可以应对高并发的复合数据库体系。取长补短之 Redis vs MySQLRedis 是一款设计简洁的缓存数据库，数据都保存在内存中，所以读写单一 Key 的性能非常高。我们来做一个简单测试，分别填充 10 万条数据到 Redis 和 MySQL 中。MySQL 中的 name 字段做了索引，相当于 Redis 的 Key，data 字段为 100 字节的数据，相当于 Redis 的 Value：@SpringBootApplication@Slf4jpublic class CommonMistakesApplication { //模拟10万条数据存到Redis和MySQL public static final int ROWS = 100000; public static final String PAYLOAD = IntStream.rangeClosed(1, 100).mapToObj(__ -\u003e \"a\").collect(Collectors.joining(\"\")); @Autowired private StringRedisTemplate stringRedisTemplate; @Autowired private JdbcTemplate jdbcTemplate; @Autowired private StandardEnvironment standardEnvironment; public static void main(String[] args) { SpringApplication.run(CommonMistakesApplication.class, args); } @PostConstruct public void init() { //使用-Dspring.profiles.active=init启动程序进行初始化 if (Arrays.stream(standardEnvironment.getActiveProfiles()).anyMatch(s -\u003e s.equalsIgnoreCase(\"init\"))) { initRedis(); initMySQL(); } } //填充数据到MySQL private void initMySQL() { //删除表 jdbcTemplate.execute(\"DROP TABLE IF EXISTS `r`;\"); //新建表，name字段做了索引 jdbcTemplate.execute(\"CREATE TABLE `r` (\\n\" + \" `id` bigint(20) NOT NULL AUTO_INCREMENT,\\n\" + \" `data` varchar(2000) NOT NULL,\\n\" + \" `name` varchar(20) NOT NULL,\\n\" + \" PRIMARY KEY (`id`),\\n\" + \" KEY `name` (`name`) USING BTREE\\n\" + \") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\"); //批量插入数据 String sql = \"INSERT INTO `r` (`data`,`name`) VALUES (?,?)\"; jdbcTemplate.batchUpdate(sql, new BatchPreparedStatementSetter() { @Override public void setValues(PreparedStatement preparedStatement, int i) throws SQLException { preparedStatement.setString(1, PAYLOAD); preparedStatement.setString(2, \"item\" + i); } @Override public int getBatchSize() { return ROWS; } }); log.info(\"init mysql finished with count {}\", jdbcTemplate.queryForObject(\"SELECT COUNT(*) FROM `r`\", Long.class)); } //填充数据到Redis private void initRedis() { IntStream.rangeClosed(1, ROWS).forEach(i -\u003e stringRedisTemplate.opsForValue().set(\"item\" + i, PAYLOAD)); log.info(\"init redis finished with count {}\", stringRedisTemplate.keys(\"item*\")); }}启动程序后，输出了如下日志，数据全部填充完毕：[14:22:47.195] [main] [INFO ] [o.g.t.c.n.r.CommonMistakesApplication:80 ] - init redis finished with count 100000[14:22:50.030] [main] [INFO ] [o.g.t.c.n.r.CommonMistakesApplication:74 ] - init mysql finished with count 100000然后，比较一下从 MySQL 和 Redis 随机读取单条数据的性能。“公平”起见，像 Redis 那样，我们使用 MySQL 时也根据 Key 来查 Value，也就是根据 name 字段来查 data 字段，并且我们给 name 字段做了索引：@Autowiredprivate JdbcTemplate jdbcTemplate;@Autowiredprivate StringRedisTemplate stringRedisTemplate;@GetMapping(\"redis\")public void redis() { //使用随机的Key来查询Value，结果应该等于PAYLOAD Assert.assertTrue(stringRedisTemplate.opsForValue().get(\"item\" + (ThreadLocalRandom.current().nextInt(CommonMistakesApplication.ROWS) + 1)).equals(CommonMistakesApplication.PAYLOAD));}@GetMapping(\"mysql\")public void mysql() { //根据随机name来查data，name字段有索引，结果应该等于PAYLOAD Assert.assertTrue(jdbcTemplate.queryForObject(\"SELECT data FROM `r` WHERE name=?\", new Object[]{(\"item\" + (ThreadLocalRandom.current().nextInt(CommonMistakesApplication.ROWS) + 1))}, String.class) .equals(CommonMistakesApplication.PAYLOAD));}在我的电脑上，使用 wrk 加 10 个线程 50 个并发连接做压测。可以看到，MySQL 90% 的请求需要 61ms，QPS 为 1460；而 Redis 90% 的请求在 5ms 左右，QPS 达到了 14008，几乎是 MySQL 的十倍：但 Redis 薄弱的地方是，不擅长做 Key 的搜索。对 MySQL，我们可以使用 LIKE 操作前匹配走 B+ 树索引实现快速搜索；但对 Redis，我们使用 Keys 命令对 Key 的搜索，其实相当于在 MySQL ","date":"0001-01-01","objectID":"/26%E4%B8%A8%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8nosql%E4%B8%8Erdbms%E5%A6%82%E4%BD%95%E5%8F%96%E9%95%BF%E8%A1%A5%E7%9F%AD%E7%9B%B8%E8%BE%85%E7%9B%B8%E6%88%90/:0:0","tags":null,"title":"","uri":"/26%E4%B8%A8%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8nosql%E4%B8%8Erdbms%E5%A6%82%E4%BD%95%E5%8F%96%E9%95%BF%E8%A1%A5%E7%9F%AD%E7%9B%B8%E8%BE%85%E7%9B%B8%E6%88%90/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 27 | 数据源头：任何客户端的东西都不可信任-极客时间  下载APP   关闭 讲堂部落算法训练营Python进阶训练营架构师训练营企业版极客商城兑换中心App下载 渠道合作 推荐作者 27 | 数据源头：任何客户端的东西都不可信任 2020-05-19 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长16:31大小15.13M  你好，我是朱晔。从今天开始，我要和你讨论几个有关安全的话题。首先声明，我不是安全专家，但我发现有这么一个问题，那就是许多做业务开发的同学往往一点点安全意识都没有。如果有些公司没有安全部门或专家的话，安全问题就会非常严重。如果只是用一些所谓的渗透服务浅层次地做一下扫描和渗透，而不在代码和逻辑层面做进一步分析的话，能够发现的安全问题非常有限。要做好安全，还是要靠一线程序员和产品经理点点滴滴的意识。所以接下来的几篇文章，我会从业务开发的角度，和你说说我们应该最应该具备的安全意识。对于 HTTP 请求，我们要在脑子里有一个根深蒂固的概念，那就是任何客户端传过来的数据都是不能直接信任的。客户端传给服务端的数据只是信息收集，数据需要经过有效性验证、权限验证等后才能使用，并且这些数据只能认为是用户操作的意图，不能直接代表数据当前的状态。举一个简单的例子，我们打游戏的时候，客户端发给服务端的只是用户的操作，比如移动了多少位置，由服务端根据用户当前的状态来设置新的位置再返回给客户端。为了防止作弊，不可能由客户端直接告诉服务端用户当前的位置。因此，客户端发给服务端的指令，代表的只是操作指令，并不能直接决定用户的状态，对于状态改变的计算在服务端。而网络不好时，我们往往会遇到走了 10 步又被服务端拉回来的现象，就是因为有指令丢失，客户端使用服务端计算的实际位置修正了客户端玩家的位置。今天，我通过四个案例来和你说说，为什么“任何客户端的东西都不可信任”。客户端的计算不可信我们先看一个电商下单操作的案例。在这个场景下，可能会暴露这么一个 /order 的 POST 接口给客户端，让客户端直接把组装后的订单信息 Order 传给服务端：@PostMapping(\"/order\")public void wrong(@RequestBody Order order) { this.createOrder(order);}订单信息 Order 可能包括商品 ID、商品价格、数量、商品总价：@Datapublic class Order { private long itemId; //商品ID private BigDecimal itemPrice; //商品价格 private int quantity; //商品数量 private BigDecimal itemTotalPrice; //商品总价}虽然用户下单时客户端肯定有商品的价格等信息，也会计算出订单的总价给用户确认，但是这些信息只能用于呈现和核对。即使客户端传给服务端的 POJO 中包含了这些信息，服务端也一定要重新从数据库来初始化商品的价格，重新计算最终的订单价格。如果不这么做的话，很可能会被黑客利用，商品总价被恶意修改为比较低的价格。因此，我们真正直接使用的、可信赖的只是客户端传过来的商品 ID 和数量，服务端会根据这些信息重新计算最终的总价。如果服务端计算出来的商品价格和客户端传过来的价格不匹配的话，可以给客户端友好提示，让用户重新下单。修改后的代码如下：@PostMapping(\"/orderRight\")public void right(@RequestBody Order order) { //根据ID重新查询商品 Item item = Db.getItem(order.getItemId()); //客户端传入的和服务端查询到的商品单价不匹配的时候，给予友好提示 if (!order.getItemPrice().equals(item.getItemPrice())) { throw new RuntimeException(\"您选购的商品价格有变化，请重新下单\"); } //重新设置商品单价 order.setItemPrice(item.getItemPrice()); //重新计算商品总价 BigDecimal totalPrice = item.getItemPrice().multiply(BigDecimal.valueOf(order.getQuantity())); //客户端传入的和服务端查询到的商品总价不匹配的时候，给予友好提示 if (order.getItemTotalPrice().compareTo(totalPrice)!=0) { throw new RuntimeException(\"您选购的商品总价有变化，请重新下单\"); } //重新设置商品总价 order.setItemTotalPrice(totalPrice); createOrder(order);}还有一种可行的做法是，让客户端仅传入需要的数据给服务端，像这样重新定义一个 POJO CreateOrderRequest 作为接口入参，比直接使用领域模型 Order 更合理。在设计接口时，我们会思考哪些数据需要客户端提供，而不是把一个大而全的对象作为参数提供给服务端，以避免因为忘记在服务端重置客户端数据而导致的安全问题。下单成功后，服务端处理完成后会返回诸如商品单价、总价等信息给客户端。此时，客户端可以进行一次判断，如果和之前客户端的数据不一致的话，给予用户提示，用户确认没问题后再进入支付阶段：@Datapublic class CreateOrderRequest { private long itemId; //商品ID private int quantity; //商品数量}@PostMapping(\"orderRight2\")public Order right2(@RequestBody CreateOrderRequest createOrderRequest) { //商品ID和商品数量是可信的没问题，其他数据需要由服务端计算 Item item = Db.getItem(createOrderRequest.getItemId()); Order order = new Order(); order.setItemPrice(item.getItemPrice()); order.setItemTotalPrice(item.getItemPrice().multiply(BigDecimal.valueOf(order.getQuantity()))); createOrder(order); return order;}通过这个案例我们可以看到，在处理客户端提交过来的数据时，服务端需要明确区分，哪些数据是需要客户端提供的，哪些数据是客户端从服务端获取后在客户端计算的。其中，前者可以信任；而后者不可信任，服务端需要重新计算，如果客户端和服务端计算结果不一致的话，可以给予友好提示。客户端提交的参数需要校验对于客户端的数据，我们还容易忽略的一点是，误以为客户端的数据来源是服务端，客户端就不可能提交异常数据。我们看一个案例。有一个用户注册页面要让用户选择所在国家，我们会把服务端支持的国家列表返回给页面，供用户选择。如下代码所示，我们的注册只支持中国、美国和英国三个国家，并不对其他国家开放，因此从数据库中筛选了 id\u003c4 的国家返回给页面进行填充：@Slf4j@RequestMapping(\"trustclientdata\")@Controllerpublic class TrustClientDataController { //所有支持的国家 private HashMap\u003cInteger, Country\u003e allCountries = new HashMap\u003c\u003e(); public TrustClientDataController() { allCountries.put(1, new Country(1, \"China\")); allCountries.put(2, new Country(2, \"US\")); allCountries.put(3, new Country(3, \"UK\")); allCountries.put(4, new Country(4, \"Japan\")); } @GetMapping(\"/\") public String index(ModelMap modelMap) { List\u003cCountry\u003e countries = new ArrayList\u003c\u003e(); //从数据库查出ID\u003c4的三个国家作为白名单在页面显示 countries.addAll(allCountries.values().stream().filter(country -\u003e country.getId()\u003c4).collect(Collectors.toList())); modelMap.addAttribute(\"countries\", countries); return \"index\"; }} 我们通过服务端返回的数据来渲染模板：...\u003cform id=\"myForm\" method=\"post\" th:action=\"@{/trustclientdata/wrong}\"\u003e \u003cselect id=\"countryId\" name=\"countryId\"\u003e \u003coption","date":"0001-01-01","objectID":"/27%E4%B8%A8%E6%95%B0%E6%8D%AE%E6%BA%90%E5%A4%B4%E4%BB%BB%E4%BD%95%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E4%B8%9C%E8%A5%BF%E9%83%BD%E4%B8%8D%E5%8F%AF%E4%BF%A1%E4%BB%BB/:0:0","tags":null,"title":"","uri":"/27%E4%B8%A8%E6%95%B0%E6%8D%AE%E6%BA%90%E5%A4%B4%E4%BB%BB%E4%BD%95%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E4%B8%9C%E8%A5%BF%E9%83%BD%E4%B8%8D%E5%8F%AF%E4%BF%A1%E4%BB%BB/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 28 | 安全兜底：涉及钱时，必须考虑防刷、限量和防重  下载APP   关闭 讲堂部落算法训练营Python进阶训练营架构师训练营企业版极客商城兑换中心App下载 渠道合作 推荐作者 28 | 安全兜底：涉及钱时，必须考虑防刷、限量和防重 2020-05-21 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长14:45大小13.53M  你好，我是朱晔。今天，我要和你分享的主题是，任何涉及钱的代码必须要考虑防刷、限量和防重，要做好安全兜底。涉及钱的代码，主要有以下三类。第一，代码本身涉及有偿使用的三方服务。如果因为代码本身缺少授权、用量控制而被利用导致大量调用，势必会消耗大量的钱，给公司造成损失。有些三方服务可能采用后付款方式的结算，出现问题后如果没及时发现，下个月结算时就会收到一笔数额巨大的账单。第二，代码涉及虚拟资产的发放，比如积分、优惠券等。虽然说虚拟资产不直接对应货币，但一般可以在平台兑换具有真实价值的资产。比如，优惠券可以在下单时使用，积分可以兑换积分商城的商品。所以从某种意义上说，虚拟资产就是具有一定价值的钱，但因为不直接涉及钱和外部资金通道，所以容易产生随意性发放而导致漏洞。第三，代码涉及真实钱的进出。比如，对用户扣款，如果出现非正常的多次重复扣款，小则用户投诉、用户流失，大则被相关管理机构要求停业整改，影响业务。又比如，给用户发放返现的付款功能，如果出现漏洞造成重复付款，涉及 B 端的可能还好，但涉及 C 端用户的重复付款可能永远无法追回。前段时间拼多多一夜之间被刷了大量 100 元无门槛优惠券的事情，就是限量和防刷出了问题。今天，我们就通过三个例子，和你说明如何在代码层面做好安全兜底。开放平台资源的使用需要考虑防刷我以真实遇到的短信服务被刷案例，和你说说防刷。有次短信账单月结时发现，之前每个月是几千元的短信费用，这个月突然变为了几万元。查数据库记录发现，之前是每天发送几千条短信验证码，从某天开始突然变为了每天几万条，但注册用户数并没有激增。显然，这是短信接口被刷了。我们知道，短信验证码服务属于开放性服务，由用户侧触发，且因为是注册验证码所以不需要登录就可以使用。如果我们的发短信接口像这样没有任何防刷的防护，直接调用三方短信通道，就相当于“裸奔”，很容易被短信轰炸平台利用：@GetMapping(\"wrong\")public void wrong() { sendSMSCaptcha(\"13600000000\");}private void sendSMSCaptcha(String mobile) { //调用短信通道}对于短信验证码这种开放接口，程序逻辑内需要有防刷逻辑。好的防刷逻辑是，对正常使用的用户毫无影响，只有疑似异常使用的用户才会感受到。对于短信验证码，有如下 4 种可行的方式来防刷。第一种方式，只有固定的请求头才能发送验证码。也就是说，我们通过请求头中网页或 App 客户端传给服务端的一些额外参数，来判断请求是不是 App 发起的。其实，这种方式“防君子不防小人”。比如，判断是否存在浏览器或手机型号、设备分辨率请求头。对于那些使用爬虫来抓取短信接口地址的程序来说，往往只能抓取到 URL，而难以分析出请求发送短信还需要的额外请求头，可以看作第一道基本防御。第二种方式，只有先到过注册页面才能发送验证码。对于普通用户来说，不管是通过 App 注册还是 H5 页面注册，一定是先进入注册页面才能看到发送验证码按钮，再点击发送。我们可以在页面或界面打开时请求固定的前置接口，为这个设备开启允许发送验证码的窗口，之后的请求发送验证码才是有效请求。这种方式可以防御直接绕开固定流程，通过接口直接调用的发送验证码请求，并不会干扰普通用户。第三种方式，控制相同手机号的发送次数和发送频次。除非是短信无法收到，否则用户不太会请求了验证码后不完成注册流程，再重新请求。因此，我们可以限制同一手机号每天的最大请求次数。验证码的到达需要时间，太短的发送间隔没有意义，所以我们还可以控制发送的最短间隔。比如，我们可以控制相同手机号一天只能发送 10 次验证码，最短发送间隔 1 分钟。第四种方式，增加前置图形验证码。短信轰炸平台一般会收集很多免费短信接口，一个接口只会给一个用户发一次短信，所以控制相同手机号发送次数和间隔的方式不够有效。这时，我们可以考虑对用户体验稍微有影响，但也是最有效的方式作为保底，即将弹出图形验证码作为前置。除了图形验证码，我们还可以使用其他更友好的人机验证手段（比如滑动、点击验证码等），甚至是引入比较新潮的无感知验证码方案（比如，通过判断用户输入手机号的打字节奏，来判断是用户还是机器），来改善用户体验。此外，我们也可以考虑在监测到异常的情况下再弹出人机检测。比如，短时间内大量相同远端 IP 发送验证码的时候，才会触发人机检测。总之，我们要确保，只有正常用户经过正常的流程才能使用开放平台资源，并且资源的用量在业务需求合理范围内。此外，还需要考虑做好短信发送量的实时监控，遇到发送量激增要及时报警。接下来，我们一起看看限量的问题。虚拟资产并不能凭空产生无限使用虚拟资产虽然是平台方自己生产和控制，但如果生产出来可以立即使用就有立即变现的可能性。比如，因为平台 Bug 有大量用户领取高额优惠券，并立即下单使用。在商家看来，这很可能只是一个用户支付的订单，并不会感知到用户使用平台方优惠券的情况；同时，因为平台和商家是事后结算的，所以会马上安排发货。而发货后基本就不可逆了，一夜之间造成了大量资金损失。我们从代码层面模拟一个优惠券被刷的例子。假设有一个 CouponCenter 类负责优惠券的产生和发放。如下是错误做法，只要调用方需要，就可以凭空产生无限的优惠券：@Slf4jpublic class CouponCenter { //用于统计发了多少优惠券 AtomicInteger totalSent = new AtomicInteger(0); public void sendCoupon(Coupon coupon) { if (coupon != null) totalSent.incrementAndGet(); } public int getTotalSentCoupon() { return totalSent.get(); } //没有任何限制，来多少请求生成多少优惠券 public Coupon generateCouponWrong(long userId, BigDecimal amount) { return new Coupon(userId, amount); }}这样一来，使用 CouponCenter 的 generateCouponWrong 方法，想发多少优惠券就可以发多少：@GetMapping(\"wrong\")public int wrong() { CouponCenter couponCenter = new CouponCenter(); //发送10000个优惠券 IntStream.rangeClosed(1, 10000).forEach(i -\u003e { Coupon coupon = couponCenter.generateCouponWrong(1L, new BigDecimal(\"100\")); couponCenter.sendCoupon(coupon); }); return couponCenter.getTotalSentCoupon();}更合适的做法是，把优惠券看作一种资源，其生产不是凭空的，而是需要事先申请，理由是：虚拟资产如果最终可以对应到真实金钱上的优惠，那么，能发多少取决于运营和财务的核算，应该是有计划、有上限的。引言提到的无门槛优惠券，需要特别小心。有门槛优惠券的大量使用至少会带来大量真实的消费，而使用无门槛优惠券下的订单，可能用户一分钱都没有支付。即使虚拟资产不值钱，大量不合常规的虚拟资产流入市场，也会冲垮虚拟资产的经济体系，造成虚拟货币的极速贬值。有量的控制才有价值。资产的申请需要理由，甚至需要走流程，这样才可以追溯是什么活动需要、谁提出的申请，程序依据申请批次来发放。接下来，我们按照这个思路改进一下程序。首先，定义一个 CouponBatch 类，要产生优惠券必须先向运营申请优惠券批次，批次中包含了固定张数的优惠券、申请原因等信息：//优惠券批次@Datapublic class CouponBatch { private long id; private AtomicInteger totalCount; private AtomicInteger remainCount; private BigDecimal amount; private String reason;}在业务需要发放优惠券的时候，先申请批次，然后再通过批次发放优惠券：@GetMapping(\"right\")public int right() { CouponCenter couponCenter = new CouponCenter(); //申请批次 CouponBatch couponBatch = couponCenter.generateCouponBatch(); IntStream.rangeClosed(1, 10000).forEach(i -\u003e { Coupon coupon = couponCenter.generateCouponRight(1L, couponBatch); //发放优惠券 c","date":"0001-01-01","objectID":"/28%E4%B8%A8%E5%AE%89%E5%85%A8%E5%85%9C%E5%BA%95%E6%B6%89%E5%8F%8A%E9%92%B1%E6%97%B6%E5%BF%85%E9%A1%BB%E8%80%83%E8%99%91%E9%98%B2%E5%88%B7%E9%99%90%E9%87%8F%E5%92%8C%E9%98%B2%E9%87%8D/:0:0","tags":null,"title":"","uri":"/28%E4%B8%A8%E5%AE%89%E5%85%A8%E5%85%9C%E5%BA%95%E6%B6%89%E5%8F%8A%E9%92%B1%E6%97%B6%E5%BF%85%E9%A1%BB%E8%80%83%E8%99%91%E9%98%B2%E5%88%B7%E9%99%90%E9%87%8F%E5%92%8C%E9%98%B2%E9%87%8D/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 29 | 数据和代码：数据就是数据，代码就是代码  防止断更 请务必加首发微信：171 6143665   关闭 讲堂部落算法训练营Python进阶训练营架构师训练营企业版极客商城兑换中心App下载 渠道合作 推荐作者 29 | 数据和代码：数据就是数据，代码就是代码 2020-05-23 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长21:14大小19.46M  你好，我是朱晔。今天，我来和你聊聊数据和代码的问题。正如这一讲标题“数据就是数据，代码就是代码”所说，Web 安全方面的很多漏洞，都是源自把数据当成了代码来执行，也就是注入类问题，比如：客户端提供给服务端的查询值，是一个数据，会成为 SQL 查询的一部分。黑客通过修改这个值注入一些 SQL，来达到在服务端运行 SQL 的目的，相当于把查询条件的数据变为了查询代码。这种攻击方式，叫做 SQL 注入。对于规则引擎，我们可能会用动态语言做一些计算，和 SQL 注入一样外部传入的数据只能当做数据使用，如果被黑客利用传入了代码，那么代码可能就会被动态执行。这种攻击方式，叫做代码注入。对于用户注册、留言评论等功能，服务端会从客户端收集一些信息，本来用户名、邮箱这类信息是纯文本信息，但是黑客把信息替换为了 JavaScript 代码。那么，这些信息在页面呈现时，可能就相当于执行了 JavaScript 代码。甚至是，服务端可能把这样的代码，当作普通信息保存到了数据库。黑客通过构建 JavaScript 代码来实现修改页面呈现、盗取信息，甚至蠕虫攻击的方式，叫做 XSS（跨站脚本）攻击。今天，我们就通过案例来看一下这三个问题，并了解下应对方式。SQL 注入能干的事情比你想象的更多我们应该都听说过 SQL 注入，也可能知道最经典的 SQL 注入的例子，是通过构造’or’1’='1 作为密码实现登录。这种简单的攻击方式，在十几年前可以突破很多后台的登录，但现在很难奏效了。最近几年，我们的安全意识增强了，都知道使用参数化查询来避免 SQL 注入问题。其中的原理是，使用参数化查询的话，参数只能作为普通数据，不可能作为 SQL 的一部分，以此有效避免 SQL 注入问题。虽然我们已经开始关注 SQL 注入的问题，但还是有一些认知上的误区，主要表现在以下三个方面：第一，认为 SQL 注入问题只可能发生于 Http Get 请求，也就是通过 URL 传入的参数才可能产生注入点。这是很危险的想法。从注入的难易度上来说，修改 URL 上的 QueryString 和修改 Post 请求体中的数据，没有任何区别，因为黑客是通过工具来注入的，而不是通过修改浏览器上的 URL 来注入的。甚至 Cookie 都可以用来 SQL 注入，任何提供数据的地方都可能成为注入点。第二，认为不返回数据的接口，不可能存在注入问题。其实，黑客完全可以利用 SQL 语句构造出一些不正确的 SQL，导致执行出错。如果服务端直接显示了错误信息，那黑客需要的数据就有可能被带出来，从而达到查询数据的目的。甚至是，即使没有详细的出错信息，黑客也可以通过所谓盲注的方式进行攻击。我后面再具体解释。第三，认为 SQL 注入的影响范围，只是通过短路实现突破登录，只需要登录操作加强防范即可。首先，SQL 注入完全可以实现拖库，也就是下载整个数据库的内容（之后我们会演示），SQL 注入的危害不仅仅是突破后台登录。其次，根据木桶原理，整个站点的安全性受限于安全级别最低的那块短板。因此，对于安全问题，站点的所有模块必须一视同仁，并不是只加强防范所谓的重点模块。在日常开发中，虽然我们是使用框架来进行数据访问的，但还可能会因为疏漏而导致注入问题。接下来，我就用一个实际的例子配合专业的 SQL 注入工具sqlmap，来测试下 SQL 注入。首先，在程序启动的时候使用 JdbcTemplate 创建一个 userdata 表（表中只有 ID、用户名、密码三列），并初始化两条用户信息。然后，创建一个不返回任何数据的 Http Post 接口。在实现上，我们通过 SQL 拼接的方式，把传入的用户名入参拼接到 LIKE 子句中实现模糊查询。//程序启动时进行表结构和数据初始化@PostConstructpublic void init() { //删除表 jdbcTemplate.execute(\"drop table IF EXISTS `userdata`;\"); //创建表，不包含自增ID、用户名、密码三列 jdbcTemplate.execute(\"create TABLE `userdata` (\\n\" + \" `id` bigint(20) NOT NULL AUTO_INCREMENT,\\n\" + \" `name` varchar(255) NOT NULL,\\n\" + \" `password` varchar(255) NOT NULL,\\n\" + \" PRIMARY KEY (`id`)\\n\" + \") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\"); //插入两条测试数据 jdbcTemplate.execute(\"INSERT INTO `userdata` (name,password) VALUES ('test1','haha1'),('test2','haha2')\");}@Autowiredprivate JdbcTemplate jdbcTemplate;//用户模糊搜索接口@PostMapping(\"jdbcwrong\")public void jdbcwrong(@RequestParam(\"name\") String name) { //采用拼接SQL的方式把姓名参数拼到LIKE子句中 log.info(\"{}\", jdbcTemplate.queryForList(\"SELECT id,name FROM userdata WHERE name LIKE '%\" + name + \"%'\"));}使用 sqlmap 来探索这个接口：python sqlmap.py -u http://localhost:45678/sqlinject/jdbcwrong --data name=test一段时间后，sqlmap 给出了如下结果：可以看到，这个接口的 name 参数有两种可能的注入方式：一种是报错注入，一种是基于时间的盲注。接下来，仅需简单的三步，就可以直接导出整个用户表的内容了。第一步，查询当前数据库：python sqlmap.py -u http://localhost:45678/sqlinject/jdbcwrong --data name=test --current-db可以得到当前数据库是 common_mistakes：current database: 'common_mistakes'第二步，查询数据库下的表：python sqlmap.py -u http://localhost:45678/sqlinject/jdbcwrong --data name=test --tables -D \"common_mistakes\"可以看到其中有一个敏感表 userdata：Database: common_mistakes[7 tables]+--------------------+| user || common_store || hibernate_sequence || m || news || r || userdata |+--------------------+第三步，查询 userdata 的数据：python sqlmap.py -u http://localhost:45678/sqlinject/jdbcwrong --data name=test -D \"common_mistakes\" -T \"userdata\" --dump你看，用户密码信息一览无遗。当然，你也可以继续查看其他表的数据：Database: common_mistakesTable: userdata[2 entries]+----+-------+----------+| id | name | password |+----+-------+----------+| 1 | test1 | haha1 || 2 | test2 | haha2 |+----+-------+----------+在日志中可以看到，sqlmap 实现拖库的方式是，让 SQL 执行后的出错信息包含字段内容。注意看下错误日志的第二行，错误信息中包含 ID 为 2 的用户的密码字段的值“haha2”。这，就是报错注入的基本原理：[13:22:27.375] [http-nio-45678-exec-10] [ERROR] [o.a.c.c.C.[.[.[/].[dispatcherServlet]:175 ] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.dao.DuplicateKeyException: StatementCallback; SQL [SELECT id,name FR","date":"0001-01-01","objectID":"/29%E4%B8%A8%E6%95%B0%E6%8D%AE%E5%92%8C%E4%BB%A3%E7%A0%81%E6%95%B0%E6%8D%AE%E5%B0%B1%E6%98%AF%E6%95%B0%E6%8D%AE%E4%BB%A3%E7%A0%81%E5%B0%B1%E6%98%AF%E4%BB%A3%E7%A0%81/:0:0","tags":null,"title":"","uri":"/29%E4%B8%A8%E6%95%B0%E6%8D%AE%E5%92%8C%E4%BB%A3%E7%A0%81%E6%95%B0%E6%8D%AE%E5%B0%B1%E6%98%AF%E6%95%B0%E6%8D%AE%E4%BB%A3%E7%A0%81%E5%B0%B1%E6%98%AF%E4%BB%A3%E7%A0%81/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 30 | 如何正确保存和传输敏感数据？  下载APP   关闭 讲堂部落算法训练营Python进阶训练营架构师训练营企业版极客商城兑换中心App下载 渠道合作 推荐作者 30 | 如何正确保存和传输敏感数据？ 2020-05-26 朱晔 Java业务开发常见错误100例 进入课程  讲述：朱晔 时长24:45大小22.67M  你好，我是朱晔。今天，我们从安全角度来聊聊用户名、密码、身份证等敏感信息，应该怎么保存和传输。同时，你还可以进一步复习加密算法中的散列、对称加密和非对称加密算法，以及 HTTPS 等相关知识。应该怎样保存用户密码？最敏感的数据恐怕就是用户的密码了。黑客一旦窃取了用户密码，或许就可以登录进用户的账号，消耗其资产、发布不良信息等；更可怕的是，有些用户至始至终都是使用一套密码，密码一旦泄露，就可以被黑客用来登录全网。为了防止密码泄露，最重要的原则是不要保存用户密码。你可能会觉得很好笑，不保存用户密码，之后用户登录的时候怎么验证？其实，我指的是不保存原始密码，这样即使拖库也不会泄露用户密码。我经常会听到大家说，不要明文保存用户密码，应该把密码通过 MD5 加密后保存。这的确是一个正确的方向，但这个说法并不准确。首先，MD5 其实不是真正的加密算法。所谓加密算法，是可以使用密钥把明文加密为密文，随后还可以使用密钥解密出明文，是双向的。而 MD5 是散列、哈希算法或者摘要算法。不管多长的数据，使用 MD5 运算后得到的都是固定长度的摘要信息或指纹信息，无法再解密为原始数据。所以，MD5 是单向的。最重要的是，仅仅使用 MD5 对密码进行摘要，并不安全。比如，使用如下代码在保持用户信息时，对密码进行了 MD5 计算：UserData userData = new UserData();userData.setId(1L);userData.setName(name);//密码字段使用MD5哈希后保存userData.setPassword(DigestUtils.md5Hex(password));return userRepository.save(userData);通过输出，可以看到密码是 32 位的 MD5：\"password\": \"325a2cc052914ceeb8c19016c091d2ac\"到某 MD5 破解网站上输入这个 MD5，不到 1 秒就得到了原始密码：其实你可以想一下，虽然 MD5 不可解密，但是我们可以构建一个超大的数据库，把所有 20 位以内的数字和字母组合的密码全部计算一遍 MD5 存进去，需要解密的时候搜索一下 MD5 就可以得到原始值了。这就是字典表。目前，有些 MD5 解密网站使用的是彩虹表，是一种使用时间空间平衡的技术，即可以使用更大的空间来降低破解时间，也可以使用更长的破解时间来换取更小的空间。此外，你可能会觉得多次 MD5 比较安全，其实并不是这样。比如，如下代码使用两次 MD5 进行摘要：userData.setPassword(DigestUtils.md5Hex(DigestUtils.md5Hex( password)));得到下面的 MD5：\"password\": \"ebbca84993fe002bac3a54e90d677d09\"也可以破解出密码，并且破解网站还告知我们这是两次 MD5 算法：所以直接保存 MD5 后的密码是不安全的。一些同学可能会说，还需要加盐。是的，但是加盐如果不当，还是非常不安全，比较重要的有两点。第一，不能在代码中写死盐，且盐需要有一定的长度，比如这样：userData.setPassword(DigestUtils.md5Hex(\"salt\" + password));得到了如下 MD5：\"password\": \"58b1d63ed8492f609993895d6ba6b93a\"对于这样一串 MD5，虽然破解网站上找不到原始密码，但是黑客可以自己注册一个账号，使用一个简单的密码，比如 1：\"password\": \"55f312f84e7785aa1efa552acbf251db\"然后，再去破解网站试一下这个 MD5，就可以得到原始密码是 salt，也就知道了盐值是 salt：其实，知道盐是什么没什么关系，关键的是我们是在代码里写死了盐，并且盐很短、所有用户都是这个盐。这么做有三个问题：因为盐太短、太简单了，如果用户原始密码也很简单，那么整个拼起来的密码也很短，这样一般的 MD5 破解网站都可以直接解密这个 MD5，除去盐就知道原始密码了。相同的盐，意味着使用相同密码的用户 MD5 值是一样的，知道了一个用户的密码就可能知道了多个。我们也可以使用这个盐来构建一张彩虹表，虽然会花不少代价，但是一旦构建完成，所有人的密码都可以被破解。所以，最好是每一个密码都有独立的盐，并且盐要长一点，比如超过 20 位。第二，虽然说每个人的盐最好不同，但我也不建议将一部分用户数据作为盐。比如，使用用户名作为盐：userData.setPassword(DigestUtils.md5Hex(name + password));如果世界上所有的系统都是按照这个方案来保存密码，那么 root、admin 这样的用户使用再复杂的密码也总有一天会被破解，因为黑客们完全可以针对这些常用用户名来做彩虹表。所以，盐最好是随机的值，并且是全球唯一的，意味着全球不可能有现成的彩虹表给你用。正确的做法是，使用全球唯一的、和用户无关的、足够长的随机值作为盐。比如，可以使用 UUID 作为盐，把盐一起保存到数据库中：userData.setSalt(UUID.randomUUID().toString());userData.setPassword(DigestUtils.md5Hex(userData.getSalt() + password));并且每次用户修改密码的时候都重新计算盐，重新保存新的密码。你可能会问，盐保存在数据库中，那被拖库了不是就可以看到了吗？难道不应该加密保存吗？在我看来，盐没有必要加密保存。盐的作用是，防止通过彩虹表快速实现密码“解密”，如果用户的盐都是唯一的，那么生成一次彩虹表只可能拿到一个用户的密码，这样黑客的动力会小很多。更好的做法是，不要使用像 MD5 这样快速的摘要算法，而是使用慢一点的算法。比如 Spring Security 已经废弃了 MessageDigestPasswordEncoder，推荐使用 BCryptPasswordEncoder，也就是BCrypt来进行密码哈希。BCrypt 是为保存密码设计的算法，相比 MD5 要慢很多。写段代码来测试一下 MD5，以及使用不同代价因子的 BCrypt，看看哈希一次密码的耗时。private static BCryptPasswordEncoder passwordEncoder = new BCryptPasswordEncoder();@GetMapping(\"performance\")public void performance() { StopWatch stopWatch = new StopWatch(); String password = \"Abcd1234\"; stopWatch.start(\"MD5\"); //MD5 DigestUtils.md5Hex(password); stopWatch.stop(); stopWatch.start(\"BCrypt(10)\"); //代价因子为10的BCrypt String hash1 = BCrypt.gensalt(10); BCrypt.hashpw(password, hash1); System.out.println(hash1); stopWatch.stop(); stopWatch.start(\"BCrypt(12)\"); //代价因子为12的BCrypt String hash2 = BCrypt.gensalt(12); BCrypt.hashpw(password, hash2); System.out.println(hash2); stopWatch.stop(); stopWatch.start(\"BCrypt(14)\"); //代价因子为14的BCrypt String hash3 = BCrypt.gensalt(14); BCrypt.hashpw(password, hash3); System.out.println(hash3); stopWatch.stop(); log.info(\"{}\", stopWatch.prettyPrint());}可以看到，MD5 只需要 0.8 毫秒，而三次 BCrypt 哈希（代价因子分别设置为 10、12 和 14）耗时分别是 82 毫秒、312 毫秒和 1.2 秒：也就是说，如果制作 8 位密码长度的 MD5 彩虹表需要 5 个月，那么对于 BCrypt 来说，可能就需要几十年，大部分黑客应该都没有这个耐心。我们写一段代码观察下，BCryptPasswordEncoder 生成的密码哈希的规律：@GetMapping(\"better\")public UserData better(@RequestParam(value = \"name\", defaultValue = \"zhuye\") String name, @RequestParam(value = \"password\", defaultValue = \"Abcd","date":"0001-01-01","objectID":"/30%E4%B8%A8%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E4%BF%9D%E5%AD%98%E5%92%8C%E4%BC%A0%E8%BE%93%E6%95%8F%E6%84%9F%E6%95%B0%E6%8D%AE/:0:0","tags":null,"title":"","uri":"/30%E4%B8%A8%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E4%BF%9D%E5%AD%98%E5%92%8C%E4%BC%A0%E8%BE%93%E6%95%8F%E6%84%9F%E6%95%B0%E6%8D%AE/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 加餐1 | 带你吃透课程中Java 8的那些重要知识点（上）  下载APP   关闭 讲堂 部落 算法训练营 前端进阶训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 加餐1 | 带你吃透课程中Java 8的那些重要知识点（上） 2020-03-17 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长16:41大小15.29M  你好，我是朱晔。Java 8 是目前最常用的 JDK 版本，在增强代码可读性、简化代码方面，相比 Java 7 增加了很多功能，比如 Lambda、Stream 流操作、并行流（ParallelStream）、Optional 可空类型、新日期时间类型等。这个课程中的所有案例，都充分使用了 Java 8 的各种特性来简化代码。这也就意味着，如果你不了解这些特性的话，理解课程内的 Demo 可能会有些困难。因此，我将这些特性，单独拎了出来组成了两篇加餐。由于后面有单独一节课去讲 Java 8 的日期时间类型，所以这里就不赘述了。如何在项目中用上 Lambda 表达式和 Stream 操作？Java 8 的特性有很多，除了这两篇加餐外，我再给你推荐一本全面介绍 Java 8 的书，叫《Java 实战（第二版）》。此外，有同学在留言区问，怎么把 Lambda 表达式和 Stream 操作运用到项目中。其实，业务代码中可以使用这些特性的地方有很多。这里，为了帮助你学习，并把这些特性用到业务开发中，我有三个小建议。第一，从 List 的操作开始，先尝试把遍历 List 来筛选数据和转换数据的操作，使用 Stream 的 filter 和 map 实现，这是 Stream 最常用、最基本的两个 API。你可以重点看看接下来两节的内容来入门。第二，使用高级的 IDE 来写代码，以此找到可以利用 Java 8 语言特性简化代码的地方。比如，对于 IDEA，我们可以把匿名类型使用 Lambda 替换的检测规则，设置为 Error 级别严重程度：这样运行 IDEA 的 Inspect Code 的功能，可以在 Error 级别的错误中看到这个问题，引起更多关注，帮助我们建立使用 Lambda 表达式的习惯：第三，如果你不知道如何把匿名类转换为 Lambda 表达式，可以借助 IDE 来重构：反过来，如果你在学习课程内案例时，如果感觉阅读 Lambda 表达式和 Stream API 比较吃力，同样可以借助 IDE 把 Java 8 的写法转换为使用循环的写法：或者是把 Lambda 表达式替换为匿名类：Lambda 表达式Lambda 表达式的初衷是，进一步简化匿名类的语法（不过实现上，Lambda 表达式并不是匿名类的语法糖），使 Java 走向函数式编程。对于匿名类，虽然没有类名，但还是要给出方法定义。这里有个例子，分别使用匿名类和 Lambda 表达式创建一个线程打印字符串：//匿名类new Thread(new Runnable(){ @Override public void run(){ System.out.println(\"hello1\"); }}).start();//Lambda表达式new Thread(() -\u003e System.out.println(\"hello2\")).start();那么，Lambda 表达式如何匹配 Java 的类型系统呢？答案就是，函数式接口。函数式接口是一种只有单一抽象方法的接口，使用 @FunctionalInterface 来描述，可以隐式地转换成 Lambda 表达式。使用 Lambda 表达式来实现函数式接口，不需要提供类名和方法定义，通过一行代码提供函数式接口的实例，就可以让函数成为程序中的头等公民，可以像普通数据一样作为参数传递，而不是作为一个固定的类中的固定方法。那，函数式接口到底是什么样的呢？java.util.function 包中定义了各种函数式接口。比如，用于提供数据的 Supplier 接口，就只有一个 get 抽象方法，没有任何入参、有一个返回值：@FunctionalInterfacepublic interface Supplier\u003cT\u003e { /** * Gets a result. * * @return a result */ T get();}我们可以使用 Lambda 表达式或方法引用，来得到 Supplier 接口的实例：//使用Lambda表达式提供Supplier接口实现，返回OK字符串Supplier\u003cString\u003e stringSupplier = ()-\u003e\"OK\";//使用方法引用提供Supplier接口实现，返回空字符串Supplier\u003cString\u003e supplier = String::new;这样，是不是很方便？为了帮你掌握函数式接口及其用法，我再举几个使用 Lambda 表达式或方法引用来构建函数的例子：//Predicate接口是输入一个参数，返回布尔值。我们通过and方法组合两个Predicate条件，判断是否值大于0并且是偶数Predicate\u003cInteger\u003e positiveNumber = i -\u003e i \u003e 0;Predicate\u003cInteger\u003e evenNumber = i -\u003e i % 2 == 0;assertTrue(positiveNumber.and(evenNumber).test(2));//Consumer接口是消费一个数据。我们通过andThen方法组合调用两个Consumer，输出两行abcdefgConsumer\u003cString\u003e println = System.out::println;println.andThen(println).accept(\"abcdefg\");//Function接口是输入一个数据，计算后输出一个数据。我们先把字符串转换为大写，然后通过andThen组合另一个Function实现字符串拼接Function\u003cString, String\u003e upperCase = String::toUpperCase;Function\u003cString, String\u003e duplicate = s -\u003e s.concat(s);assertThat(upperCase.andThen(duplicate).apply(\"test\"), is(\"TESTTEST\"));//Supplier是提供一个数据的接口。这里我们实现获取一个随机数Supplier\u003cInteger\u003e random = ()-\u003eThreadLocalRandom.current().nextInt();System.out.println(random.get());//BinaryOperator是输入两个同类型参数，输出一个同类型参数的接口。这里我们通过方法引用获得一个整数加法操作，通过Lambda表达式定义一个减法操作，然后依次调用BinaryOperator\u003cInteger\u003e add = Integer::sum;BinaryOperator\u003cInteger\u003e subtraction = (a, b) -\u003e a - b;assertThat(subtraction.apply(add.apply(1, 2), 3), is(0));Predicate、Function 等函数式接口，还使用 default 关键字实现了几个默认方法。这样一来，它们既可以满足函数式接口只有一个抽象方法，又能为接口提供额外的功能：@FunctionalInterfacepublic interface Function\u003cT, R\u003e { R apply(T t); default \u003cV\u003e Function\u003cV, R\u003e compose(Function\u003c? super V, ? extends T\u003e before) { Objects.requireNonNull(before); return (V v) -\u003e apply(before.apply(v)); } default \u003cV\u003e Function\u003cT, V\u003e andThen(Function\u003c? super R, ? extends V\u003e after) { Objects.requireNonNull(after); return (T t) -\u003e after.apply(apply(t)); }}很明显，Lambda 表达式给了我们复用代码的更多可能性：我们可以把一大段逻辑中变化的部分抽象出函数式接口，由外部方法提供函数实现，重用方法内的整体逻辑处理。不过需要注意的是，在自定义函数式接口之前，可以先确认下java.util.function 包中的 43 个标准函数式接口是否能满足需求，我们要尽可能重用这些接口，因为使用大家熟悉的标准接口可以提高代码的可读性。使用 Java 8 简化代码这一部分，我会通过几个具体的例子，带你感受一下使用 Java 8 简化代码的三个重要方面：使用 Stream 简化集合操作；使用 Optional 简化判空逻辑；JDK8 结合 Lambda 和 Stream 对各种类的增强。使用 Stream 简化集合操作Lambda 表达式可以帮我们用简短的代码实现方法的定义，给了我们复用代码的更多可能性。利用这个特性，我们可以把集合的投影、转换、过滤等操作抽象成通用的接口，然后通过 Lambda 表达式传入其具体实现，这也就是 Stream 操作。我们看一个具体的例","date":"0001-01-01","objectID":"/%E5%8A%A0%E9%A4%901%E4%B8%A8%E5%B8%A6%E4%BD%A0%E5%90%83%E9%80%8F%E8%AF%BE%E7%A8%8B%E4%B8%ADjava8%E7%9A%84%E9%82%A3%E4%BA%9B%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%8A/:0:0","tags":null,"title":"","uri":"/%E5%8A%A0%E9%A4%901%E4%B8%A8%E5%B8%A6%E4%BD%A0%E5%90%83%E9%80%8F%E8%AF%BE%E7%A8%8B%E4%B8%ADjava8%E7%9A%84%E9%82%A3%E4%BA%9B%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%8A/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 加餐2 | 带你吃透课程中Java 8的那些重要知识点（下）  下载APP   关闭 讲堂 部落 算法训练营 前端进阶训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 加餐2 | 带你吃透课程中Java 8的那些重要知识点（下） 2020-03-17 朱晔 Java 业务开发常见错误 100 例 进入课程  讲述：王少泽 时长14:27大小13.24M  你好，我是朱晔。上一讲的几个例子中，其实都涉及了 Stream API 的最基本使用方法。今天，我会与你详细介绍复杂、功能强大的 Stream API。Stream 流式操作，用于对集合进行投影、转换、过滤、排序等，更进一步地，这些操作能链式串联在一起使用，类似于 SQL 语句，可以大大简化代码。可以说，Stream 操作是 Java 8 中最重要的内容，也是这个课程大部分代码都会用到的操作。我先说明下，有些案例可能不太好理解，建议你对着代码逐一到源码中查看 Stream 操作的方法定义，以及 JDK 中的代码注释。Stream 操作详解为了方便你理解 Stream 的各种操作，以及后面的案例，我先把这节课涉及的 Stream 操作汇总到了一张图中。你可以先熟悉一下。在接下来的讲述中，我会围绕订单场景，给出如何使用 Stream 的各种 API 完成订单的统计、搜索、查询等功能，和你一起学习 Stream 流式操作的各种方法。你可以结合代码中的注释理解案例，也可以自己运行源码观察输出。我们先定义一个订单类、一个订单商品类和一个顾客类，用作后续 Demo 代码的数据结构：//订单类@Datapublic class Order { private Long id; private Long customerId;//顾客ID private String customerName;//顾客姓名 private List\u003cOrderItem\u003e orderItemList;//订单商品明细 private Double totalPrice;//总价格 private LocalDateTime placedAt;//下单时间}//订单商品类@Data@AllArgsConstructor@NoArgsConstructorpublic class OrderItem { private Long productId;//商品ID private String productName;//商品名称 private Double productPrice;//商品价格 private Integer productQuantity;//商品数量}//顾客类@Data@AllArgsConstructorpublic class Customer { private Long id; private String name;//顾客姓名}在这里，我们有一个 orders 字段保存了一些模拟数据，类型是 List。这里，我就不贴出生成模拟数据的代码了。这不会影响你理解后面的代码，你也可以自己下载源码阅读。创建流要使用流，就要先创建流。创建流一般有五种方式：通过 stream 方法把 List 或数组转换为流；通过 Stream.of 方法直接传入多个元素构成一个流；通过 Stream.iterate 方法使用迭代的方式构造一个无限流，然后使用 limit 限制流元素个数；通过 Stream.generate 方法从外部传入一个提供元素的 Supplier 来构造无限流，然后使用 limit 限制流元素个数；通过 IntStream 或 DoubleStream 构造基本类型的流。//通过stream方法把List或数组转换为流@Testpublic void stream(){ Arrays.asList(\"a1\", \"a2\", \"a3\").stream().forEach(System.out::println); Arrays.stream(new int[]{1, 2, 3}).forEach(System.out::println);}//通过Stream.of方法直接传入多个元素构成一个流@Testpublic void of(){ String[] arr = {\"a\", \"b\", \"c\"}; Stream.of(arr).forEach(System.out::println); Stream.of(\"a\", \"b\", \"c\").forEach(System.out::println); Stream.of(1, 2, \"a\").map(item -\u003e item.getClass().getName()).forEach(System.out::println);}//通过Stream.iterate方法使用迭代的方式构造一个无限流，然后使用limit限制流元素个数@Testpublic void iterate(){ Stream.iterate(2, item -\u003e item * 2).limit(10).forEach(System.out::println); Stream.iterate(BigInteger.ZERO, n -\u003e n.add(BigInteger.TEN)).limit(10).forEach(System.out::println);}//通过Stream.generate方法从外部传入一个提供元素的Supplier来构造无限流，然后使用limit限制流元素个数@Testpublic void generate(){ Stream.generate(() -\u003e \"test\").limit(3).forEach(System.out::println); Stream.generate(Math::random).limit(10).forEach(System.out::println);}//通过IntStream或DoubleStream构造基本类型的流@Testpublic void primitive(){ //演示IntStream和DoubleStream IntStream.range(1, 3).forEach(System.out::println); IntStream.range(0, 3).mapToObj(i -\u003e \"x\").forEach(System.out::println); IntStream.rangeClosed(1, 3).forEach(System.out::println); DoubleStream.of(1.1, 2.2, 3.3).forEach(System.out::println); //各种转换，后面注释代表了输出结果 System.out.println(IntStream.of(1, 2).toArray().getClass()); //class [I System.out.println(Stream.of(1, 2).mapToInt(Integer::intValue).toArray().getClass()); //class [I System.out.println(IntStream.of(1, 2).boxed().toArray().getClass()); //class [Ljava.lang.Object; System.out.println(IntStream.of(1, 2).asDoubleStream().toArray().getClass()); //class [D System.out.println(IntStream.of(1, 2).asLongStream().toArray().getClass()); //class [J //注意基本类型流和装箱后的流的区别 Arrays.asList(\"a\", \"b\", \"c\").stream() // Stream\u003cString\u003e .mapToInt(String::length) // IntStream .asLongStream() // LongStream .mapToDouble(x -\u003e x / 10.0) // DoubleStream .boxed() // Stream\u003cDouble\u003e .mapToLong(x -\u003e 1L) // LongStream .mapToObj(x -\u003e \"\") // Stream\u003cString\u003e .collect(Collectors.toList());}filterfilter 方法可以实现过滤操作，类似 SQL 中的 where。我们可以使用一行代码，通过 filter 方法实现查询所有订单中最近半年金额大于 40 的订单，通过连续叠加 filter 方法进行多次条件过滤：//最近半年的金额大于40的订单orders.stream() .filter(Objects::nonNull) //过滤null值 .filter(order -\u003e order.getPlacedAt().isAfter(LocalDateTime.now().minusMonths(6))) //最近半年的订单 .filter(order -\u003e order.getTotalPrice() \u003e 40) //金额大于40的订单 .forEach(System.out::println); 如果不使用 Stream","date":"0001-01-01","objectID":"/%E5%8A%A0%E9%A4%902%E4%B8%A8%E5%B8%A6%E4%BD%A0%E5%90%83%E9%80%8F%E8%AF%BE%E7%A8%8B%E4%B8%ADjava8%E7%9A%84%E9%82%A3%E4%BA%9B%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%8B/:0:0","tags":null,"title":"","uri":"/%E5%8A%A0%E9%A4%902%E4%B8%A8%E5%B8%A6%E4%BD%A0%E5%90%83%E9%80%8F%E8%AF%BE%E7%A8%8B%E4%B8%ADjava8%E7%9A%84%E9%82%A3%E4%BA%9B%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%8B/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 加餐3 | 定位应用问题，排错套路很重要  下载APP   关闭 讲堂 学习路径 部落 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 加餐3 | 定位应用问题，排错套路很重要 2020-04-09 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长23:16大小21.31M  你好，我是朱晔。咱们这个课程已经更新 13 讲了，感谢各位同学一直在坚持学习，并在评论区留下了很多高质量的留言。这些留言，有的是分享自己曾经踩的坑，有的是对课后思考题的详细解答，还有的是提出了非常好的问题，进一步丰富了这个课程的内容。有同学说，这个课程的案例非常实用，都是工作中会遇到的。正如我在开篇词中所说，这个课程涉及的 100 个案例、约 130 个小坑，有 40% 来自于我经历过或者是见过的 200 多个线上生产事故，剩下的 60% 来自于我开发业务项目，以及日常审核别人的代码发现的问题。确实，我在整理这些案例上花费了很多精力，也特别感谢各位同学的认可，更希望你们能继续坚持学习，继续在评论区和我交流。也有同学反馈，排查问题的思路很重要，希望自己遇到问题时，也能够从容、高效地定位到根因。因此，今天这一讲，我就与你说说我在应急排错方面积累的心得。这都是我多年担任技术负责人和架构师自己总结出来的，希望对你有所帮助。当然了，也期待你能留言与我说说，自己平时的排错套路。在不同环境排查问题，有不同的方式要说排查问题的思路，我们首先得明白是在什么环境排错。如果是在自己的开发环境排查问题，那你几乎可以使用任何自己熟悉的工具来排查，甚至可以进行单步调试。只要问题能重现，排查就不会太困难，最多就是把程序调试到 JDK 或三方类库内部进行分析。如果是在测试环境排查问题，相比开发环境少的是调试，不过你可以使用 JDK 自带的 jvisualvm 或阿里的Arthas，附加到远程的 JVM 进程排查问题。另外，测试环境允许造数据、造压力模拟我们需要的场景，因此遇到偶发问题时，我们可以尝试去造一些场景让问题更容易出现，方便测试。如果是在生产环境排查问题，往往比较难：一方面，生产环境权限管控严格，一般不允许调试工具从远程附加进程；另一方面，生产环境出现问题要求以恢复为先，难以留出充足的时间去慢慢排查问题。但，因为生产环境的流量真实、访问量大、网络权限管控严格、环境复杂，因此更容易出问题，也是出问题最多的环境。接下来，我就与你详细说说，如何在生产环境排查问题吧。生产问题的排查很大程度依赖监控其实，排查问题就像在破案，生产环境出现问题时，因为要尽快恢复应用，就不可能保留完整现场用于排查和测试。因此，是否有充足的信息可以了解过去、还原现场就成了破案的关键。这里说的信息，主要就是日志、监控和快照。日志就不用多说了，主要注意两点：确保错误、异常信息可以被完整地记录到文件日志中；确保生产上程序的日志级别是 INFO 以上。记录日志要使用合理的日志优先级，DEBUG 用于开发调试、INFO 用于重要流程信息、WARN 用于需要关注的问题、ERROR 用于阻断流程的错误。对于监控，在生产环境排查问题时，首先就需要开发和运维团队做好充足的监控，而且是多个层次的监控。主机层面，对 CPU、内存、磁盘、网络等资源做监控。如果应用部署在虚拟机或 Kubernetes 集群中，那么除了对物理机做基础资源监控外，还要对虚拟机或 Pod 做同样的监控。监控层数取决于应用的部署方案，有一层 OS 就要做一层监控。网络层面，需要监控专线带宽、交换机基本情况、网络延迟。所有的中间件和存储都要做好监控，不仅仅是监控进程对 CPU、内存、磁盘 IO、网络使用的基本指标，更重要的是监控组件内部的一些重要指标。比如，著名的监控工具 Prometheus，就提供了大量的exporter来对接各种中间件和存储系统。应用层面，需要监控 JVM 进程的类加载、内存、GC、线程等常见指标（比如使用Micrometer来做应用监控），此外还要确保能够收集、保存应用日志、GC 日志。我们再来看看快照。这里的“快照”是指，应用进程在某一时刻的快照。通常情况下，我们会为生产环境的 Java 应用设置 -XX:+HeapDumpOnOutOfMemoryError 和 -XX:HeapDumpPath=…这 2 个 JVM 参数，用于在出现 OOM 时保留堆快照。这个课程中，我们也多次使用 MAT 工具来分析堆快照。了解过去、还原现场后，接下来我们就看看定位问题的套路。分析定位问题的套路定位问题，首先要定位问题出在哪个层次上。比如，是 Java 应用程序自身的问题还是外部因素导致的问题。我们可以先查看程序是否有异常，异常信息一般比较具体，可以马上定位到大概的问题方向；如果是一些资源消耗型的问题可能不会有异常，我们可以通过指标监控配合显性问题点来定位。一般情况下，程序的问题来自以下三个方面。第一，程序发布后的 Bug，回滚后可以立即解决。这类问题的排查，可以回滚后再慢慢分析版本差异。第二，外部因素，比如主机、中间件或数据库的问题。这类问题的排查方式，按照主机层面的问题、中间件或存储（统称组件）的问题分为两类。主机层面的问题，可以使用工具排查：CPU 相关问题，可以使用 top、vmstat、pidstat、ps 等工具排查；内存相关问题，可以使用 free、top、ps、vmstat、cachestat、sar 等工具排查；IO 相关问题，可以使用 lsof、iostat、pidstat、sar、iotop、df、du 等工具排查；网络相关问题，可以使用 ifconfig、ip、nslookup、dig、ping、tcpdump、iptables 等工具排查。组件的问题，可以从以下几个方面排查：排查组件所在主机是否有问题；排查组件进程基本情况，观察各种监控指标；查看组件的日志输出，特别是错误日志；进入组件控制台，使用一些命令查看其运作情况。第三，因为系统资源不够造成系统假死的问题，通常需要先通过重启和扩容解决问题，之后再进行分析，不过最好能留一个节点作为现场。系统资源不够，一般体现在 CPU 使用高、内存泄漏或 OOM 的问题、IO 问题、网络相关问题这四个方面。对于 CPU 使用高的问题，如果现场还在，具体的分析流程是：首先，在 Linux 服务器上运行 top -Hp pid 命令，来查看进程中哪个线程 CPU 使用高；然后，输入大写的 P 将线程按照 CPU 使用率排序，并把明显占用 CPU 的线程 ID 转换为 16 进制；最后，在 jstack 命令输出的线程栈中搜索这个线程 ID，定位出问题的线程当时的调用栈。如果没有条件直接在服务器上运行 top 命令的话，我们可以用采样的方式定位问题：间隔固定秒数（比如 10 秒）运行一次 jstack 命令，采样几次后，对比采样得出哪些线程始终处于运行状态，分析出问题的线程。如果现场没有了，我们可以通过排除法来分析。CPU 使用高，一般是由下面的因素引起的：突发压力。这类问题，我们可以通过应用之前的负载均衡的流量或日志量来确认，诸如 Nginx 等反向代理都会记录 URL，可以依靠代理的 Access Log 进行细化定位，也可以通过监控观察 JVM 线程数的情况。压力问题导致 CPU 使用高的情况下，如果程序的各资源使用没有明显不正常，之后可以通过压测 +Profiler（jvisualvm 就有这个功能）进一步定位热点方法；如果资源使用不正常，比如产生了几千个线程，就需要考虑调参。GC。这种情况，我们可以通过 JVM 监控 GC 相关指标、GC Log 进行确认。如果确认是 GC 的压力，那么内存使用也很可能会不正常，需要按照内存问题分析流程做进一步分析。程序中死循环逻辑或不正常的处理流程。这类问题，我们可以结合应用日志分析。一般情况下，应用执行过程中都会产生一些日志，可以重点关注日志量异常部分。对于内存泄露或 OOM 的问题，最简单的分析方式，就是堆转储后使用 MAT 分析。堆转储，包含了堆现场全貌和线程栈信息，一般观察支配树图、直方图就可以马上看到占用大量内存的对象，可以快速定位到内存相关问题。这一点我们会在第 5 篇加餐中详细介绍。需要注意的是，Java 进程对内存的使用不仅仅是堆区，还包括线程使用的内存（线程个数 * 每一个线程的线程栈）和元数据区。每一个内存区都可能产生 OOM，可以结合监控观察线程数、已加载类数量等指标分析。另外，我们需要注意看一下，JVM 参数的设置是否有明显不合理的地方，限制了资源使用。IO 相关的问题，除非是代码问题引起的资源不释放等问题，否则通常都不是由 Java 进程内部因素引发的。网络相关的问题，一般也是由外部因素引起的。对于连通性问题，结合异常信息通常比较容易定位；对于性能或瞬断问题，可以先尝试使用 ping 等工具简单判断，如果不行再使用 tcpdump 或 Wireshark 来分析。分析和定位问题需要注意的九个点有些时候，我们分析和定位问题时，会陷入误区或是找不到方向。遇到这种情况，你可以借鉴下我的九个心得。第一，考虑“鸡”和“蛋”的问题。比如，发现业务逻辑执行很慢且线程数增多的情况时，我们需要考虑两种可能性：一是，程序逻辑有问题或外部依赖慢，使得业务逻辑执行慢，在访问量不变的情况下需要更多的线程数来应对。比如，10TPS 的并发原先一次请求 1s 可以执行完成，10 个线程可以支撑；现在执行完成需要 10s，那就需要 100 个线程。二是，有可能是请求量","date":"0001-01-01","objectID":"/%E5%8A%A0%E9%A4%903%E4%B8%A8%E5%AE%9A%E4%BD%8D%E5%BA%94%E7%94%A8%E9%97%AE%E9%A2%98%E6%8E%92%E9%94%99%E5%A5%97%E8%B7%AF%E5%BE%88%E9%87%8D%E8%A6%81/:0:0","tags":null,"title":"","uri":"/%E5%8A%A0%E9%A4%903%E4%B8%A8%E5%AE%9A%E4%BD%8D%E5%BA%94%E7%94%A8%E9%97%AE%E9%A2%98%E6%8E%92%E9%94%99%E5%A5%97%E8%B7%AF%E5%BE%88%E9%87%8D%E8%A6%81/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 加餐4 | 分析定位Java问题，一定要用好这些工具（一）  下载APP   关闭 讲堂 部落 前端训练营 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 加餐4 | 分析定位Java问题，一定要用好这些工具（一） 2020-04-21 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长14:30大小13.29M  你好，我是朱晔。今天，我要和你分享的内容是分析定位 Java 问题常用的一些工具。到这里，我们的课程更新 17 讲了，已经更新过半了。在学习过程中，你会发现我在介绍各种坑的时候，并不是直接给出问题的结论，而是通过工具来亲眼看到问题。为什么这么做呢？因为我始终认为，遇到问题尽量不要去猜，一定要眼见为实。只有通过日志、监控或工具真正看到问题，然后再回到代码中进行比对确认，我们才能认为是找到了根本原因。你可能一开始会比较畏惧使用复杂的工具去排查问题，又或者是打开了工具感觉无从下手，但是随着实践越来越多，对 Java 程序和各种框架的运作越来越熟悉，你会发现使用这些工具越来越顺手。其实呢，工具只是我们定位问题的手段，要用好工具主要还是得对程序本身的运作有大概的认识，这需要长期的积累。因此，我会通过两篇加餐，和你分享 4 个案例，分别展示使用 JDK 自带的工具来排查 JVM 参数配置问题、使用 Wireshark 来分析网络问题、通过 MAT 来分析内存问题，以及使用 Arthas 来分析 CPU 使用高的问题。这些案例也只是冰山一角，你可以自己再通过些例子进一步学习和探索。在今天这篇加餐中，我们就先学习下如何使用 JDK 自带工具、Wireshark 来分析和定位 Java 程序的问题吧。使用 JDK 自带工具查看 JVM 情况JDK 自带了很多命令行甚至是图形界面工具，帮助我们查看 JVM 的一些信息。比如，在我的机器上运行 ls 命令，可以看到 JDK 8 提供了非常多的工具或程序：接下来，我会与你介绍些常用的监控工具。你也可以先通过下面这张图了解下各种工具的基本作用：为了测试这些工具，我们先来写一段代码：启动 10 个死循环的线程，每个线程分配一个 10MB 左右的字符串，然后休眠 10 秒。可以想象到，这个程序会对 GC 造成压力。//启动10个线程IntStream.rangeClosed(1, 10).mapToObj(i -\u003e new Thread(() -\u003e { while (true) { //每一个线程都是一个死循环，休眠10秒，打印10M数据 String payload = IntStream.rangeClosed(1, 10000000) .mapToObj(__ -\u003e \"a\") .collect(Collectors.joining(\"\")) + UUID.randomUUID().toString(); try { TimeUnit.SECONDS.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(payload.length()); }})).forEach(Thread::start);TimeUnit.HOURS.sleep(1);修改 pom.xml，配置 spring-boot-maven-plugin 插件打包的 Java 程序的 main 方法类：\u003cplugin\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-maven-plugin\u003c/artifactId\u003e \u003cconfiguration\u003e \u003cmainClass\u003eorg.geekbang.time.commonmistakes.troubleshootingtools.jdktool.CommonMistakesApplication \u003c/mainClass\u003e \u003c/configuration\u003e\u003c/plugin\u003e然后使用 java -jar 启动进程，设置 JVM 参数，让堆最小最大都是 1GB：java -jar common-mistakes-0.0.1-SNAPSHOT.jar -Xms1g -Xmx1g完成这些准备工作后，我们就可以使用 JDK 提供的工具，来观察分析这个测试程序了。jps首先，使用 jps 得到 Java 进程列表，这会比使用 ps 来的方便：➜ ~ jps1270722261 Launcher23864 common-mistakes-0.0.1-SNAPSHOT.jar15608 RemoteMavenServer3623243 Main23868 Jps22893 KotlinCompileDaemonjinfo然后，可以使用 jinfo 打印 JVM 的各种参数：➜ ~ jinfo 23864Java System Properties:#Wed Jan 29 12:49:47 CST 2020...user.name=zhuyepath.separator=\\:os.version=10.15.2java.runtime.name=Java(TM) SE Runtime Environmentfile.encoding=UTF-8java.vm.name=Java HotSpot(TM) 64-Bit Server VM...VM Flags:-XX:CICompilerCount=4 -XX:ConcGCThreads=2 -XX:G1ConcRefinementThreads=8 -XX:G1HeapRegionSize=1048576 -XX:GCDrainStackTargetSize=64 -XX:InitialHeapSize=268435456 -XX:MarkStackSize=4194304 -XX:MaxHeapSize=4294967296 -XX:MaxNewSize=2576351232 -XX:MinHeapDeltaBytes=1048576 -XX:NonNMethodCodeHeapSize=5835340 -XX:NonProfiledCodeHeapSize=122911450 -XX:ProfiledCodeHeapSize=122911450 -XX:ReservedCodeCacheSize=251658240 -XX:+SegmentedCodeCache -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GCVM Arguments:java_command: common-mistakes-0.0.1-SNAPSHOT.jar -Xms1g -Xmx1gjava_class_path (initial): common-mistakes-0.0.1-SNAPSHOT.jarLauncher Type: SUN_STANDARD查看第 15 行和 19 行可以发现，我们设置 JVM 参数的方式不对，-Xms1g 和 -Xmx1g 这两个参数被当成了 Java 程序的启动参数，整个 JVM 目前最大内存是 4GB 左右，而不是 1GB。因此，当我们怀疑 JVM 的配置很不正常的时候，要第一时间使用工具来确认参数。除了使用工具确认 JVM 参数外，你也可以打印 VM 参数和程序参数：System.out.println(\"VM options\");System.out.println(ManagementFactory.getRuntimeMXBean().getInputArguments().stream().collect(Collectors.joining(System.lineSeparator())));System.out.println(\"Program arguments\");System.out.println(Arrays.stream(args).collect(Collectors.joining(System.lineSeparator())));把 JVM 参数放到 -jar 之前，重新启动程序，可以看到如下输出，从输出也可以确认这次 JVM 参数的配置正确了：➜ target git:(master) ✗ java -Xms1g -Xmx1g -jar common-mistakes-0.0.1-SNAPSHOT.jar testVM options-Xms1g-Xmx1gProgram argumentstestjvisualvm然后，启动另一个重量级工具 jvisualvm 观察一下程序，可以在概述面板再次确认 JVM 参数设置成功了：继续观察监视面板可以看到，JVM 的 GC 活动基本是 10 秒发生一次，堆内存在 250MB 到 900MB 之间波动，活动线程数是 22。我们可以在监视面板看到 JVM 的基本情况，也可以直接在这里进行手动 GC 和堆 Dump 操作：jconsole如果希望看到各个内存区的 GC 曲线图，可以使用 jconsole 观察。jconsole 也是一个综合性图形界面监控工具，比 jvisualvm 更方便的一点是，可以用曲线的形式监控各种数据，包括 MBean 中的属性值：jstat同样，如果没有条件使用","date":"0001-01-01","objectID":"/%E5%8A%A0%E9%A4%904%E4%B8%A8%E5%88%86%E6%9E%90%E5%AE%9A%E4%BD%8Djava%E9%97%AE%E9%A2%98%E4%B8%80%E5%AE%9A%E8%A6%81%E7%94%A8%E5%A5%BD%E8%BF%99%E4%BA%9B%E5%B7%A5%E5%85%B7%E4%B8%80/:0:0","tags":null,"title":"","uri":"/%E5%8A%A0%E9%A4%904%E4%B8%A8%E5%88%86%E6%9E%90%E5%AE%9A%E4%BD%8Djava%E9%97%AE%E9%A2%98%E4%B8%80%E5%AE%9A%E8%A6%81%E7%94%A8%E5%A5%BD%E8%BF%99%E4%BA%9B%E5%B7%A5%E5%85%B7%E4%B8%80/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 加餐5 | 分析定位Java问题，一定要用好这些工具（二）  下载APP   关闭 讲堂 部落 Python 进阶训练营 算法训练营 架构师训练营 企业服务 极客商城 客户端下载 兑换中心 渠道合作 推荐作者 加餐5 | 分析定位Java问题，一定要用好这些工具（二） 2020-04-30 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长18:15大小16.72M  你好，我是朱晔。在上一篇加餐中，我们介绍了使用 JDK 内置的一些工具、网络抓包工具 Wireshark 去分析、定位 Java 程序的问题。很多同学看完这一讲，留言反馈说是“打开了一片新天地，之前没有关注过 JVM”“利用 JVM 工具发现了生产 OOM 的原因”。其实，工具正是帮助我们深入到框架和组件内部，了解其运作方式和原理的重要抓手。所以，我们一定要用好它们。今天，我继续和你介绍如何使用 JVM 堆转储的工具 MAT 来分析 OOM 问题，以及如何使用全能的故障诊断工具 Arthas 来分析、定位高 CPU 问题。使用 MAT 分析 OOM 问题对于排查 OOM 问题、分析程序堆内存使用情况，最好的方式就是分析堆转储。堆转储，包含了堆现场全貌和线程栈信息（Java 6 Update 14 开始包含）。我们在上一篇加餐中看到，使用 jstat 等工具虽然可以观察堆内存使用情况的变化，但是对程序内到底有多少对象、哪些是大对象还一无所知，也就是说只能看到问题但无法定位问题。而堆转储，就好似得到了病人在某个瞬间的全景核磁影像，可以拿着慢慢分析。Java 的 OutOfMemoryError 是比较严重的问题，需要分析出根因，所以对生产应用一般都会这样设置 JVM 参数，方便发生 OOM 时进行堆转储：-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=.上一篇加餐中我们提到的 jvisualvm 工具，同样可以进行一键堆转储后，直接打开这个 dump 查看。但是，jvisualvm 的堆转储分析功能并不是很强大，只能查看类使用内存的直方图，无法有效跟踪内存使用的引用关系，所以我更推荐使用 Eclipse 的 Memory Analyzer（也叫做 MAT）做堆转储的分析。你可以点击这个链接，下载 MAT。使用 MAT 分析 OOM 问题，一般可以按照以下思路进行：通过支配树功能或直方图功能查看消耗内存最大的类型，来分析内存泄露的大概原因；查看那些消耗内存最大的类型、详细的对象明细列表，以及它们的引用链，来定位内存泄露的具体点；配合查看对象属性的功能，可以脱离源码看到对象的各种属性的值和依赖关系，帮助我们理清程序逻辑和参数；辅助使用查看线程栈来看 OOM 问题是否和过多线程有关，甚至可以在线程栈看到 OOM 最后一刻出现异常的线程。比如，我手头有一个 OOM 后得到的转储文件 java_pid29569.hprof，现在要使用 MAT 的直方图、支配树、线程栈、OQL 等功能来分析此次 OOM 的原因。首先，用 MAT 打开后先进入的是概览信息界面，可以看到整个堆是 437.6MB：那么，这 437.6MB 都是什么对象呢？如图所示，工具栏的第二个按钮可以打开直方图，直方图按照类型进行分组，列出了每个类有多少个实例，以及占用的内存。可以看到，char[]字节数组占用内存最多，对象数量也很多，结合第二位的 String 类型对象数量也很多，大概可以猜出（String 使用 char[]作为实际数据存储）程序可能是被字符串占满了内存，导致 OOM。我们继续分析下，到底是不是这样呢。在 char[]上点击右键，选择 List objects-\u003ewith incoming references，就可以列出所有的 char[]实例，以及每个 char[]的整个引用关系链：随机展开一个 char[]，如下图所示：接下来，我们按照红色框中的引用链来查看，尝试找到这些大 char[]的来源：在①处看到，这些 char[]几乎都是 10000 个字符、占用 20000 字节左右（char 是 UTF-16，每一个字符占用 2 字节）；在②处看到，char[]被 String 的 value 字段引用，说明 char[]来自字符串；在③处看到，String 被 ArrayList 的 elementData 字段引用，说明这些字符串加入了一个 ArrayList 中；在④处看到，ArrayList 又被 FooService 的 data 字段引用，这个 ArrayList 整个 RetainedHeap 列的值是 431MB。Retained Heap（深堆）代表对象本身和对象关联的对象占用的内存，Shallow Heap（浅堆）代表对象本身占用的内存。比如，我们的 FooService 中的 data 这个 ArrayList 对象本身只有 16 字节，但是其所有关联的对象占用了 431MB 内存。这些就可以说明，肯定有哪里在不断向这个 List 中添加 String 数据，导致了 OOM。左侧的蓝色框可以查看每一个实例的内部属性，图中显示 FooService 有一个 data 属性，类型是 ArrayList。如果我们希望看到字符串完整内容的话，可以右键选择 Copy-\u003eValue，把值复制到剪贴板或保存到文件中：这里，我们复制出的是 10000 个字符 a（下图红色部分可以看到）。对于真实案例，查看大字符串、大数据的实际内容对于识别数据来源，有很大意义：看到这些，我们已经基本可以还原出真实的代码是怎样的了。其实，我们之前使用直方图定位 FooService，已经走了些弯路。你可以点击工具栏中第三个按钮（下图左上角的红框所示）进入支配树界面（有关支配树的具体概念参考这里）。这个界面会按照对象保留的 Retained Heap 倒序直接列出占用内存最大的对象。可以看到，第一位就是 FooService，整个路径是 FooSerice-\u003eArrayList-\u003eObject[]-\u003eString-\u003echar[]（蓝色框部分），一共有 21523 个字符串（绿色方框部分）：这样，我们就从内存角度定位到 FooService 是根源了。那么，OOM 的时候，FooService 是在执行什么逻辑呢？为解决这个问题，我们可以点击工具栏的第五个按钮（下图红色框所示）。打开线程视图，首先看到的就是一个名为 main 的线程（Name 列），展开后果然发现了 FooService：先执行的方法先入栈，所以线程栈最上面是线程当前执行的方法，逐一往下看能看到整个调用路径。因为我们希望了解 FooService.oom() 方法，看看是谁在调用它，它的内部又调用了谁，所以选择以 FooService.oom() 方法（蓝色框）为起点来分析这个调用栈。往下看整个绿色框部分，oom() 方法被 OOMApplication 的 run 方法调用，而这个 run 方法又被 SpringAppliction.callRunner 方法调用。看到参数中的 CommandLineRunner 你应该能想到，OOMApplication 其实是实现了 CommandLineRunner 接口，所以是 SpringBoot 应用程序启动后执行的。以 FooService 为起点往上看，从紫色框中的 Collectors 和 IntPipeline，你大概也可以猜出，这些字符串是由 Stream 操作产生的。再往上看，可以发现在 StringBuilder 的 append 操作的时候，出现了 OutOfMemoryError 异常（黑色框部分），说明这这个线程抛出了 OOM 异常。我们看到，整个程序是 Spring Boot 应用程序，那么 FooService 是不是 Spring 的 Bean 呢，又是不是单例呢？如果能分析出这点的话，就更能确认是因为反复调用同一个 FooService 的 oom 方法，然后导致其内部的 ArrayList 不断增加数据的。点击工具栏的第四个按钮（如下图红框所示），来到 OQL 界面。在这个界面，我们可以使用类似 SQL 的语法，在 dump 中搜索数据（你可以直接在 MAT 帮助菜单搜索 OQL Syntax，来查看 OQL 的详细语法）。比如，输入如下语句搜索 FooService 的实例：SELECT * FROM org.geekbang.time.commonmistakes.troubleshootingtools.oom.FooService可以看到只有一个实例，然后我们通过 List objects 功能搜索引用 FooService 的对象：得到以下结果：可以看到，一共两处引用：第一处是，OOMApplication 使用了 FooService，这个我们已经知道了。第二处是一个 ConcurrentHashMap。可以看到，这个 HashMap 是 DefaultListableBeanFactory 的 singletonObjects 字段，可以证实 FooService 是 Spring 容器管理的单例的 Bean。你甚至可以在这个 HashMap 上点击右键，选择 Java Collections-\u003eHash Entries 功能，来查看其内容：这样就列出了所有的 Bean，可以在 Value 上的 Regex 进一步过滤。输入 FooService 后可以看到","date":"0001-01-01","objectID":"/%E5%8A%A0%E9%A4%905%E4%B8%A8%E5%88%86%E6%9E%90%E5%AE%9A%E4%BD%8Djava%E9%97%AE%E9%A2%98%E4%B8%80%E5%AE%9A%E8%A6%81%E7%94%A8%E5%A5%BD%E8%BF%99%E4%BA%9B%E5%B7%A5%E5%85%B7%E4%BA%8C/:0:0","tags":null,"title":"","uri":"/%E5%8A%A0%E9%A4%905%E4%B8%A8%E5%88%86%E6%9E%90%E5%AE%9A%E4%BD%8Djava%E9%97%AE%E9%A2%98%E4%B8%80%E5%AE%9A%E8%A6%81%E7%94%A8%E5%A5%BD%E8%BF%99%E4%BA%9B%E5%B7%A5%E5%85%B7%E4%BA%8C/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 加餐6 | 这15年来，我是如何在工作中学习技术和英语的？  下载APP   关闭 讲堂部落算法训练营Python进阶训练营架构师训练营企业版极客商城兑换中心App下载 渠道合作 推荐作者 加餐6 | 这15年来，我是如何在工作中学习技术和英语的？ 2020-05-16 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长16:33大小15.17M  你好，我是朱晔。今天，我来和你聊聊如何在工作中，让自己成长得更快。工作这些年来，经常会有同学来找我沟通学习和成长，他们的问题可以归结为两个。一是，长期参与 CRUD 业务开发项目，技术提升出现瓶颈，学不到新知识，完全没有办法实践各种新技术，以后会不会被淘汰、找不到工作？二是，英语学得比较晚，大学的时候也只是为了应试，英语水平很低，看不了英文的技术资料，更别说去外企找工作了。不知道你是不是也面临这两个问题呢？今天，我就通过自己的经历和你分享一下，如何利用有限的环境、有限的时间来学习技术和英语？学好技术在我看来，知识网络的搭建就是在造楼房：基础也就是地基的承载力，决定了你能把楼造多高；广度就像是把房子造大、造宽；深度就是楼房的高度。因此，如果你想要提升自己的水平，那这三个方面的发展缺一不可。第一，学习必须靠自觉。虽说工作经历和项目经验是实践技术、提升技术的一个重要手段，但不可能所有的工作经历和项目都能持续地提升我们的技术。所以，我们要想提升自己的技术水平，就必须打消仅仅通过工作经历来提升的念头，要靠业余时间主动地持续学习和积累来提升。比如，你可以针对项目中用到的技术，全面阅读官方文档，做各种 Demo 来论证其技术特性。在这个过程中，你一定还会产生许多技术疑问，那就继续展开学习。第二，不要吝啬分享。刚毕业那会，我花了很多时间和精力在 CSDN 回答问题，积极写博客、写书和翻译书。这些经历对我的技术成长，帮助非常大。很多知识点我们自认为完全掌握了，但其实并不是那么回事儿。当我们要说出来教别人的时候，就必须 100% 了解每一个细节。因此，分享不仅是帮助自己进一步理清每一个知识点、锻炼自己的表达能力，更是一种强迫自己学习的手段，因为你要保证按时交付。当然了，分享的过程也需要些正向激励，让自己保持分享的激情。就比如说，我获得的几次微软 MVP、CSDN TOP3 专家等荣誉，就对我激励很大，可以让我保持热情去不断地学习并帮助别人。第三，不要停留在舒适区。分享一段我的真实经历吧。我加入一家公司组建新团队后，在做技术选型的时候，考虑到成本等因素，放弃了从事了七年的.NET 技术，转型 Java。有了.NET 的积累，我自己转型 Java 只用了两周。其实，一开始做这个决定非常痛苦，但是突破自己的舒适区并没有想象得那么困难。随后，我又自学了 iOS、深度学习、Python 等技术或语言。随着掌握的技术越来越多，这些技术不但让我触类旁通，更让我理解了技术只是工具，解决问题需要使用合适的技术。因此，我也建议你，利用业余时间多学习几门不同类型的编程语言，比如 Java、Python 和 Go。有些时候，我们因为恐惧跳出舒适区而不愿意学习和引入合适的新技术来解决问题，虽然省去了前期的学习转型成本，但是后期却会投入更多的时间来弥补技术上的短板。第四，打好基础很重要。这里的“基础”是指，和编程语言无关的那部分知识，包括硬件基础、操作系统原理、TCP/IP、HTTP、数据结构和算法、安全基础、设计模式、数据库原理等。学习基础知识是比较枯燥的过程，需要大块的时间来系统阅读相关书籍，并要尝试把学到的知识付诸实践。只有实践过的技术才能映入脑子里，否则只是书本上的知识。比如，学习 TCP/IP 的时候，我们可以使用 Wireshark 来观察网络数据。又比如，学习设计模式的时候，我们可以结合身边的业务案例来思考下，是否有对应的适用场景，如果没有能否模拟一个场景，然后使用所有设计模式和自己熟悉的语言开发一个实际的 Demo。这些看似和我们日常业务开发关系不大的基础知识，是我们是否能够深入理解技术的最重要的基石。第五，想办法积累技术深度。对开发者而言，技术深度体现在从一个框架、组件或 SDK 的使用者转变为开发者。虽然不建议大家重复去造轮子、造框架，但我们完全可以阅读各种框架的源码去了解其实现，并亲手实现一些框架的原型。比如，你可以尝试把 MVC、RPC、ORM、IoC、AOP 等框架，都实现一个最基本功能点原型。在实现的过程中，你一定会遇到很多问题和难点，然后再继续研究一下 Spring、Hibernate、Dubbo 等框架是如何实现的。当把自己的小框架实现出来的那一刻，你收获的不仅是满满的成就感，更是在技术深度积累上的更进一步。在这个过程中，你肯定会遇到不少问题、解决不少问题。有了这些积累，之后再去学习甚至二次开发那些流行的开源框架，就会更容易了。除了实现一些框架外，我还建议你选择一个中间件（比如 Redis、RocketMQ）来练手学习网络知识。我们可以先实现它的客户端，用 Netty 实现 TCP 通信层的功能，之后参照官方文档实现协议封装、客户端连接池等功能。在实现的过程中，你可以对自己实现的客户端进行压测，分析和官方实现的性能差距。这样一来，你不仅可以对 TCP/IP 网络有更深入的了解，还可以获得很多网络方面的优化经验。然后，再尝试实现服务端，进一步加深对网络的认识。最后，尝试把服务端扩展为支持高可用的集群，来加深对分布式通信技术的理解。在实现这样一个分布式 C/S 中间件的过程中，你对技术的理解肯定会深入了许多。在这个过程中，你会发现，技术深度的“下探”和基础知识的积累息息相关。基础知识不扎实，往深了走往往会步履维艰。这时，你可以再回过头来，重新系统学习一些基础理论。第六，扩大技术广度也重要。除了之前提到的多学几门编程语言之外，在技术广度的拓展上，我们还可以在两个方面下功夫。第一，阅读大量的技术书籍。新出来的各种技术图书（不只是编程相关的），一般我都会买。十几年来，我买了 500 多本技术图书，大概有三分之一是完整看过的，还有三分之一只翻了一个大概，还有三分之一只看了目录。广泛的阅读，让我能够了解目前各种技术的主流框架和平台。这样的好处是，在整体看技术方案的时候，我可以知道大家都在做什么，不至于只能理解方案中的一部分。对于看不完的、又比较有价值的书，我会做好标签，等空闲的时候再看。第二，在开发程序的时候，我们会直接使用运维搭建的数据库（比如 Elasticsearch、MySQL）、中间件（比如 RabbitMQ、ZooKeeper）、容器云（比如 Kubernetes）。但，如果我们只会使用这些组件而不会搭建的话，对它们的理解很可能只是停留在 API 或客户端层面。因此，我建议你去尝试下从头搭建和配置这些组件，在遇到性能问题的时候自己着手分析一下。把实现技术的前后打通，遇到问题时我们就不至于手足无措了。我通常会购买公有云按小时收费的服务器，来构建一些服务器集群，尝试搭建和测试这些系统，加深对运维的理解。学好英语为啥要单独说英语的学习方法呢，这是因为学好英语对做技术的同学非常重要：国外的社区环境比较好，许多技术问题只有通过英文关键字才能在 Google 或 Stackoverflow 上搜到答案；可以第一时间学习各种新技术、阅读第一手资料，中文翻译资料往往至少有半年左右的延迟；参与或研究各种开源项目，和老外沟通需要使用英语来提问，以及阅读别人的答复。所以说，学好英语可以整体拓宽个人视野。不过，对于上班族来说，我们可能没有太多的大块时间投入英语学习，那如何利用碎片时间、相对休闲地学习英语呢？还有一个问题是，学好英语需要大量的练习和训练，但不在外企工作就连个英语环境都没有，那如何解决这样的矛盾呢？接下来，我将从读、听、写和说四个方面，和你分享一下我学习英语的方法。读方面读对于我们这些搞技术的人来说是最重要的，并且也是最容易掌握的。我建议你这么学：先从阅读身边的技术文档开始，有英语文档的一定要选择阅读英语文档。一来，贴近实际工作，是我们真正用得到的知识，比较容易有兴趣去读；二来，这些文档中大部分词汇，我们日常基本都接触过，难度不会太大。技术书籍的常用词汇量不大，有了一些基础后，你可以正式或非正式地参与翻译一些英语书籍或文档。从我的经验来看，翻译过一本书之后，你在日常阅读任何技术资料时基本都不需要查字典了。订阅一些英语报纸，比如 ChinaDaily。第一，贴近日常生活，都是我们身边发生的事儿，不会很枯燥；第二，可以进一步积累词汇量。在这个过程中，你肯定需要大量查字典打断阅读，让你感觉很痛苦。但一般来说，一个单词最多查三次也就记住了，所以随着时间推移，你慢慢可以摆脱字典，词汇量也可以上一个台阶了。技术方面阅读能力的培养，通常只需要三个月左右的时间，但生活方面资料的阅读可能需要一年甚至更长的时间。听方面读需要积累词汇量，听力的训练需要通过时间来磨耳朵。每个人都可以选择适合自己的材料来磨耳朵，比如我是通过看美剧来训练听力的。我就以看美剧为例，说说练听力的几个关键点。量变到质变的过程，需要 1000 小时的量。如果一部美剧是 100 小时，那么看前 9 部的时候可能都很痛苦，直到某一天你突然觉得一下子都可以听懂了。需要确保看美剧时没有中文字幕，否则很难忍住不看，看了字幕就无法起到训练听力的效果。在美剧的选择上，可以先选择对话比较少，也可以选择自己感兴趣的题材，这样不容易放弃。如果第一次听下来，听懂率低于 30%，连理解剧情都困难，那么可以先带着中文字幕看一遍，然后再脱离字幕看","date":"0001-01-01","objectID":"/%E5%8A%A0%E9%A4%906%E4%B8%A8%E8%BF%9915%E5%B9%B4%E6%9D%A5%E6%88%91%E6%98%AF%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%92%8C%E8%8B%B1%E8%AF%AD%E7%9A%84/:0:0","tags":null,"title":"","uri":"/%E5%8A%A0%E9%A4%906%E4%B8%A8%E8%BF%9915%E5%B9%B4%E6%9D%A5%E6%88%91%E6%98%AF%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%92%8C%E8%8B%B1%E8%AF%AD%E7%9A%84/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 结束语 | 写代码时，如何才能尽量避免踩坑？  下载APP   关闭 讲堂部落算法训练营Python进阶训练营架构师训练营企业版极客商城兑换中心App下载 渠道合作 推荐作者 结束语 | 写代码时，如何才能尽量避免踩坑？ 2020-05-28 朱晔 Java业务开发常见错误100例 进入课程  讲述：王少泽 时长11:09大小10.22M  你好，我是朱晔。这个课程要告一段落了，在这里我要特别感谢你一直以来的认可与陪伴。于我而言，虽然这半年多以来我几乎所有的业余时间都用了在这个课程的创作，以及回答你的问题上，很累很辛苦，但是看到你的认真学习和对课程内容的好评，看到你不仅收获了知识还燃起了钻研源码的热情，我也非常高兴，深觉一切的辛苦付出都是甜蜜的。相信一路走来，你不仅理解了业务代码开发中常见的 130 多个坑点的解决方式，也知道了其根本原因，以及如何使用一些常用工具来分析问题。这样在以后遇到各种坑的时候，你就更加能有方法、有信心来解决问题。如何尽量避免踩坑？不过，学习、分析这些坑点并不是我们的最终目的，在写业务代码时如何尽量避免踩坑才是。所以，接下来，我要重点和你聊聊避免踩坑的一些方法。所谓坑，往往就是我们意识不到的陷进。虽然这个课程覆盖了 130 多个业务开发时可能会出错的点，但我相信在整个 Java 开发领域还有成千上万个可能会踩的坑。同时，随着 Java 语言以及各种新框架、新技术的产生，我们还会不断遇到各种坑，很难有一种方式确保永远不会遇到新问题。而我们能做的，就是尽可能少踩坑，或者减少踩坑给我们带来的影响。鉴于此，我还有 10 条建议要分享给你。第一，遇到自己不熟悉的新类，在不了解之前不要随意使用。比如，我在并发工具这一讲中提到的 CopyOnWriteArrayList。如果你仅仅认为 CopyOnWriteArrayList 是 ArrayList 的线程安全版本，在不知晓原理之前把它用于大量写操作的场景，那么很可能会遇到性能问题。JDK 或各种框架随着时间的推移会不断推出各种特殊类，用于极致化各种细化场景下的程序性能。在使用这些类之前，我们需要认清楚这些类的由来，以及要解决的问题，在确认自己的场景符合的情况下再去使用。而且，越普适的工具类通常用起来越简单，越高级的类用起来越复杂，也更容易踩坑。比如，代码加锁这一讲中提到的，锁工具类 StampedLock 就比 ReentrantLock 或者 synchronized 的用法复杂得多，很容易踩坑。第二，尽量使用更高层次的框架。通常情况下，偏底层的框架趋向于提供更多细节的配置，尽可能让使用者根据自己的需求来进行不同的配置，而较少考虑最佳实践的问题；而高层次的框架，则会更多地考虑怎么方便开发者开箱即用。比如，在HTTP 请求这一讲中，我们谈到 Apache HttpClient 的并发数限制问题。如果你使用 Spring Cloud Feign 搭配 HttpClient，就不会遇到单域名默认 2 个并发连接的问题。因为，Spring Cloud Feign 已经把这个参数设置为了 50，足够应对一般场景了。第三，关注各种框架和组件的安全补丁和版本更新。比如，我们使用的 Tomcat 服务器、序列化框架等，就是黑客关注的安全突破口。我们需要及时关注这些组件和框架的稳定大版本和补丁，并及时更新升级，以避免组件和框架本身的性能问题或安全问题带来的大坑。第四，尽量少自己造轮子，使用流行的框架。流行框架最大的好处是成熟，在经过大量用户的使用打磨后，你能想到、能遇到的所有问题几乎别人都遇到了，框架中也有了解决方案。很多时候我们会以“轻量级”为由来造轮子，但其实很多复杂的框架，一开始也是轻量的。只不过是，这些框架经过各种迭代解决了各种问题，做了很多可扩展性预留之后，才变得越来越复杂，而并不一定是框架本身的设计臃肿。如果我们自己去开发框架的话，很可能会踩一些别人已经踩过的坑。比如，直接使用 JDK NIO 来开发网络程序或网络框架的话，我们可能会遇到 epoll 的 selector 空轮询 Bug，最终导致 CPU 100%。而 Netty 规避了这些问题，因此使用 Netty 开发 NIO 网络程序，不但简单而且可以少踩很多坑。第五，开发的时候遇到错误，除了搜索解决方案外，更重要的是理解原理。比如，在OOM这一讲，我提到的配置超大 server.max-http-header-size 参数导致的 OOM 问题，可能就是来自网络的解决方案。网络上别人给出的解决方案，可能只是适合“自己”，不一定适合所有人。并且，各种框架迭代很频繁，今天有效的解决方案，明天可能就无效了；今天有效的参数配置，新版本可能就不再建议使用甚至失效了。因此，只有知其所以然，才能从根本上避免踩坑。第六，网络上的资料有很多，但不一定可靠，最可靠的还是官方文档。比如，搜索 Java 8 的一些介绍，你可以看到有些资料提到了在 Java 8 中 Files.lines 方法进行文件读取更高效，但是 Demo 代码并没使用 try-with-resources 来释放资源。在文件 IO这一讲中，我和你讲解了这么做会导致文件句柄无法释放。其实，网上的各种资料，本来就是大家自己学习分享的经验和心得，不一定都是对的。另外，这些资料给出的都是 Demo，演示的是某个类在某方面的功能，不一定会面面俱到地考虑到资源释放、并发等问题。因此，对于系统学习某个组件或框架，我最推荐的还是 JDK 或者三方库的官方文档。这些文档基本不会出现错误的示例，一般也会提到使用的最佳实践，以及最需要注意的点。第七，做好单元测试和性能测试。如果你开发的是一个偏底层的服务或框架，有非常多的受众和分支流程，那么单元测试（或者是自动化测试）就是必须的。人工测试一般针对主流程和改动点，只有单元测试才可以确保任何一次改动不会影响现有服务的每一个细节点。此外，许多坑都涉及线程安全、资源使用，这些问题只有在高并发的情况下才会产生。没有经过性能测试的代码，只能认为是完成了功能，还不能确保健壮性、可扩展性和可靠性。第八，做好设计评审和代码审查工作。人都会犯错，而且任何一个人的知识都有盲区。因此，项目的设计如果能提前有专家组进行评审，每一段代码都能有至少三个人进行代码审核，就可以极大地减少犯错的可能性。比如，对于熟悉 IO 的开发者来说，他肯定知道文件的读写需要基于缓冲区。如果他看到另一个同事提交的代码，是以单字节的方式来读写文件，就可以提前发现代码的性能问题。又比如，一些比较老的资料仍然提倡使用MD5 摘要来保存密码。但是，现在 MD5 已经不安全了。如果项目设计已经由公司内安全经验丰富的架构师和安全专家评审过，就可以提前避免安全疏漏。第九，借助工具帮我们避坑。其实，我们犯很多低级错误时，并不是自己不知道，而是因为疏忽。就好像是，即使我们知道可能存在这 100 个坑，但如果让我们一条一条地确认所有代码是否有这些坑，我们也很难办到。但是，如果我们可以把规则明确的坑使用工具来检测，就可以避免大量的低级错误。比如，使用 YYYY 进行日期格式化的坑、使用 == 进行判等的坑、List.subList原 List 和子 List 相互影响的坑等，都可以通过阿里 P3C 代码规约扫描插件发现。我也建议你为 IDE 安装这个插件。此外，我还建议在 CI 流程中集成Sonarqube代码静态扫描平台，对需要构建发布的代码进行全面的代码质量扫描。第十，做好完善的监控报警。诸如内存泄露、文件句柄不释放、线程泄露等消耗型问题，往往都是量变积累成为质变，最后才会造成进程崩溃。如果一开始我们就可以对应用程序的内存使用、文件句柄使用、IO 使用量、网络带宽、TCP 连接、线程数等各种指标进行监控，并且基于合理阈值设置报警，那么可能就能在事故的婴儿阶段及时发现问题、解决问题。此外，在遇到报警的时候，我们不能凭经验想当然地认为这些问题都是已知的，对报警置之不理。我们要牢记，所有报警都需要处理和记录。以上，就是我要分享给你的 10 条建议了。用好这 10 条建议，可以帮助我们很大程度提前发现 Java 开发中的一些坑、避免一些压力引起的生产事故，或是减少踩坑的影响。最后，正所谓师傅领进门，修行靠个人，希望你在接下来学习技术和写代码的过程中，能够养成多研究原理、多思考总结问题的习惯，点点滴滴补全自己的知识网络。对代码精益求精，写出健壮的代码，线上问题少了，不但自己的心情好了，也能得到更多认可，并有更多时间来学习提升。这样，我们的个人成长就会比较快，形成正向循环。另外，如果你有时间，我想请你帮我填个课程问卷，和我反馈你对这个课程的想法和建议。今天虽然是结课，但我还会继续关注你的留言，也希望你能继续学习这个课程的内容，并会通过留言区和你互动。你还可以继续把这个课程分享给身边的朋友和同事，我们继续交流、讨论在写 Java 业务代码时可能会犯的错儿。 © 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。 上一篇 加餐6 | 这15年来，我是如何在工作中学习技术和英语的？ 下一篇 结课测试 | 关于Java业务开发的100个常见错误，你都明白其中缘由了吗？  写留言 精选留言(27) insight 2020-05-28 非常感谢老师的课，这是我第一门在极客时间听完的课，让我学到了很多东西，解决了很多编程中遇到的问题，流处理的教学也让我打开了新大门，爱上了这种工具，期待老师的新课程！ 作者回复: 大家的留言我就不一一回复了，如果觉","date":"0001-01-01","objectID":"/%E7%BB%93%E6%9D%9F%E8%AF%AD%E4%B8%A8%E5%86%99%E4%BB%A3%E7%A0%81%E6%97%B6%E5%A6%82%E4%BD%95%E6%89%8D%E8%83%BD%E5%B0%BD%E9%87%8F%E9%81%BF%E5%85%8D%E8%B8%A9%E5%9D%91/:0:0","tags":null,"title":"","uri":"/%E7%BB%93%E6%9D%9F%E8%AF%AD%E4%B8%A8%E5%86%99%E4%BB%A3%E7%A0%81%E6%97%B6%E5%A6%82%E4%BD%95%E6%89%8D%E8%83%BD%E5%B0%BD%E9%87%8F%E9%81%BF%E5%85%8D%E8%B8%A9%E5%9D%91/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e 结课测试 | 关于Java业务开发的100个常见错误，你都明白其中缘由了吗？  下载APP   关闭 讲堂部落算法训练营Python进阶训练营架构师训练营企业版极客商城兑换中心App下载 渠道合作 推荐作者 结课测试 | 关于Java业务开发的100个常见错误，你都明白其中缘由了吗？ 2020-05-30 朱晔 Java业务开发常见错误100例 进入课程  你好，我是朱晔。《Java 业务开发常见错误 100 例》这门课程已经全部结束了。我给你准备了一套结课测试题。它既可以是对你学习效果的一个检验，也可以被看作对于课程内容的一个系统性回顾。这套测试题共有 20 道题目，包括 8 道单选题和 12 道多选题，满分 100 分，系统自动评分。还等什么，点击下面按钮开始测试吧！ © 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。 上一篇 结束语 | 写代码时，如何才能尽量避免踩坑？  写留言 精选留言(2) Planeswalker23 2020-05-30 完结撒花🎉 展开   3 QQ怪 2020-05-30 第一次70分有点低，时间感觉有点不够，后面飞快答题错了不少，还有很多不足，会继续加油！   2  搜索 复制 ","date":"0001-01-01","objectID":"/%E7%BB%93%E8%AF%BE%E6%B5%8B%E8%AF%95%E4%B8%A8%E5%85%B3%E4%BA%8Ejava%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E7%9A%84100%E4%B8%AA%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E4%BD%A0%E9%83%BD%E6%98%8E%E7%99%BD%E5%85%B6%E4%B8%AD%E7%BC%98%E7%94%B1%E4%BA%86%E5%90%97/:0:0","tags":null,"title":"","uri":"/%E7%BB%93%E8%AF%BE%E6%B5%8B%E8%AF%95%E4%B8%A8%E5%85%B3%E4%BA%8Ejava%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E7%9A%84100%E4%B8%AA%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E4%BD%A0%E9%83%BD%E6%98%8E%E7%99%BD%E5%85%B6%E4%B8%AD%E7%BC%98%E7%94%B1%E4%BA%86%E5%90%97/"}]